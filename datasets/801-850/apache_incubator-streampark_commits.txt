File: streampark-common/src/main/java/org/apache/streampark/common/enums/FlinkJobType.java
Patch:
@@ -31,9 +31,9 @@ public enum FlinkJobType {
     UNKNOWN("Unknown", -1),
 
     /**
-     * custom code
+     * Flink Jar
      */
-    CUSTOM_CODE("Custom Code", 1),
+    FLINK_JAR("Flink JAR", 1),
 
     /**
      * Flink SQL

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/ResourceFromEnum.java
Patch:
@@ -24,8 +24,8 @@
 @Getter
 public enum ResourceFromEnum {
 
-    /** cicd(build from cvs) */
-    CICD(1),
+    /** build from cvs */
+    BUILD(1),
 
     /** upload local jar */
     UPLOAD(2);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/FlinkApplicationBackupServiceImpl.java
Patch:
@@ -89,7 +89,7 @@ public void rollback(FlinkApplicationBackup bakParam) {
         // If necessary, perform the backup first
         if (bakParam.isBackup()) {
             application.setBackUpDescription(bakParam.getDescription());
-            if (application.isFlinkSqlJobOrCDC()) {
+            if (application.isJobTypeFlinkSqlOrCDC()) {
                 FlinkSql flinkSql = flinkSqlService.getEffective(application.getId(), false);
                 backup(application, flinkSql);
             } else {
@@ -107,7 +107,7 @@ public void rollback(FlinkApplicationBackup bakParam) {
             effectiveService.saveOrUpdate(
                 bakParam.getAppId(), EffectiveTypeEnum.CONFIG, bakParam.getId());
             // if flink sql task, will be rollback sql and dependencies
-            if (application.isFlinkSqlJobOrCDC()) {
+            if (application.isJobTypeFlinkSqlOrCDC()) {
                 effectiveService.saveOrUpdate(
                     bakParam.getAppId(), EffectiveTypeEnum.FLINKSQL, bakParam.getSqlId());
             }
@@ -190,7 +190,7 @@ public Boolean removeById(Long id) throws InternalException {
     @Override
     public void backup(FlinkApplication appParam, FlinkSql flinkSqlParam) {
         // basic configuration file backup
-        String appHome = (appParam.isCustomCodeJob() && appParam.isCICDJob())
+        String appHome = (appParam.isJobTypeFlinkJar() && appParam.isResourceFromBuild())
             ? appParam.getDistHome()
             : appParam.getAppHome();
         FsOperator fsOperator = appParam.getFsOperator();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/FlinkApplicationConfigServiceImpl.java
Patch:
@@ -99,7 +99,7 @@ public void setLatest(Long appId, Long configId) {
     public synchronized void update(FlinkApplication appParam, Boolean latest) {
         // flink sql job
         FlinkApplicationConfig latestConfig = getLatest(appParam.getId());
-        if (appParam.isFlinkSqlJobOrCDC()) {
+        if (appParam.isJobTypeFlinkSqlOrCDC()) {
             updateForFlinkSqlJob(appParam, latest, latestConfig);
         } else {
             updateForNonFlinkSqlJob(appParam, latest, latestConfig);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationActionServiceImpl.java
Patch:
@@ -487,7 +487,7 @@ private Tuple2<String, String> getUserJarAndAppConf(
                 break;
 
             case SPARK_JAR:
-                if (application.isUploadJob()) {
+                if (application.isFromUploadJob()) {
                     appConf = applicationConfig == null
                         ? null
                         : String.format("yaml://%s", applicationConfig.getContent());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationBackupServiceImpl.java
Patch:
@@ -189,7 +189,7 @@ public Boolean removeById(Long id) throws InternalException {
     @Override
     public void backup(SparkApplication appParam, SparkSql sparkSqlParam) {
         // basic configuration file backup
-        String appHome = (appParam.isCICDJob())
+        String appHome = (appParam.isFromBuildJob())
             ? appParam.getDistHome()
             : appParam.getAppHome();
         FsOperator fsOperator = appParam.getFsOperator();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationBuildPipelineServiceImpl.java
Patch:
@@ -214,7 +214,7 @@ public void onStart(PipelineSnapshot snapshot) {
                         String appHome = app.getAppHome();
                         FsOperator fsOperator = app.getFsOperator();
                         fsOperator.delete(appHome);
-                        if (app.isUploadJob()) {
+                        if (app.isFromUploadJob()) {
                             String uploadJar = appUploads.concat("/").concat(app.getJar());
                             File localJar = new File(
                                 String.format(
@@ -244,7 +244,7 @@ public void onStart(PipelineSnapshot snapshot) {
                                     break;
                                 default:
                                     throw new IllegalArgumentException(
-                                        "[StreamPark] unsupported ApplicationType of custom code: "
+                                        "[StreamPark] unsupported ApplicationType of FlinkJar: "
                                             + app.getApplicationType());
                             }
                         } else {
@@ -453,7 +453,7 @@ private String retrieveSparkUserJar(SparkEnv sparkEnv, SparkApplication app) {
                         return String.format("%s/%s", app.getAppHome(), app.getJar());
                     default:
                         throw new IllegalArgumentException(
-                            "[StreamPark] unsupported ApplicationType of custom code: "
+                            "[StreamPark] unsupported ApplicationType of FlinkJar: "
                                 + app.getApplicationType());
                 }
             case PYSPARK:

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationManageServiceImpl.java
Patch:
@@ -280,7 +280,7 @@ public boolean create(SparkApplication appParam) {
                 appParam.setMainClass(Constants.STREAMPARK_SPARKSQL_CLIENT_CLASS);
             }
         }
-        if (appParam.isUploadJob()) {
+        if (appParam.isFromUploadJob()) {
             String jarPath = String.format(
                 "%s/%d/%s", Workspace.local().APP_UPLOADS(), appParam.getTeamId(), appParam.getJar());
             if (!new File(jarPath).exists()) {
@@ -412,7 +412,7 @@ public boolean update(SparkApplication appParam) {
         application.setRelease(ReleaseStateEnum.NEED_RELEASE.get());
 
         // 1) jar job jar file changed
-        if (application.isUploadJob()) {
+        if (application.isFromUploadJob()) {
             if (!Objects.equals(application.getJar(), appParam.getJar())) {
                 application.setBuild(true);
             } else {
@@ -640,7 +640,7 @@ public SparkApplication getApp(Long id) {
             }
             sparkSql.setToApplication(application);
         } else {
-            if (application.isCICDJob()) {
+            if (application.isFromBuildJob()) {
                 String path = this.projectService.getAppConfPath(application.getProjectId(), application.getModule());
                 application.setConfPath(path);
             }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkSavepointServiceImpl.java
Patch:
@@ -342,7 +342,7 @@ public String getSavepointFromDynamicProps(String dynamicProps) {
     @VisibleForTesting
     @Nullable
     public String getSavepointFromConfig(FlinkApplication application) {
-        if (!application.isStreamParkJob() && !application.isFlinkSqlJobOrCDC()) {
+        if (!application.isAppTypeStreamPark() && !application.isJobTypeFlinkSqlOrCDC()) {
             return null;
         }
         FlinkApplicationConfig applicationConfig = configService.getEffective(application.getId());

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/FlinkSavepointServiceTest.java
Patch:
@@ -104,14 +104,14 @@ void testGetSavepointFromAppCfgIfStreamParkOrSQLJob() {
         app.setAppType(ApplicationType.APACHE_FLINK.getType());
         assertThat(savepointServiceImpl.getSavepointFromConfig(app)).isNull();
         app.setAppType(ApplicationType.STREAMPARK_FLINK.getType());
-        app.setJobType(FlinkJobType.CUSTOM_CODE.getMode());
+        app.setJobType(FlinkJobType.FLINK_JAR.getMode());
         assertThat(savepointServiceImpl.getSavepointFromConfig(app)).isNull();
 
         // Test for (StreamPark job Or FlinkSQL job) without application config.
         app.setAppType(ApplicationType.STREAMPARK_FLINK.getType());
         assertThat(savepointServiceImpl.getSavepointFromConfig(app)).isNull();
         app.setAppType(ApplicationType.STREAMPARK_FLINK.getType());
-        app.setJobType(FlinkJobType.CUSTOM_CODE.getMode());
+        app.setJobType(FlinkJobType.FLINK_JAR.getMode());
         assertThat(savepointServiceImpl.getSavepointFromConfig(app)).isNull();
 
         // Test for (StreamPark job Or FlinkSQL job) with application config just disabled checkpoint.

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/flink/applications/ApplicationForm.java
Patch:
@@ -96,9 +96,9 @@ public ApplicationForm addApplication(FlinkJobType jobType,
         new WebDriverWait(driver, Constants.DEFAULT_WEBDRIVER_WAIT_DURATION)
             .until(ExpectedConditions.visibilityOfAllElements(selectJobType));
         switch (jobType) {
-            case CUSTOM_CODE:
+            case FLINK_JAR:
                 selectJobType.stream()
-                    .filter(e -> e.getText().equalsIgnoreCase(FlinkJobType.CUSTOM_CODE.desc))
+                    .filter(e -> e.getText().equalsIgnoreCase(FlinkJobType.FLINK_JAR.desc))
                     .findFirst()
                     .orElseThrow(
                         () -> new IllegalArgumentException(
@@ -250,7 +250,7 @@ public ApplicationForm submit() {
     @Getter
     public enum FlinkJobType {
 
-        CUSTOM_CODE("custom code"),
+        FLINK_JAR("flink jar"),
         FLINK_SQL("flink sql"),
         PYTHON_FLINK("python flink");
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/FlinkApplicationBackupServiceImpl.java
Patch:
@@ -89,7 +89,7 @@ public void rollback(FlinkApplicationBackup bakParam) {
         // If necessary, perform the backup first
         if (bakParam.isBackup()) {
             application.setBackUpDescription(bakParam.getDescription());
-            if (application.isFlinkSqlJob()) {
+            if (application.isFlinkSqlJobOrCDC()) {
                 FlinkSql flinkSql = flinkSqlService.getEffective(application.getId(), false);
                 backup(application, flinkSql);
             } else {
@@ -107,7 +107,7 @@ public void rollback(FlinkApplicationBackup bakParam) {
             effectiveService.saveOrUpdate(
                 bakParam.getAppId(), EffectiveTypeEnum.CONFIG, bakParam.getId());
             // if flink sql task, will be rollback sql and dependencies
-            if (application.isFlinkSqlJob()) {
+            if (application.isFlinkSqlJobOrCDC()) {
                 effectiveService.saveOrUpdate(
                     bakParam.getAppId(), EffectiveTypeEnum.FLINKSQL, bakParam.getSqlId());
             }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/MybatisConfig.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.base.config;
 
+import org.apache.streampark.console.base.mybatis.interceptor.PaginationInterceptor;
 import org.apache.streampark.console.base.mybatis.interceptor.PostgreSQLPrepareInterceptor;
 import org.apache.streampark.console.base.mybatis.interceptor.PostgreSQLQueryInterceptor;
 
@@ -30,7 +31,6 @@
 import com.baomidou.mybatisplus.core.config.GlobalConfig;
 import com.baomidou.mybatisplus.core.toolkit.GlobalConfigUtils;
 import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;
-import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;
 import org.mybatis.spring.annotation.MapperScan;
 import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
 import org.springframework.context.annotation.Bean;
@@ -46,7 +46,7 @@ public class MybatisConfig {
     @Bean
     public MybatisPlusInterceptor mybatisPlusInterceptor() {
         MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();
-        interceptor.addInnerInterceptor(new PaginationInnerInterceptor());
+        interceptor.addInnerInterceptor(new PaginationInterceptor());
         return interceptor;
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ResourceMapper.java
Patch:
@@ -28,6 +28,4 @@
 public interface ResourceMapper extends BaseMapper<Resource> {
 
     IPage<Resource> selectPage(Page<Resource> page, @Param("resource") Resource resource);
-
-    boolean existsByUserId(@Param("userId") Long userId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -210,9 +210,9 @@ public List<FlinkSql> listByTeamId(Long teamId) {
 
     @Override
     public IPage<FlinkSql> getPage(Long appId, RestRequest request) {
-        request.setSortField("version");
         Page<FlinkSql> page = MybatisPager.getPage(request);
-        IPage<FlinkSql> sqlList = this.lambdaQuery().eq(FlinkSql::getAppId, appId).page(page);
+        IPage<FlinkSql> sqlList = this.lambdaQuery().eq(FlinkSql::getAppId, appId)
+            .orderByDesc(FlinkSql::getVersion).page(page);
         FlinkSql effectiveSql = baseMapper.getEffective(appId);
         if (effectiveSql != null) {
             for (FlinkSql sql : sqlList.getRecords()) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -123,7 +123,8 @@ public IPage<Resource> getPage(Resource resource, RestRequest request) {
      */
     @Override
     public boolean existsByUserId(Long userId) {
-        return this.baseMapper.existsByUserId(userId);
+        return this.lambdaQuery().eq(Resource::getCreatorId, userId)
+            .exists();
     }
 
     @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SparkSqlServiceImpl.java
Patch:
@@ -209,9 +209,9 @@ public List<SparkSql> listByTeamId(Long teamId) {
 
     @Override
     public IPage<SparkSql> getPage(Long appId, RestRequest request) {
-        request.setSortField("version");
         Page<SparkSql> page = MybatisPager.getPage(request);
-        IPage<SparkSql> sqlList = this.lambdaQuery().eq(SparkSql::getAppId, appId).page(page);
+        IPage<SparkSql> sqlList = this.lambdaQuery().eq(SparkSql::getAppId, appId)
+            .orderByDesc(SparkSql::getVersion).page(page);
         SparkSql effectiveSql = baseMapper.getEffective(appId);
         if (effectiveSql != null) {
             for (SparkSql sql : sqlList.getRecords()) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/MemberServiceImpl.java
Patch:
@@ -58,13 +58,13 @@ public class MemberServiceImpl extends ServiceImpl<MemberMapper, Member> impleme
     @Override
     @Transactional
     public void removeByRoleIds(String[] roleIds) {
-        Arrays.stream(roleIds).forEach(id -> baseMapper.deleteByRoleId(Long.valueOf(id)));
+        this.lambdaUpdate().in(Member::getRoleId, Arrays.asList(roleIds)).remove();
     }
 
     @Override
     @Transactional
     public void removeByUserId(Long userId) {
-        baseMapper.deleteByUserId(userId);
+        this.lambdaUpdate().eq(Member::getUserId, userId).remove();
     }
 
     @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/RoleServiceImpl.java
Patch:
@@ -63,7 +63,9 @@ public class RoleServiceImpl extends ServiceImpl<RoleMapper, Role> implements Ro
     @Override
     public IPage<Role> getPage(Role role, RestRequest request) {
         Page<Role> page = MybatisPager.getPage(request);
-        return this.baseMapper.selectPage(page, role);
+        return this.lambdaQuery()
+            .like(StringUtils.isNotBlank(role.getRoleName()), Role::getRoleName, role.getRoleName())
+            .page(page);
     }
 
     @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/NoticeTypeEnum.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.streampark.console.core.enums;
 
+import com.baomidou.mybatisplus.annotation.EnumValue;
+
 import java.util.Arrays;
 
 /** notification type */
@@ -27,6 +29,7 @@ public enum NoticeTypeEnum {
     /** message */
     MESSAGE(2);
 
+    @EnumValue
     private final int value;
 
     public int get() {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/AlertConfigMapper.java
Patch:
@@ -19,11 +19,8 @@
 
 import org.apache.streampark.console.core.entity.AlertConfig;
 
-import org.apache.ibatis.annotations.Param;
-
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;
 
 public interface AlertConfigMapper extends BaseMapper<AlertConfig> {
 
-    AlertConfig selectAlertConfByName(@Param("alertConfig") AlertConfig alertConfig);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/runner/EnvInitializer.java
Patch:
@@ -116,8 +116,7 @@ private void initConfig() {
     }
 
     private void initRegistryService() {
-        boolean enable = SystemPropertyUtils.get("high-availability.enable", "false").equals("true");
-        if (enable) {
+        if (WebUtils.isHaEnable()) {
             RegistryService registryService = SpringContextUtils.getBean(RegistryService.class);
             registryService.registry();
             Runtime.getRuntime().addShutdownHook(new Thread(() -> {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/DistributedTaskService.java
Patch:
@@ -61,7 +61,7 @@ public interface DistributedTaskService extends IService<DistributedTask> {
      * @param appId Long
      * @return boolean
      */
-    public boolean isLocalProcessing(Long appId);
+    boolean isLocalProcessing(Long appId);
 
     /**
      * Save Distributed Task.
@@ -70,5 +70,5 @@ public interface DistributedTaskService extends IService<DistributedTask> {
      * @param autoStart boolean
      * @param action It may be one of the following values: START, RESTART, REVOKE, CANCEL, ABORT
      */
-    public void saveDistributedTask(BaseEntity appParam, boolean autoStart, DistributedTaskEnum action);
+    void saveDistributedTask(BaseEntity appParam, boolean autoStart, DistributedTaskEnum action);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -138,8 +138,7 @@ public FlinkEnv getByAppId(Long appId) {
 
     @Override
     public FlinkEnv getDefault() {
-        return this.baseMapper.selectOne(
-            new LambdaQueryWrapper<FlinkEnv>().eq(FlinkEnv::getIsDefault, true));
+        return this.lambdaQuery().eq(FlinkEnv::getIsDefault, true).one();
     }
 
     @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/RegistryServiceImpl.java
Patch:
@@ -53,7 +53,8 @@ public class RegistryServiceImpl implements RegistryService {
     private String zkAddress;
     private ZooKeeper zk;
     private String nodePath;
-    private Watcher watcher = event -> {
+
+    private final Watcher watcher = event -> {
         if (event.getType() == Watcher.Event.EventType.NodeChildrenChanged
             && event.getPath().equals(REGISTRY_PATH)) {
             handleNodeChanges();
@@ -72,7 +73,6 @@ public void registry() {
         try {
             zkAddress = SystemPropertyUtils.get("high-availability.zookeeper.quorum", "localhost:2181");
             zk = new ZooKeeper(zkAddress, HEARTBEAT_TIMEOUT, watcher);
-
             if (zk.exists(REGISTRY_PATH, false) == null) {
                 zk.create(REGISTRY_PATH, new byte[0], OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
             }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -241,8 +241,7 @@ public void remove(Long id) {
     }
 
     public List<Resource> listByTeamId(Long teamId) {
-        LambdaQueryWrapper<Resource> queryWrapper = new LambdaQueryWrapper<Resource>().eq(Resource::getTeamId, teamId);
-        return baseMapper.selectList(queryWrapper);
+        return this.lambdaQuery().eq(Resource::getTeamId, teamId).list();
     }
 
     /**

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/MenuServiceImpl.java
Patch:
@@ -78,9 +78,8 @@ public List<Menu> listMenus(Long userId, Long teamId) {
                     String.format("The userId:[%s] not found", userId)));
         // Admin has the permission for all menus.
         if (UserTypeEnum.ADMIN == user.getUserType()) {
-            LambdaQueryWrapper<Menu> queryWrapper = new LambdaQueryWrapper<Menu>().eq(Menu::getType, "0")
-                .orderByAsc(Menu::getOrderNum);
-            return this.list(queryWrapper);
+            return this.lambdaQuery().eq(Menu::getType, "0")
+                .orderByAsc(Menu::getOrderNum).list();
         }
         return this.baseMapper.selectMenus(userId, teamId);
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -497,7 +497,7 @@ private List<FlinkApplication> getResourceApplicationsById(Resource resource) {
         for (FlinkSql flinkSql : flinkSqls) {
             String sqlTeamResource = flinkSql.getTeamResource();
             if (sqlTeamResource != null
-                && sqlTeamResource.contains(String.valueOf(resource.getTeamId()))) {
+                && sqlTeamResource.contains(String.valueOf(resource.getId()))) {
                 FlinkApplication app = applicationMap.get(flinkSql.getAppId());
                 if (!dependApplications.contains(app)) {
                     dependApplications.add(applicationMap.get(flinkSql.getAppId()));

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Resource.java
Patch:
@@ -83,7 +83,7 @@ public void setResourcePath(String resourcePath) {
         if (StringUtils.isBlank(resourcePath)) {
             throw new IllegalArgumentException("resource path cannot be null.");
         }
-        String[] namePath = resourcePath.split(":");
+        String[] namePath = resourcePath.split(":", 2);
         if (namePath.length != 2) {
             throw new IllegalArgumentException("resource path invalid, format: $name:$path");
         }
@@ -101,6 +101,6 @@ public String getFilePath() {
         if (StringUtils.isBlank(this.resourcePath)) {
             return null;
         }
-        return resourcePath.split(":")[1];
+        return resourcePath.split(":", 2)[1];
     }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -153,7 +153,7 @@ public void addResource(Resource resource) throws Exception {
             String resourcePath = jars.get(0);
             resource.setResourcePath(resourcePath);
             // copy jar to team upload directory
-            String upFile = resourcePath.split(":")[1];
+            String upFile = resourcePath.split(":", 2)[1];
             transferTeamResource(resource.getTeamId(), upFile);
         }
 
@@ -207,7 +207,7 @@ public void updateResource(Resource resource) {
 
             Dependency dependency = Dependency.toDependency(resource.getResource());
             if (!dependency.getJar().isEmpty()) {
-                String jarFile = dependency.getJar().get(0).split(":")[1];
+                String jarFile = dependency.getJar().get(0).split(":", 2)[1];
                 transferTeamResource(findResource.getTeamId(), jarFile);
             }
         }
@@ -446,7 +446,7 @@ private File getResourceJar(Resource resource) throws Exception {
             return null;
         }
         if (!dependency.getJar().isEmpty()) {
-            String jar = dependency.getJar().get(0).split(":")[1];
+            String jar = dependency.getJar().get(0).split(":", 2)[1];
             return new File(jar);
         } else {
             Artifact artifact = dependency.toArtifact().get(0);

File: streampark-common/src/main/java/org/apache/streampark/common/enums/CatalogType.java
Patch:
@@ -19,6 +19,9 @@
 
 /** catalog type */
 public enum CatalogType {
+    MYSQL,
+    PGSQL,
+    ORACLE,
     JDBC,
     HIVE,
     PAIMON,

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/util/WebUtils.java
Patch:
@@ -87,4 +87,7 @@ public static File getAppClientDir() {
         return getAppDir(CLIENT);
     }
 
+    public static File getPluginDir() {
+        return getAppDir(PLUGINS);
+    }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/FlinkCatalogMapper.java
Patch:
@@ -30,5 +30,7 @@ public interface FlinkCatalogMapper extends BaseMapper<FlinkCatalog> {
 
     boolean existsByCatalogName(@Param("catalogName") String catalogName);
 
+    FlinkCatalog selectByCatalogName(@Param("catalogName") String catalogName);
+
     IPage<FlinkCatalog> selectPage(Page<FlinkCatalog> page, @Param("catalog") FlinkCatalog catalog);
 }

File: streampark-flink/streampark-flink-kubernetes/src/main/java/org/apache/flink/kubernetes/kubeclient/resources/CompKubernetesDeployment.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.flink.kubernetes.kubeclient.resources;
 
-import io.fabric8.kubernetes.api.model.apps.Deployment;
+import org.apache.flink.kubernetes.shaded.io.fabric8.kubernetes.api.model.apps.Deployment;
 
 public class CompKubernetesDeployment extends KubernetesResource<Deployment> {
 

File: streampark-flink/streampark-flink-kubernetes/src/main/java/org/apache/flink/kubernetes/kubeclient/resources/CompatibleKubernetesWatcher.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.flink.kubernetes.kubeclient.resources;
 
-import io.fabric8.kubernetes.api.model.HasMetadata;
+import org.apache.flink.kubernetes.shaded.io.fabric8.kubernetes.api.model.HasMetadata;
 
 /** Compatible AbstractKubernetesWatcher for fabric8. */
 public abstract class CompatibleKubernetesWatcher<T extends HasMetadata, K extends KubernetesResource<T>>

File: streampark-common/src/main/java/org/apache/streampark/common/enums/FlinkJobType.java
Patch:
@@ -52,9 +52,9 @@ public enum FlinkJobType {
      */
     @Nonnull
     public static FlinkJobType of(@Nullable Integer value) {
-        for (FlinkJobType flinkDevelopmentMode : values()) {
-            if (flinkDevelopmentMode.mode.equals(value)) {
-                return flinkDevelopmentMode;
+        for (FlinkJobType flinkJobType : values()) {
+            if (flinkJobType.mode.equals(value)) {
+                return flinkJobType;
             }
         }
         return FlinkJobType.UNKNOWN;

File: streampark-common/src/main/java/org/apache/streampark/common/enums/SparkJobType.java
Patch:
@@ -52,9 +52,9 @@ public enum SparkJobType {
      */
     @Nonnull
     public static SparkJobType valueOf(@Nullable Integer value) {
-        for (SparkJobType sparkDevelopmentMode : values()) {
-            if (sparkDevelopmentMode.mode.equals(value)) {
-                return sparkDevelopmentMode;
+        for (SparkJobType sparkJobType : values()) {
+            if (sparkJobType.mode.equals(value)) {
+                return sparkJobType;
             }
         }
         return SparkJobType.UNKNOWN;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/bean/AppControl.java
Patch:
@@ -32,4 +32,6 @@ public class AppControl {
 
     /** allow to build the application */
     private boolean allowBuild;
+
+    private boolean allowView;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkBuildPipelineController.java
Patch:
@@ -42,7 +42,7 @@
 @Validated
 @RestController
 @RequestMapping("flink/pipe")
-public class FlinkApplicationBuildPipelineController {
+public class FlinkBuildPipelineController {
 
     @Autowired
     private AppBuildPipeService appBuildPipeService;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/SparkBuildPipelineController.java
Patch:
@@ -39,7 +39,7 @@
 @Validated
 @RestController
 @RequestMapping("spark/pipe")
-public class SparkApplicationBuildPipelineController {
+public class SparkBuildPipelineController {
 
     @Autowired
     private SparkAppBuildPipeService appBuildPipeService;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/FlinkApplicationBackUp.java
Patch:
@@ -62,7 +62,7 @@ public FlinkApplicationBackUp(FlinkApplication application) {
     }
 
     private void renderPath(FlinkApplication application) {
-        switch (application.getFlinkDeployMode()) {
+        switch (application.getDeployModeEnum()) {
             case KUBERNETES_NATIVE_APPLICATION:
             case KUBERNETES_NATIVE_SESSION:
             case YARN_PER_JOB:
@@ -80,7 +80,7 @@ private void renderPath(FlinkApplication application) {
                 break;
             default:
                 throw new UnsupportedOperationException(
-                    "unsupported deployMode ".concat(application.getFlinkDeployMode().getName()));
+                    "unsupported deployMode ".concat(application.getDeployModeEnum().getName()));
         }
     }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/SparkApplicationBackUp.java
Patch:
@@ -64,7 +64,7 @@ public SparkApplicationBackUp(SparkApplication application) {
     }
 
     private void renderPath(SparkApplication application) {
-        switch (application.getSparkDeployMode()) {
+        switch (application.getDeployModeEnum()) {
             case LOCAL:
                 this.path = String.format(
                     "%s/%d/%d",
@@ -78,7 +78,7 @@ private void renderPath(SparkApplication application) {
                 break;
             default:
                 throw new UnsupportedOperationException(
-                    "unsupported deployMode ".concat(application.getSparkDeployMode().getName()));
+                    "unsupported deployMode ".concat(application.getDeployModeEnum().getName()));
         }
     }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/SparkOperationEnum.java
Patch:
@@ -25,7 +25,7 @@
 @Getter
 public enum SparkOperationEnum {
 
-    RELEASE(0), START(1), STOP(2);
+    RELEASE(0), START(1), CANCEL(2);
 
     private final int value;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ProxyService.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.streampark.console.core.entity.ApplicationLog;
 import org.apache.streampark.console.core.entity.FlinkApplication;
-import org.apache.streampark.console.core.entity.SparkApplicationLog;
+import org.apache.streampark.console.core.entity.SparkApplication;
 
 import org.springframework.http.ResponseEntity;
 
@@ -29,11 +29,11 @@ public interface ProxyService {
 
     ResponseEntity<?> proxyFlink(HttpServletRequest request, FlinkApplication app) throws Exception;
 
-    ResponseEntity<?> proxyYarn(HttpServletRequest request, SparkApplicationLog log) throws Exception;
+    ResponseEntity<?> proxySpark(HttpServletRequest request, SparkApplication app) throws Exception;
 
     ResponseEntity<?> proxyYarn(HttpServletRequest request, ApplicationLog log) throws Exception;
 
     ResponseEntity<?> proxyHistory(HttpServletRequest request, ApplicationLog log) throws Exception;
 
-    ResponseEntity<?> proxyCluster(HttpServletRequest request, Long clusterId) throws Exception;
+    ResponseEntity<?> proxyFlinkCluster(HttpServletRequest request, Long clusterId) throws Exception;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/SparkApplicationActionService.java
Patch:
@@ -59,7 +59,7 @@ public interface SparkApplicationActionService extends IService<SparkApplication
      * @param appParam the application to be stopped
      * @throws Exception if stop fails
      */
-    void stop(SparkApplication appParam) throws Exception;
+    void cancel(SparkApplication appParam) throws Exception;
 
     /**
      * Forces the given application to stop.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/FlinkApplicationInfoServiceImpl.java
Patch:
@@ -222,8 +222,8 @@ public boolean checkEnv(FlinkApplication appParam) throws ApplicationException {
             envInitializer.checkFlinkEnv(application.getStorageType(), flinkEnv);
             envInitializer.storageInitialize(application.getStorageType());
 
-            if (FlinkDeployMode.YARN_SESSION == application.getFlinkDeployMode()
-                || FlinkDeployMode.REMOTE == application.getFlinkDeployMode()) {
+            if (FlinkDeployMode.YARN_SESSION == application.getDeployModeEnum()
+                || FlinkDeployMode.REMOTE == application.getDeployModeEnum()) {
                 FlinkCluster flinkCluster = flinkClusterService.getById(application.getFlinkClusterId());
                 boolean conned = flinkClusterWatcher.verifyClusterConnection(flinkCluster);
                 if (!conned) {
@@ -370,7 +370,7 @@ public String k8sStartLog(Long id, Integer offset, Integer limit) throws Excepti
         ApiAlertException.throwIfNull(
             application, String.format("The application id=%s can't be found.", id));
         ApiAlertException.throwIfFalse(
-            FlinkDeployMode.isKubernetesMode(application.getFlinkDeployMode()),
+            FlinkDeployMode.isKubernetesMode(application.getDeployModeEnum()),
             "Job deployMode must be kubernetes-session|kubernetes-application.");
 
         CompletableFuture<String> future = CompletableFuture.supplyAsync(

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/DistributedTaskServiceImpl.java
Patch:
@@ -159,8 +159,8 @@ public void executeDistributedTask(DistributedTask distributedTask) throws Excep
                 case REVOKE:
                     sparkApplicationActionService.revoke(appParam.getId());
                     break;
-                case STOP:
-                    sparkApplicationActionService.stop(appParam);
+                case CANCEL:
+                    sparkApplicationActionService.cancel(appParam);
                     break;
                 case FORCED_STOP:
                     sparkApplicationActionService.forcedStop(appParam.getId());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/utils/AlertTemplateUtils.java
Patch:
@@ -44,7 +44,7 @@ public static AlertTemplate createAlertTemplate(FlinkApplication application, Fl
         return AlertTemplate.builder()
             .duration(application.getStartTime(), application.getEndTime())
             .jobName(application.getJobName())
-            .link(application.getFlinkDeployMode(), application.getClusterId())
+            .link(application.getDeployModeEnum(), application.getClusterId())
             .startTime(application.getStartTime())
             .endTime(application.getEndTime())
             .restart(application.isNeedRestartOnFailed(), application.getRestartCount())
@@ -66,7 +66,7 @@ public static AlertTemplate createAlertTemplate(FlinkApplication application, Ch
         return AlertTemplate.builder()
             .duration(application.getStartTime(), application.getEndTime())
             .jobName(application.getJobName())
-            .link(application.getFlinkDeployMode(), application.getClusterId())
+            .link(application.getDeployModeEnum(), application.getClusterId())
             .startTime(application.getStartTime())
             .type(AlertTypeEnum.DING_TALK.getCode())
             .cpFailureRateInterval(
@@ -120,7 +120,7 @@ public static AlertTemplate createAlertTemplate(SparkApplication application, Sp
         return AlertTemplate.builder()
             .duration(application.getStartTime(), application.getEndTime())
             .jobName(application.getAppName())
-            .link(application.getSparkDeployMode(), application.getAppId())
+            .link(application.getDeployModeEnum(), application.getClusterId())
             .startTime(application.getStartTime())
             .endTime(application.getEndTime())
             .restart(application.isNeedRestartOnFailed(), application.getRestartCount())

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/FlinkSQL116OnYarnTest.java
Patch:
@@ -87,7 +87,7 @@ void testCreateFlinkApplicationOnYarnApplicationMode() {
         applicationsPage
             .createApplication()
             .addApplication(
-                ApplicationForm.DevelopmentMode.FLINK_SQL,
+                ApplicationForm.FlinkJobType.FLINK_SQL,
                 ApplicationForm.DeployMode.YARN_APPLICATION,
                 applicationName)
             .flinkVersion(flinkName)
@@ -189,7 +189,7 @@ void testCreateFlinkApplicationOnYarnPerJobMode() {
         applicationsPage
             .createApplication()
             .addApplication(
-                ApplicationForm.DevelopmentMode.FLINK_SQL,
+                ApplicationForm.FlinkJobType.FLINK_SQL,
                 ApplicationForm.DeployMode.YARN_PER_JOB,
                 applicationName)
             .flinkVersion(flinkName)
@@ -265,7 +265,7 @@ void testCreateFlinkApplicationOnYarnSessionMode() {
 
         applicationsPage.createApplication()
             .addApplication(
-                ApplicationForm.DevelopmentMode.FLINK_SQL,
+                ApplicationForm.FlinkJobType.FLINK_SQL,
                 ApplicationForm.DeployMode.YARN_SESSION,
                 applicationName)
             .flinkVersion(flinkName)

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/FlinkSQL117OnYarnTest.java
Patch:
@@ -86,7 +86,7 @@ void testCreateFlinkApplicationOnYarnApplicationMode() {
         applicationsPage
             .createApplication()
             .addApplication(
-                ApplicationForm.DevelopmentMode.FLINK_SQL,
+                ApplicationForm.FlinkJobType.FLINK_SQL,
                 ApplicationForm.DeployMode.YARN_APPLICATION,
                 applicationName)
             .flinkVersion(flinkName)
@@ -189,7 +189,7 @@ void testCreateFlinkApplicationOnYarnPerJobMode() {
         applicationsPage
             .createApplication()
             .addApplication(
-                ApplicationForm.DevelopmentMode.FLINK_SQL,
+                ApplicationForm.FlinkJobType.FLINK_SQL,
                 ApplicationForm.DeployMode.YARN_PER_JOB,
                 applicationName)
             .flinkVersion(flinkName)
@@ -266,7 +266,7 @@ void testCreateFlinkApplicationOnYarnSessionMode() {
         applicationsPage
             .createApplication()
             .addApplication(
-                ApplicationForm.DevelopmentMode.FLINK_SQL,
+                ApplicationForm.FlinkJobType.FLINK_SQL,
                 ApplicationForm.DeployMode.YARN_SESSION,
                 applicationName)
             .flinkVersion(flinkName)

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/FlinkSQL118OnYarnTest.java
Patch:
@@ -86,7 +86,7 @@ void testCreateFlinkApplicationOnYarnApplicationMode() {
         applicationsPage
             .createApplication()
             .addApplication(
-                ApplicationForm.DevelopmentMode.FLINK_SQL,
+                ApplicationForm.FlinkJobType.FLINK_SQL,
                 ApplicationForm.DeployMode.YARN_APPLICATION,
                 applicationName)
             .flinkVersion(flinkName)
@@ -189,7 +189,7 @@ void testCreateFlinkApplicationOnYarnPerJobMode() {
         applicationsPage
             .createApplication()
             .addApplication(
-                ApplicationForm.DevelopmentMode.FLINK_SQL,
+                ApplicationForm.FlinkJobType.FLINK_SQL,
                 ApplicationForm.DeployMode.YARN_PER_JOB,
                 applicationName)
             .flinkVersion(flinkName)
@@ -292,7 +292,7 @@ void testCreateFlinkApplicationOnYarnSessionMode() {
         applicationsPage
             .createApplication()
             .addApplication(
-                ApplicationForm.DevelopmentMode.FLINK_SQL,
+                ApplicationForm.FlinkJobType.FLINK_SQL,
                 ApplicationForm.DeployMode.YARN_SESSION,
                 applicationName)
             .flinkVersion(flinkName)

File: streampark-flink/streampark-flink-packer/src/main/java/org/apache/streampark/flink/packer/pipeline/PipelineTypeEnum.java
Patch:
@@ -81,9 +81,9 @@ public enum PipelineTypeEnum {
             .build(),
         K8sAppModeBuildResponse.class),
 
-    SPARK_YARN_APPLICATION(
+    SPARK_CLUSTER(
         6,
-        "spark yarn application mode task building pipeline",
+        "spark yarn cluster mode task building pipeline",
         ImmutableMap.<Integer, String>builder()
             .put(1, "Prepare hadoop yarn environment and building workspace")
             .put(2, "Resolve maven dependencies")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationActionServiceImpl.java
Patch:
@@ -80,7 +80,6 @@
 import org.springframework.stereotype.Service;
 
 import java.io.File;
-import java.util.Arrays;
 import java.util.Date;
 import java.util.EnumSet;
 import java.util.HashMap;
@@ -310,7 +309,6 @@ public void start(SparkApplication appParam, boolean auto) throws Exception {
 
         // Get the args after placeholder replacement
         String applicationArgs = variableService.replaceVariable(application.getTeamId(), application.getAppArgs());
-        List<String> sparkArgs = Arrays.asList(applicationArgs.split("\\s+"));
 
         SubmitRequest submitRequest = new SubmitRequest(
             sparkEnv.getSparkVersion(),
@@ -322,7 +320,7 @@ public void start(SparkApplication appParam, boolean auto) throws Exception {
             application.getMainClass(),
             appConf,
             PropertiesUtils.extractSparkPropertiesAsJava(application.getAppProperties()),
-            sparkArgs,
+            PropertiesUtils.extractSparkArgumentsAsJava(applicationArgs),
             application.getApplicationType(),
             application.getHadoopUser(),
             buildResult,

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkSqlController.java
Patch:
@@ -22,7 +22,7 @@
 import org.apache.streampark.console.base.exception.ApiAlertException;
 import org.apache.streampark.console.base.exception.InternalException;
 import org.apache.streampark.console.core.annotation.Permission;
-import org.apache.streampark.console.core.entity.Application;
+import org.apache.streampark.console.core.entity.FlinkApplication;
 import org.apache.streampark.console.core.entity.FlinkSql;
 import org.apache.streampark.console.core.service.FlinkSqlService;
 import org.apache.streampark.console.core.service.SqlCompleteService;
@@ -119,7 +119,7 @@ public RestResponse get(Long appId, Long teamId, String id) throws InternalExcep
 
     @PostMapping("history")
     @Permission(app = "#app.id", team = "#app.teamId")
-    public RestResponse history(Application app) {
+    public RestResponse history(FlinkApplication app) {
         List<FlinkSql> sqlList = flinkSqlService.listFlinkSqlHistory(app.getId());
         return RestResponse.success(sqlList);
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/SparkSqlController.java
Patch:
@@ -22,7 +22,7 @@
 import org.apache.streampark.console.base.exception.ApiAlertException;
 import org.apache.streampark.console.base.exception.InternalException;
 import org.apache.streampark.console.core.annotation.Permission;
-import org.apache.streampark.console.core.entity.Application;
+import org.apache.streampark.console.core.entity.FlinkApplication;
 import org.apache.streampark.console.core.entity.SparkSql;
 import org.apache.streampark.console.core.service.SparkSqlService;
 import org.apache.streampark.console.core.service.SqlCompleteService;
@@ -119,7 +119,7 @@ public RestResponse get(Long appId, Long teamId, String id) throws InternalExcep
 
     @PostMapping("history")
     @Permission(app = "#app.id", team = "#app.teamId")
-    public RestResponse history(Application app) {
+    public RestResponse history(FlinkApplication app) {
         List<SparkSql> sqlList = sparkSqlService.listSparkSqlHistory(app.getId());
         return RestResponse.success(sqlList);
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/VariableController.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.domain.RestResponse;
-import org.apache.streampark.console.core.entity.Application;
+import org.apache.streampark.console.core.entity.FlinkApplication;
 import org.apache.streampark.console.core.entity.Variable;
 import org.apache.streampark.console.core.service.VariableService;
 
@@ -86,7 +86,7 @@ public RestResponse variableList(@RequestParam Long teamId, String keyword) {
     @PostMapping("depend_apps")
     @RequiresPermissions("variable:depend_apps")
     public RestResponse dependApps(RestRequest restRequest, Variable variable) {
-        IPage<Application> dependApps = variableService.getDependAppsPage(variable, restRequest);
+        IPage<FlinkApplication> dependApps = variableService.getDependAppsPage(variable, restRequest);
         return RestResponse.success(dependApps);
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/FlinkSavepoint.java
Patch:
@@ -28,7 +28,7 @@
 @Data
 @TableName("t_flink_savepoint")
 @Slf4j
-public class Savepoint {
+public class FlinkSavepoint {
 
     @TableId(type = IdType.AUTO)
     private Long id;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/FlinkSql.java
Patch:
@@ -66,7 +66,7 @@ public class FlinkSql {
     public FlinkSql() {
     }
 
-    public FlinkSql(Application application) {
+    public FlinkSql(FlinkApplication application) {
         this.appId = application.getId();
         this.sql = application.getFlinkSql();
         this.teamResource = application.getTeamResource();
@@ -86,7 +86,7 @@ public void decode() {
         this.setSql(DeflaterUtils.unzipString(this.sql));
     }
 
-    public void setToApplication(Application application) {
+    public void setToApplication(FlinkApplication application) {
         String encode = Base64.getEncoder().encodeToString(this.sql.getBytes());
         application.setFlinkSql(encode);
         application.setDependency(this.dependency);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/SparkApplicationBackUp.java
Patch:
@@ -64,7 +64,7 @@ public SparkApplicationBackUp(SparkApplication application) {
     }
 
     private void renderPath(SparkApplication application) {
-        switch (application.getSparkExecutionMode()) {
+        switch (application.getSparkDeployMode()) {
             case LOCAL:
                 this.path = String.format(
                     "%s/%d/%d",
@@ -78,7 +78,7 @@ private void renderPath(SparkApplication application) {
                 break;
             default:
                 throw new UnsupportedOperationException(
-                    "unsupported executionMode ".concat(application.getSparkExecutionMode().getName()));
+                    "unsupported deployMode ".concat(application.getSparkDeployMode().getName()));
         }
     }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/SparkApplicationConfig.java
Patch:
@@ -28,7 +28,8 @@
 import com.baomidou.mybatisplus.annotation.TableName;
 import lombok.Data;
 import lombok.extern.slf4j.Slf4j;
-import org.jetbrains.annotations.Nullable;
+
+import javax.annotation.Nullable;
 
 import java.util.Base64;
 import java.util.Date;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/FlinkApplicationBackUpMapper.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.streampark.console.core.mapper;
 
-import org.apache.streampark.console.core.entity.ApplicationBackUp;
+import org.apache.streampark.console.core.entity.FlinkApplicationBackUp;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;
 
-public interface ApplicationBackUpMapper extends BaseMapper<ApplicationBackUp> {
+public interface FlinkApplicationBackUpMapper extends BaseMapper<FlinkApplicationBackUp> {
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/FlinkCatalogMapper.java
Patch:
@@ -26,7 +26,7 @@
 import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
 
 /** catalog mapper */
-public interface CatalogMapper extends BaseMapper<FlinkCatalog> {
+public interface FlinkCatalogMapper extends BaseMapper<FlinkCatalog> {
 
     boolean existsByCatalogName(@Param("catalogName") String catalogName);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/FlinkSavepointMapper.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.streampark.console.core.mapper;
 
-import org.apache.streampark.console.core.entity.Savepoint;
+import org.apache.streampark.console.core.entity.FlinkSavepoint;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;
 
-public interface SavepointMapper extends BaseMapper<Savepoint> {
+public interface FlinkSavepointMapper extends BaseMapper<FlinkSavepoint> {
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/SparkApplicationMapper.java
Patch:
@@ -43,7 +43,7 @@ IPage<SparkApplication> selectPage(
     List<String> selectRecentK8sNamespaces(@Param("limitSize") Integer limit);
 
     List<String> selectRecentK8sClusterIds(
-                                           @Param("executionMode") Integer executionMode,
+                                           @Param("deployMode") Integer deployMode,
                                            @Param("limitSize") Integer limit);
 
     List<String> selectRecentK8sPodTemplates(@Param("limitSize") Integer limit);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/DistributedTaskService.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.streampark.console.core.service;
 
-import org.apache.streampark.console.core.entity.Application;
 import org.apache.streampark.console.core.entity.DistributedTask;
+import org.apache.streampark.console.core.entity.FlinkApplication;
 import org.apache.streampark.console.core.enums.DistributedTaskEnum;
 
 import com.baomidou.mybatisplus.extension.service.IService;
@@ -49,7 +49,7 @@ public interface DistributedTaskService extends IService<DistributedTask> {
      * @param applications List<Application>
      * @return List<Application> List of tasks that need to be monitored
      */
-    List<Application> getMonitoredTaskList(List<Application> applications);
+    List<FlinkApplication> getMonitoredTaskList(List<FlinkApplication> applications);
 
     /**
      * This interface handles task redistribution when server nodes are added.
@@ -78,5 +78,5 @@ public interface DistributedTaskService extends IService<DistributedTask> {
      * @param autoStart boolean
      * @param action It may be one of the following values: START, RESTART, REVOKE, CANCEL, ABORT
      */
-    public void saveDistributedTask(Application appParam, boolean autoStart, DistributedTaskEnum action);
+    public void saveDistributedTask(FlinkApplication appParam, boolean autoStart, DistributedTaskEnum action);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkSqlService.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.streampark.console.core.service;
 
 import org.apache.streampark.console.base.domain.RestRequest;
-import org.apache.streampark.console.core.entity.Application;
+import org.apache.streampark.console.core.entity.FlinkApplication;
 import org.apache.streampark.console.core.entity.FlinkSql;
 import org.apache.streampark.console.core.enums.CandidateTypeEnum;
 import org.apache.streampark.flink.core.FlinkSqlValidationResult;
@@ -105,7 +105,7 @@ public interface FlinkSqlService extends IService<FlinkSql> {
      *
      * @param application Application
      */
-    void rollback(Application application);
+    void rollback(FlinkApplication application);
 
     /**
      * Verify whether the entered SQL is correct

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ProjectService.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.domain.RestResponse;
-import org.apache.streampark.console.core.entity.Application;
+import org.apache.streampark.console.core.entity.FlinkApplication;
 import org.apache.streampark.console.core.entity.Project;
 import org.apache.streampark.console.core.enums.GitAuthorizedErrorEnum;
 
@@ -139,7 +139,7 @@ public interface ProjectService extends IService<Project> {
      * @param project Project
      * @return List of Applications
      */
-    List<Application> listApps(Project project);
+    List<FlinkApplication> listApps(Project project);
 
     /**
      * Check whether the corresponding project exists

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ProxyService.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.streampark.console.core.service;
 
-import org.apache.streampark.console.core.entity.Application;
 import org.apache.streampark.console.core.entity.ApplicationLog;
+import org.apache.streampark.console.core.entity.FlinkApplication;
 import org.apache.streampark.console.core.entity.SparkApplicationLog;
 
 import org.springframework.http.ResponseEntity;
@@ -27,7 +27,7 @@
 
 public interface ProxyService {
 
-    ResponseEntity<?> proxyFlink(HttpServletRequest request, Application app) throws Exception;
+    ResponseEntity<?> proxyFlink(HttpServletRequest request, FlinkApplication app) throws Exception;
 
     ResponseEntity<?> proxyYarn(HttpServletRequest request, SparkApplicationLog log) throws Exception;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/VariableService.java
Patch:
@@ -18,7 +18,7 @@
 package org.apache.streampark.console.core.service;
 
 import org.apache.streampark.console.base.domain.RestRequest;
-import org.apache.streampark.console.core.entity.Application;
+import org.apache.streampark.console.core.entity.FlinkApplication;
 import org.apache.streampark.console.core.entity.Variable;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;
@@ -102,7 +102,7 @@ public interface VariableService extends IService<Variable> {
      * @param request The REST request containing additional parameters for retrieving the page.
      * @return An instance of IPage<Application> containing the dependent applications.
      */
-    IPage<Application> getDependAppsPage(Variable variable, RestRequest request);
+    IPage<FlinkApplication> getDependAppsPage(Variable variable, RestRequest request);
 
     /**
      * Updates the given variable.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkCatalogServiceImpl.java
Patch:
@@ -23,7 +23,7 @@
 import org.apache.streampark.console.base.mybatis.pager.MybatisPager;
 import org.apache.streampark.console.core.bean.FlinkCatalogParams;
 import org.apache.streampark.console.core.entity.FlinkCatalog;
-import org.apache.streampark.console.core.mapper.CatalogMapper;
+import org.apache.streampark.console.core.mapper.FlinkCatalogMapper;
 import org.apache.streampark.console.core.service.CatalogService;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;
@@ -44,7 +44,7 @@
 @Service
 @Slf4j
 @Transactional(propagation = Propagation.SUPPORTS, rollbackFor = Exception.class)
-public class CatalogServiceImpl extends ServiceImpl<CatalogMapper, FlinkCatalog>
+public class FlinkCatalogServiceImpl extends ServiceImpl<FlinkCatalogMapper, FlinkCatalog>
     implements
         CatalogService {
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -26,7 +26,7 @@
 import org.apache.streampark.console.core.mapper.FlinkEnvMapper;
 import org.apache.streampark.console.core.service.FlinkClusterService;
 import org.apache.streampark.console.core.service.FlinkEnvService;
-import org.apache.streampark.console.core.service.application.ApplicationInfoService;
+import org.apache.streampark.console.core.service.application.FlinkApplicationInfoService;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
 import com.baomidou.mybatisplus.core.metadata.IPage;
@@ -51,7 +51,7 @@ public class FlinkEnvServiceImpl extends ServiceImpl<FlinkEnvMapper, FlinkEnv>
     @Autowired
     private FlinkClusterService flinkClusterService;
     @Autowired
-    private ApplicationInfoService applicationInfoService;
+    private FlinkApplicationInfoService applicationInfoService;
 
     /**
      * two places will be checked: <br>

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/TeamServiceImpl.java
Patch:
@@ -24,7 +24,7 @@
 import org.apache.streampark.console.core.enums.UserTypeEnum;
 import org.apache.streampark.console.core.service.ProjectService;
 import org.apache.streampark.console.core.service.VariableService;
-import org.apache.streampark.console.core.service.application.ApplicationInfoService;
+import org.apache.streampark.console.core.service.application.FlinkApplicationInfoService;
 import org.apache.streampark.console.core.util.ServiceHelper;
 import org.apache.streampark.console.system.entity.Team;
 import org.apache.streampark.console.system.entity.User;
@@ -55,7 +55,7 @@ public class TeamServiceImpl extends ServiceImpl<TeamMapper, Team> implements Te
     private UserService userService;
 
     @Autowired
-    private ApplicationInfoService applicationInfoService;
+    private FlinkApplicationInfoService applicationInfoService;
 
     @Autowired
     private ProjectService projectService;

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/DistributedTaskServiceTest.java
Patch:
@@ -18,8 +18,8 @@
 package org.apache.streampark.console.core.service;
 
 import org.apache.streampark.console.core.bean.FlinkTaskItem;
-import org.apache.streampark.console.core.entity.Application;
 import org.apache.streampark.console.core.entity.DistributedTask;
+import org.apache.streampark.console.core.entity.FlinkApplication;
 import org.apache.streampark.console.core.enums.DistributedTaskEnum;
 import org.apache.streampark.console.core.service.impl.DistributedTaskServiceImpl;
 
@@ -58,13 +58,13 @@ void testIsLocalProcessing() {
 
     @Test
     void testGetTaskAndApp() {
-        Application application = new Application();
+        FlinkApplication application = new FlinkApplication();
         application.setId(0L);
         try {
             DistributedTask DistributedTask =
                 distributionTaskService.getDistributedTaskByApp(application, false, DistributedTaskEnum.START);
             FlinkTaskItem flinkTaskItem = distributionTaskService.getFlinkTaskItem(DistributedTask);
-            Application newApplication = distributionTaskService.getAppByFlinkTaskItem(flinkTaskItem);
+            FlinkApplication newApplication = distributionTaskService.getAppByFlinkTaskItem(flinkTaskItem);
             assert (application.equals(newApplication));
         } catch (JacksonException e) {
             log.error("testGetTaskAndApp failed:", e);

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/FlinkClusterServiceTest.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.core.service;
 
-import org.apache.streampark.common.enums.FlinkExecutionMode;
+import org.apache.streampark.common.enums.FlinkDeployMode;
 import org.apache.streampark.console.SpringUnitTestBase;
 import org.apache.streampark.console.core.entity.FlinkCluster;
 import org.apache.streampark.console.core.entity.YarnQueue;
@@ -97,7 +97,7 @@ void testCheckQueueValidationIfNeeded() {
         assertThat(clusterServiceImpl.validateQueueIfNeeded(cluster1, cluster2)).isTrue();
 
         // Test non-existed queue
-        cluster1.setExecutionMode(FlinkExecutionMode.KUBERNETES_NATIVE_APPLICATION.getMode());
+        cluster1.setDeployMode(FlinkDeployMode.KUBERNETES_NATIVE_APPLICATION.getMode());
         cluster2.setYarnQueue(nonExistedQueue);
         assertThat(clusterServiceImpl.validateQueueIfNeeded(cluster1, cluster2)).isFalse();
     }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/alert/AlertServiceTest.java
Patch:
@@ -26,7 +26,7 @@
 import org.apache.streampark.console.core.bean.AlertTemplate;
 import org.apache.streampark.console.core.bean.AlertWeComParams;
 import org.apache.streampark.console.core.bean.EmailConfig;
-import org.apache.streampark.console.core.entity.Application;
+import org.apache.streampark.console.core.entity.FlinkApplication;
 import org.apache.streampark.console.core.enums.FlinkAppStateEnum;
 import org.apache.streampark.console.core.service.alert.impl.DingTalkAlertNotifyServiceImpl;
 import org.apache.streampark.console.core.service.alert.impl.LarkAlertNotifyServiceImpl;
@@ -157,7 +157,7 @@ void testLarkAlert() {
 
     @Test
     void testAlert() {
-        Application application = new Application();
+        FlinkApplication application = new FlinkApplication();
         application.setStartTime(new Date());
         application.setJobName("Test My Job");
         application.setClusterId("1234567890");
@@ -194,7 +194,7 @@ void testAlert() {
         }
     }
 
-    private AlertTemplate getAlertBaseInfo(Application application) {
+    private AlertTemplate getAlertBaseInfo(FlinkApplication application) {
         long duration;
         if (application.getEndTime() == null) {
             duration = System.currentTimeMillis() - application.getStartTime().getTime();

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/Flink116OnRemoteClusterDeployTest.java
Patch:
@@ -50,7 +50,7 @@ public class Flink116OnRemoteClusterDeployTest {
 
     private static final String flinkJobManagerUrl = "http://jobmanager:8081";
 
-    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.STANDALONE;
+    private static final ClusterDetailForm.DeployMode deployMode = ClusterDetailForm.DeployMode.STANDALONE;
 
     @BeforeAll
     public static void setUp() {
@@ -71,7 +71,7 @@ public void testCreateFlinkCluster() {
         FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 
         flinkClustersPage.createFlinkCluster()
-            .<RemoteForm>addCluster(executionMode)
+            .<RemoteForm>addCluster(deployMode)
             .jobManagerURL(flinkJobManagerUrl)
             .clusterName(flinkClusterName)
             .flinkVersion(flinkName)

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/Flink116OnYarnClusterDeployTest.java
Patch:
@@ -50,7 +50,7 @@ public class Flink116OnYarnClusterDeployTest {
 
     private static final String flinkClusterNameEdited = "flink_1.16.3_cluster_e2e_edited";
 
-    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.YARN_SESSION;
+    private static final ClusterDetailForm.DeployMode deployMode = ClusterDetailForm.DeployMode.YARN_SESSION;
 
     @BeforeAll
     public static void setUp() {
@@ -71,7 +71,7 @@ public void testCreateFlinkCluster() {
         FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 
         flinkClustersPage.createFlinkCluster()
-            .<YarnSessionForm>addCluster(executionMode)
+            .<YarnSessionForm>addCluster(deployMode)
             .clusterName(flinkClusterName)
             .flinkVersion(flinkName)
             .submit();
@@ -90,7 +90,7 @@ public void testEditFlinkCluster() {
         final FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 
         flinkClustersPage.editFlinkCluster(flinkClusterName)
-            .<YarnSessionForm>addCluster(executionMode)
+            .<YarnSessionForm>addCluster(deployMode)
             .clusterName(flinkClusterNameEdited)
             .submit();
 

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/Flink117OnRemoteClusterDeployTest.java
Patch:
@@ -50,7 +50,7 @@ public class Flink117OnRemoteClusterDeployTest {
 
     private static final String flinkJobManagerUrl = "http://jobmanager:8081";
 
-    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.STANDALONE;
+    private static final ClusterDetailForm.DeployMode deployMode = ClusterDetailForm.DeployMode.STANDALONE;
 
     @BeforeAll
     public static void setUp() {
@@ -71,7 +71,7 @@ public void testCreateFlinkCluster() {
         FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 
         flinkClustersPage.createFlinkCluster()
-            .<RemoteForm>addCluster(executionMode)
+            .<RemoteForm>addCluster(deployMode)
             .jobManagerURL(flinkJobManagerUrl)
             .clusterName(flinkClusterName)
             .flinkVersion(flinkName)

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/Flink117OnYarnClusterDeployTest.java
Patch:
@@ -50,7 +50,7 @@ public class Flink117OnYarnClusterDeployTest {
 
     private static final String flinkClusterNameEdited = "flink_1.17.2_cluster_e2e_edited";
 
-    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.YARN_SESSION;
+    private static final ClusterDetailForm.DeployMode deployMode = ClusterDetailForm.DeployMode.YARN_SESSION;
 
     @BeforeAll
     public static void setup() {
@@ -71,7 +71,7 @@ public void testCreateFlinkCluster() {
         final FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 
         flinkClustersPage.createFlinkCluster()
-            .<YarnSessionForm>addCluster(executionMode)
+            .<YarnSessionForm>addCluster(deployMode)
             .resolveOrder(YarnSessionForm.ResolveOrder.CHILD_FIRST)
             .clusterName(flinkClusterName)
             .flinkVersion(flinkName)
@@ -91,7 +91,7 @@ public void testEditFlinkCluster() {
         final FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 
         flinkClustersPage.editFlinkCluster(flinkClusterName)
-            .<YarnSessionForm>addCluster(executionMode)
+            .<YarnSessionForm>addCluster(deployMode)
             .clusterName(flinkClusterNameEdited)
             .submit();
 

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/Flink118OnRemoteClusterDeployTest.java
Patch:
@@ -50,7 +50,7 @@ public class Flink118OnRemoteClusterDeployTest {
 
     private static final String flinkJobManagerUrl = "http://jobmanager:8081";
 
-    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.STANDALONE;
+    private static final ClusterDetailForm.DeployMode deployMode = ClusterDetailForm.DeployMode.STANDALONE;
 
     @BeforeAll
     public static void setUp() {
@@ -71,7 +71,7 @@ public void testCreateFlinkCluster() {
         FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 
         flinkClustersPage.createFlinkCluster()
-            .<RemoteForm>addCluster(executionMode)
+            .<RemoteForm>addCluster(deployMode)
             .jobManagerURL(flinkJobManagerUrl)
             .clusterName(flinkClusterName)
             .flinkVersion(flinkName)

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/Flink118OnYarnClusterDeployTest.java
Patch:
@@ -50,7 +50,7 @@ public class Flink118OnYarnClusterDeployTest {
 
     private static final String flinkClusterNameEdited = "flink_1.18.1_cluster_e2e_edited";
 
-    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.YARN_SESSION;
+    private static final ClusterDetailForm.DeployMode deployMode = ClusterDetailForm.DeployMode.YARN_SESSION;
 
     @BeforeAll
     public static void setup() {
@@ -71,7 +71,7 @@ public void testCreateFlinkCluster() {
         final FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 
         flinkClustersPage.createFlinkCluster()
-            .<YarnSessionForm>addCluster(executionMode)
+            .<YarnSessionForm>addCluster(deployMode)
             .resolveOrder(YarnSessionForm.ResolveOrder.CHILD_FIRST)
             .clusterName(flinkClusterName)
             .flinkVersion(flinkName)
@@ -91,7 +91,7 @@ public void testEditFlinkCluster() {
         final FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 
         flinkClustersPage.editFlinkCluster(flinkClusterName)
-            .<YarnSessionForm>addCluster(executionMode)
+            .<YarnSessionForm>addCluster(deployMode)
             .clusterName(flinkClusterNameEdited)
             .submit();
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationActionServiceImpl.java
Patch:
@@ -80,6 +80,7 @@
 import org.springframework.stereotype.Service;
 
 import java.io.File;
+import java.util.Arrays;
 import java.util.Date;
 import java.util.EnumSet;
 import java.util.HashMap;
@@ -309,6 +310,7 @@ public void start(SparkApplication appParam, boolean auto) throws Exception {
 
         // Get the args after placeholder replacement
         String applicationArgs = variableService.replaceVariable(application.getTeamId(), application.getAppArgs());
+        List<String> sparkArgs = Arrays.asList(applicationArgs.split("\\s+"));
 
         SubmitRequest submitRequest = new SubmitRequest(
             sparkEnv.getSparkVersion(),
@@ -320,7 +322,7 @@ public void start(SparkApplication appParam, boolean auto) throws Exception {
             application.getMainClass(),
             appConf,
             PropertiesUtils.extractSparkPropertiesAsJava(application.getAppProperties()),
-            PropertiesUtils.extractSparkArgumentsAsJava(applicationArgs),
+            sparkArgs,
             application.getApplicationType(),
             application.getHadoopUser(),
             buildResult,

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/JdbcRegistryProperties.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core;
+package org.apache.streampark.registry.core;
 
 import org.apache.streampark.common.utils.NetworkUtils;
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/JdbcRegistryThreadFactory.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core;
+package org.apache.streampark.registry.core;
 
 import org.apache.streampark.registry.api.thread.ThreadUtils;
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/LockUtils.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core;
+package org.apache.streampark.registry.core;
 
 import org.apache.streampark.common.utils.NetworkUtils;
 import org.apache.streampark.common.utils.OSUtils;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/client/JdbcRegistryClientIdentify.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.client;
+package org.apache.streampark.registry.core.client;
 
 import lombok.AllArgsConstructor;
 import lombok.Getter;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/mapper/JdbcRegistryClientHeartbeatMapper.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.mapper;
+package org.apache.streampark.registry.core.mapper;
 
-import org.apache.streampark.plugin.registry.core.model.DO.JdbcRegistryClientHeartbeat;
+import org.apache.streampark.registry.core.model.DO.JdbcRegistryClientHeartbeat;
 
 import org.apache.ibatis.annotations.Select;
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/mapper/JdbcRegistryDataChanceEventMapper.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.mapper;
+package org.apache.streampark.registry.core.mapper;
 
-import org.apache.streampark.plugin.registry.core.model.DO.JdbcRegistryDataChanceEvent;
+import org.apache.streampark.registry.core.model.DO.JdbcRegistryDataChanceEvent;
 
 import org.apache.ibatis.annotations.Delete;
 import org.apache.ibatis.annotations.Param;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/mapper/JdbcRegistryDataMapper.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.mapper;
+package org.apache.streampark.registry.core.mapper;
 
-import org.apache.streampark.plugin.registry.core.model.DO.JdbcRegistryData;
+import org.apache.streampark.registry.core.model.DO.JdbcRegistryData;
 
 import org.apache.ibatis.annotations.Delete;
 import org.apache.ibatis.annotations.Param;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/mapper/JdbcRegistryLockMapper.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.mapper;
+package org.apache.streampark.registry.core.mapper;
 
-import org.apache.streampark.plugin.registry.core.model.DO.JdbcRegistryLock;
+import org.apache.streampark.registry.core.model.DO.JdbcRegistryLock;
 
 import org.apache.ibatis.annotations.Delete;
 import org.apache.ibatis.annotations.Param;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/model/DO/JdbcRegistryClientHeartbeat.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.model.DO;
+package org.apache.streampark.registry.core.model.DO;
 
 import com.baomidou.mybatisplus.annotation.IdType;
 import com.baomidou.mybatisplus.annotation.TableId;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/model/DO/JdbcRegistryData.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.model.DO;
+package org.apache.streampark.registry.core.model.DO;
 
 import com.baomidou.mybatisplus.annotation.IdType;
 import com.baomidou.mybatisplus.annotation.TableId;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/model/DO/JdbcRegistryDataChanceEvent.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.model.DO;
+package org.apache.streampark.registry.core.model.DO;
 
 import com.baomidou.mybatisplus.annotation.IdType;
 import com.baomidou.mybatisplus.annotation.TableId;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/model/DO/JdbcRegistryLock.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.model.DO;
+package org.apache.streampark.registry.core.model.DO;
 
 import com.baomidou.mybatisplus.annotation.IdType;
 import com.baomidou.mybatisplus.annotation.TableId;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/model/DTO/DataType.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.model.DTO;
+package org.apache.streampark.registry.core.model.DTO;
 
 public enum DataType {
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/model/DTO/JdbcRegistryClientHeartbeatDTO.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.model.DTO;
+package org.apache.streampark.registry.core.model.DTO;
 
 import org.apache.streampark.common.utils.JSONUtils;
-import org.apache.streampark.plugin.registry.core.model.DO.JdbcRegistryClientHeartbeat;
+import org.apache.streampark.registry.core.model.DO.JdbcRegistryClientHeartbeat;
 
 import lombok.AllArgsConstructor;
 import lombok.Builder;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/model/DTO/JdbcRegistryDataChanceEventDTO.java
Patch:
@@ -15,11 +15,11 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.model.DTO;
+package org.apache.streampark.registry.core.model.DTO;
 
 import org.apache.streampark.common.utils.JSONUtils;
-import org.apache.streampark.plugin.registry.core.model.DO.JdbcRegistryData;
-import org.apache.streampark.plugin.registry.core.model.DO.JdbcRegistryDataChanceEvent;
+import org.apache.streampark.registry.core.model.DO.JdbcRegistryData;
+import org.apache.streampark.registry.core.model.DO.JdbcRegistryDataChanceEvent;
 
 import lombok.AllArgsConstructor;
 import lombok.Builder;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/model/DTO/JdbcRegistryDataDTO.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.model.DTO;
+package org.apache.streampark.registry.core.model.DTO;
 
-import org.apache.streampark.plugin.registry.core.model.DO.JdbcRegistryData;
+import org.apache.streampark.registry.core.model.DO.JdbcRegistryData;
 
 import lombok.AllArgsConstructor;
 import lombok.Builder;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/model/DTO/JdbcRegistryLockDTO.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.model.DTO;
+package org.apache.streampark.registry.core.model.DTO;
 
-import org.apache.streampark.plugin.registry.core.model.DO.JdbcRegistryLock;
+import org.apache.streampark.registry.core.model.DO.JdbcRegistryLock;
 
 import lombok.AllArgsConstructor;
 import lombok.Builder;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/server/ConnectionStateListener.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.server;
+package org.apache.streampark.registry.core.server;
 
 public interface ConnectionStateListener {
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/server/IJdbcRegistryDataManager.java
Patch:
@@ -15,10 +15,10 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.server;
+package org.apache.streampark.registry.core.server;
 
-import org.apache.streampark.plugin.registry.core.model.DTO.DataType;
-import org.apache.streampark.plugin.registry.core.model.DTO.JdbcRegistryDataDTO;
+import org.apache.streampark.registry.core.model.DTO.DataType;
+import org.apache.streampark.registry.core.model.DTO.JdbcRegistryDataDTO;
 
 import java.util.List;
 import java.util.Optional;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/server/IJdbcRegistryLockManager.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.server;
+package org.apache.streampark.registry.core.server;
 
 public interface IJdbcRegistryLockManager {
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/server/IRegistryRowChangeNotifier.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.server;
+package org.apache.streampark.registry.core.server;
 
 public interface IRegistryRowChangeNotifier<T> {
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/server/JdbcRegistryDataChangeListener.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.server;
+package org.apache.streampark.registry.core.server;
 
 public interface JdbcRegistryDataChangeListener {
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/main/java/org/apache/streampark/registry/core/server/JdbcRegistryServerState.java
Patch:
@@ -15,9 +15,9 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core.server;
+package org.apache.streampark.registry.core.server;
 
-import org.apache.streampark.plugin.registry.core.JdbcRegistryProperties;
+import org.apache.streampark.registry.core.JdbcRegistryProperties;
 
 public enum JdbcRegistryServerState {
     /**

File: streampark-console/streampark-console-registry/streampark-registry-core/src/test/java/org/apache/streampark/registry/core/JdbcRegistryTestCase.java
Patch:
@@ -15,12 +15,12 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core;
+package org.apache.streampark.registry.core;
 
 import org.apache.streampark.common.CommonConfiguration;
-import org.apache.streampark.plugin.registry.RegistryTestCase;
-import org.apache.streampark.plugin.registry.core.server.IJdbcRegistryServer;
+import org.apache.streampark.registry.RegistryTestCase;
 import org.apache.streampark.registry.api.ConnectionState;
+import org.apache.streampark.registry.core.server.IJdbcRegistryServer;
 
 import lombok.SneakyThrows;
 import org.junit.jupiter.api.Test;

File: streampark-console/streampark-console-registry/streampark-registry-core/src/test/java/org/apache/streampark/registry/core/JdbcRegistryThreadFactoryTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core;
+package org.apache.streampark.registry.core;
 
 import org.junit.jupiter.api.Test;
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/test/java/org/apache/streampark/registry/core/LockUtilsTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core;
+package org.apache.streampark.registry.core;
 
 import org.apache.streampark.common.utils.NetworkUtils;
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/test/java/org/apache/streampark/registry/core/MysqlJdbcRegistryTestCase.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core;
+package org.apache.streampark.registry.core;
 
 import org.apache.streampark.registry.api.sql.SqlScriptRunner;
 

File: streampark-console/streampark-console-registry/streampark-registry-core/src/test/java/org/apache/streampark/registry/core/PostgresqlJdbcRegistryTestCase.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry.core;
+package org.apache.streampark.registry.core;
 
 import org.apache.streampark.registry.api.sql.SqlScriptRunner;
 

File: streampark-console/streampark-console-registry/streampark-registry-it/src/test/java/org/apache/streampark/plugin/registry/RegistryTestCase.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.plugin.registry;
+package org.apache.streampark.registry;
 
 import org.apache.streampark.common.utils.NetworkUtils;
 import org.apache.streampark.registry.api.ConnectionState;

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/Flink116OnRemoteClusterDeployTest.java
Patch:
@@ -50,7 +50,7 @@ public class Flink116OnRemoteClusterDeployTest {
 
     private static final String flinkJobManagerUrl = "http://jobmanager:8081";
 
-    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.REMOTE;
+    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.STANDALONE;
 
     @BeforeAll
     public static void setUp() {
@@ -86,7 +86,7 @@ public void testCreateFlinkCluster() {
     }
 
     @Test
-    @Order(5)
+    @Order(2)
     public void testDeleteFlinkCluster() {
         final FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/Flink116OnYarnClusterDeployTest.java
Patch:
@@ -53,7 +53,7 @@ public class Flink116OnYarnClusterDeployTest {
     private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.YARN_SESSION;
 
     @BeforeAll
-    public static void setup() {
+    public static void setUp() {
         FlinkHomePage flinkHomePage = new LoginPage(browser)
             .login()
             .goToNav(ApacheFlinkPage.class)
@@ -68,11 +68,10 @@ public static void setup() {
     @Test
     @Order(1)
     public void testCreateFlinkCluster() {
-        final FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
+        FlinkClustersPage flinkClustersPage = new FlinkClustersPage(browser);
 
         flinkClustersPage.createFlinkCluster()
             .<YarnSessionForm>addCluster(executionMode)
-            .resolveOrder(YarnSessionForm.ResolveOrder.CHILD_FIRST)
             .clusterName(flinkClusterName)
             .flinkVersion(flinkName)
             .submit();

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/Flink117OnRemoteClusterDeployTest.java
Patch:
@@ -50,7 +50,7 @@ public class Flink117OnRemoteClusterDeployTest {
 
     private static final String flinkJobManagerUrl = "http://jobmanager:8081";
 
-    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.REMOTE;
+    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.STANDALONE;
 
     @BeforeAll
     public static void setUp() {

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/Flink118OnRemoteClusterDeployTest.java
Patch:
@@ -50,7 +50,7 @@ public class Flink118OnRemoteClusterDeployTest {
 
     private static final String flinkJobManagerUrl = "http://jobmanager:8081";
 
-    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.REMOTE;
+    private static final ClusterDetailForm.ExecutionMode executionMode = ClusterDetailForm.ExecutionMode.STANDALONE;
 
     @BeforeAll
     public static void setUp() {

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/flink/applications/ApplicationsPage.java
Patch:
@@ -170,9 +170,6 @@ public class StartJobForm {
 
         @FindBy(id = "e2e-flinkapp-start-submit")
         public WebElement buttonSubmit;
-
-        @FindBy(id = "e2e-flinkapp-start-cancel")
-        public WebElement buttonCancel;
     }
 
     @Getter

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/flink/clusters/CommonForm.java
Patch:
@@ -36,7 +36,7 @@ public abstract class CommonForm {
 
     public WebDriver driver;
 
-    @FindBy(id = "form_item_clusterName")
+    @FindBy(id = "flink_cluster_clusterName")
     public WebElement inputFlinkClusterName;
 
     @FindBy(xpath = "//div[contains(@codefield, 'versionId')]//div[contains(@class, 'ant-select-selector')]")
@@ -48,7 +48,7 @@ public abstract class CommonForm {
     })
     public List<WebElement> selectFlinkVersion;
 
-    @FindBy(xpath = "//button[contains(@class, 'ant-btn')]//span[contains(text(), 'Submit')]")
+    @FindBy(id = "e2e-flinkcluster-submit-btn")
     public WebElement buttonSubmit;
 
     private final ClusterDetailForm parent;

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/flink/clusters/RemoteForm.java
Patch:
@@ -29,7 +29,7 @@ public class RemoteForm extends CommonForm {
 
     public WebDriver driver;
 
-    @FindBy(id = "form_item_address")
+    @FindBy(id = "flink_cluster_address")
     public WebElement inputJobManagerURL;
 
     public RemoteForm(ClusterDetailForm clusterDetailForm) {

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/setting/ExternalLinkPage.java
Patch:
@@ -116,6 +116,7 @@ public ExternalLinkPage deleteExternalLink(String label) {
             .until(ExpectedConditions.elementToBeClickable(deleteConfirmButton));
 
         deleteConfirmButton.click();
+
         return this;
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/SparkApplication.java
Patch:
@@ -204,6 +204,7 @@ public class SparkApplication extends BaseEntity {
     private transient String teamResource;
     private transient String dependency;
     private transient Long sqlId;
+    private transient String nickName;
     private transient String sparkSql;
     private transient Boolean backUp = false;
     private transient Boolean restart = false;
@@ -335,14 +336,14 @@ public String getDistHome() {
 
     @JsonIgnore
     public String getLocalAppHome() {
-        String path = String.format("%s/%s", Workspace.local().APP_WORKSPACE(), id.toString());
+        String path = String.format("%s/%s", Workspace.local().SPARK_APP_WORKSPACE(), id.toString());
         log.info("local appHome:{}", path);
         return path;
     }
 
     @JsonIgnore
     public String getRemoteAppHome() {
-        String path = String.format("%s/%s", Workspace.remote().APP_WORKSPACE(), id.toString());
+        String path = String.format("%s/%s", Workspace.remote().SPARK_APP_WORKSPACE(), id.toString());
         log.info("remote appHome:{}", path);
         return path;
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/runner/EnvInitializer.java
Patch:
@@ -147,6 +147,7 @@ private void prepareWorkspace(
         Arrays.asList(
             workspace.APP_UPLOADS(),
             workspace.APP_WORKSPACE(),
+            workspace.SPARK_APP_WORKSPACE(),
             workspace.APP_BACKUPS(),
             workspace.APP_SAVEPOINTS(),
             workspace.APP_PYTHON(),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ProxyService.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.streampark.console.core.entity.Application;
 import org.apache.streampark.console.core.entity.ApplicationLog;
+import org.apache.streampark.console.core.entity.SparkApplicationLog;
 
 import org.springframework.http.ResponseEntity;
 
@@ -28,6 +29,8 @@ public interface ProxyService {
 
     ResponseEntity<?> proxyFlink(HttpServletRequest request, Application app) throws Exception;
 
+    ResponseEntity<?> proxyYarn(HttpServletRequest request, SparkApplicationLog log) throws Exception;
+
     ResponseEntity<?> proxyYarn(HttpServletRequest request, ApplicationLog log) throws Exception;
 
     ResponseEntity<?> proxyHistory(HttpServletRequest request, ApplicationLog log) throws Exception;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationActionServiceImpl.java
Patch:
@@ -360,6 +360,7 @@ public void start(SparkApplication appParam, boolean auto) throws Exception {
                     application.setAppId(response.sparkAppId());
                 }
                 applicationLog.setSparkAppId(response.sparkAppId());
+                applicationLog.setTrackUrl(response.trackingUrl());
                 application.setStartTime(new Date());
                 application.setEndTime(null);
 
@@ -480,7 +481,7 @@ private Tuple2<String, String> getUserJarAndAppConf(
                     }
                 }
 
-                if (SparkExecutionMode.YARN_CLUSTER == executionModeEnum) {
+                if (SparkExecutionMode.isYarnMode(executionModeEnum)) {
                     switch (application.getApplicationType()) {
                         case STREAMPARK_SPARK:
                             sparkUserJar = String.format(

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationManageServiceImpl.java
Patch:
@@ -194,9 +194,9 @@ private void removeApp(SparkApplication application) {
         try {
             application
                 .getFsOperator()
-                .delete(application.getWorkspace().APP_WORKSPACE().concat("/").concat(appId.toString()));
+                .delete(application.getWorkspace().SPARK_APP_WORKSPACE().concat("/").concat(appId.toString()));
             // try to delete yarn-application, and leave no trouble.
-            String path = Workspace.of(StorageType.HDFS).APP_WORKSPACE().concat("/").concat(appId.toString());
+            String path = Workspace.of(StorageType.HDFS).SPARK_APP_WORKSPACE().concat("/").concat(appId.toString());
             if (HdfsOperator.exists(path)) {
                 HdfsOperator.delete(path);
             }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SparkApplicationBackUpServiceImpl.java
Patch:
@@ -143,7 +143,7 @@ public void revoke(SparkApplication appParam) {
         if (!backUpPages.getRecords().isEmpty()) {
             SparkApplicationBackUp backup = backUpPages.getRecords().get(0);
             String path = backup.getPath();
-            appParam.getFsOperator().move(path, appParam.getWorkspace().APP_WORKSPACE());
+            appParam.getFsOperator().move(path, appParam.getWorkspace().SPARK_APP_WORKSPACE());
             super.removeById(backup.getId());
         }
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationManageServiceImpl.java
Patch:
@@ -527,7 +527,6 @@ public boolean update(Application appParam) {
         application.setDynamicProperties(appParam.getDynamicProperties());
         application.setResolveOrder(appParam.getResolveOrder());
         application.setExecutionMode(appParam.getExecutionMode());
-        application.setClusterId(appParam.getClusterId());
         application.setFlinkImage(appParam.getFlinkImage());
         application.setK8sNamespace(appParam.getK8sNamespace());
         application.updateHotParams(appParam);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/ApplicationBackUp.java
Patch:
@@ -47,6 +47,8 @@ public class ApplicationBackUp {
 
     private transient boolean backup;
 
+    private transient String teamId;
+
     public ApplicationBackUp() {
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/ApplicationLog.java
Patch:
@@ -48,4 +48,6 @@ public class ApplicationLog {
     private String exception;
     /** The user who operates the application */
     private Long userId;
+
+    private transient String teamId;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/FlinkSql.java
Patch:
@@ -61,6 +61,8 @@ public class FlinkSql {
     /** dependency diff */
     private transient boolean dependencyDifference = false;
 
+    private transient Long teamId;
+
     public FlinkSql() {
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Savepoint.java
Patch:
@@ -50,4 +50,6 @@ public class Savepoint {
     private Date triggerTime;
 
     private Date createTime;
+
+    private transient Long teamId;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationLogService.java
Patch:
@@ -41,4 +41,6 @@ public interface ApplicationLogService extends IService<ApplicationLog> {
      * @param appId The id of the application to be removed
      */
     void removeByAppId(Long appId);
+
+    Boolean delete(ApplicationLog applicationLog);
 }

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/flink/ApacheFlinkPage.java
Patch:
@@ -34,13 +34,13 @@
 public final class ApacheFlinkPage extends NavBarPage implements NavBarItem {
 
     @FindBy(className = "menu-item-flink_app")
-    private WebElement menuApplications;
+    public WebElement menuApplications;
 
     @FindBy(className = "menu-item-flink_home")
-    private WebElement menuFlinkHome;
+    public WebElement menuFlinkHome;
 
     @FindBy(className = "menu-item-flink_cluster")
-    private WebElement menuClusters;
+    public WebElement menuClusters;
 
     public ApacheFlinkPage(RemoteWebDriver driver) {
         super(driver);

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/resource/ResourcePage.java
Patch:
@@ -32,13 +32,13 @@
 public final class ResourcePage extends NavBarPage implements NavBarItem {
 
     @FindBy(className = "menu-item-resource_variable")
-    private WebElement menuVariables;
+    public WebElement menuVariables;
 
     @FindBy(className = "menu-item-resource_project")
-    private WebElement menuProjects;
+    public WebElement menuProjects;
 
     @FindBy(className = "menu-item-resource_upload")
-    private WebElement menuUploads;
+    public WebElement menuUploads;
 
     public ResourcePage(RemoteWebDriver driver) {
         super(driver);

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/setting/alarm/SMSAlertForm.java
Patch:
@@ -23,11 +23,10 @@
 @Getter
 public class SMSAlertForm extends CommonForm {
 
-    private WebDriver driver;
+    public WebDriver driver;
 
     public SMSAlertForm(AlertTypeDetailForm alertTypeDetailForm) {
         super(alertTypeDetailForm);
-
-        this.driver = alertTypeDetailForm.driver();
+        this.driver = alertTypeDetailForm.driver;
     }
 }

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/setting/env/CommonForm.java
Patch:
@@ -24,12 +24,12 @@
 @Getter
 public abstract class CommonForm {
 
-    private WebDriver driver;
+    public WebDriver driver;
 
-    private final EnvironmentDetailForm parent;
+    public final EnvironmentDetailForm parent;
 
     public CommonForm(EnvironmentDetailForm environmentDetailForm) {
-        final WebDriver driver = environmentDetailForm.driver();
+        final WebDriver driver = environmentDetailForm.driver;
         PageFactory.initElements(driver, this);
         this.parent = environmentDetailForm;
     }

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/setting/env/EnvironmentDetailForm.java
Patch:
@@ -27,7 +27,7 @@
 @Getter
 public class EnvironmentDetailForm {
 
-    private WebDriver driver;
+    public WebDriver driver;
 
     public EnvironmentDetailForm(WebDriver driver) {
         PageFactory.initElements(driver, this);
@@ -48,7 +48,7 @@ public <T> T addSetting(EnvSettingTypeEnum envSettingTypeEnum) {
                 return (T) new IngressSettingForm(this);
             default:
                 throw new UnsupportedOperationException(
-                    String.format("Unsupported Environment setting type %s", envSettingTypeEnum.desc()));
+                    String.format("Unsupported Environment setting type %s", envSettingTypeEnum.desc));
         }
     }
 
@@ -59,7 +59,7 @@ public enum EnvSettingTypeEnum {
         Docker("Docker"),
         Email("Email"),
         Ingress("Ingress");
-        private final String desc;
+        public final String desc;
 
         EnvSettingTypeEnum(String desc) {
             this.desc = desc;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/runner/EnvInitializer.java
Patch:
@@ -89,8 +89,8 @@ public void run(ApplicationArguments args) throws Exception {
     }
 
     private void initConfig() {
-
         Environment env = context.getEnvironment();
+        InternalConfigHolder.initConfigHub();
         // override config from spring application.yaml
         InternalConfigHolder.keys().stream()
             .filter(env::containsProperty)

File: streampark-console/streampark-console-registry/streampark-registry-plugins/streampark-registry-it/src/test/java/org/apache/streampark/plugin/registry/RegistryTestCase.java
Patch:
@@ -54,15 +54,13 @@ public static void init() {
 
     @BeforeEach
     public void setupRegistry() {
-
         registry = createRegistry();
     }
 
     @SneakyThrows
     @AfterEach
     public void tearDownRegistry() {
-        try (R registry = this.registry) {
-        }
+        this.registry.close();
     }
 
     @Test

File: streampark-console/streampark-console-registry/streampark-registry-plugins/streampark-registry-jdbc/src/main/java/org/apache/streampark/plugin/registry/jdbc/JdbcRegistry.java
Patch:
@@ -261,7 +261,9 @@ public boolean releaseLock(String key) {
     public void close() {
         log.info("Closing Jdbc Registry...");
         // remove the current Ephemeral node, if can connect to jdbc
-        try (JdbcRegistryClient closed1 = jdbcRegistryClient) {
+        try {
+            jdbcRegistryServer.close();
+            jdbcRegistryClient.close();
         } catch (Exception e) {
             log.error("Close Jdbc Registry error", e);
         }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/SpringProperties.java
Patch:
@@ -89,7 +89,6 @@ private static void dataSourceConfig(Properties userConfig, Properties springCon
                 String userName = userConfig.getProperty("datasource.username", "admin");
                 String password = userConfig.getProperty("datasource.password", "streampark");
 
-                springConfig.put("spring.jpa.database-platform", "org.hibernate.dialect.H2Dialect");
                 springConfig.put("spring.datasource.driver-class-name", "org.h2.Driver");
                 springConfig.put("spring.datasource.username", userName);
                 springConfig.put("spring.datasource.password", password);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.streampark.console.core.entity;
 
-import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.ConfigKeys;
 import org.apache.streampark.common.conf.Workspace;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.enums.ApplicationType;
 import org.apache.streampark.common.enums.FlinkDevelopmentMode;
 import org.apache.streampark.common.enums.FlinkExecutionMode;
@@ -98,7 +98,7 @@ public class Application implements Serializable {
     private String flinkImage;
 
     /** k8s namespace */
-    private String k8sNamespace = Constant.DEFAULT;
+    private String k8sNamespace = Constants.DEFAULT;
 
     /** The exposed type of the rest service of K8s(kubernetes.rest-service.exposed.type) */
     private Integer k8sRestExposedType;
@@ -262,7 +262,7 @@ public class Application implements Serializable {
     private transient AppControl appControl;
 
     public void setK8sNamespace(String k8sNamespace) {
-        this.k8sNamespace = StringUtils.isBlank(k8sNamespace) ? Constant.DEFAULT : k8sNamespace;
+        this.k8sNamespace = StringUtils.isBlank(k8sNamespace) ? Constants.DEFAULT : k8sNamespace;
     }
 
     public K8sPodTemplates getK8sPodTemplates() {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/SparkApplication.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.streampark.console.core.entity;
 
-import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.ConfigKeys;
 import org.apache.streampark.common.conf.Workspace;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.enums.ApplicationType;
 import org.apache.streampark.common.enums.SparkDevelopmentMode;
 import org.apache.streampark.common.enums.SparkExecutionMode;
@@ -135,7 +135,7 @@ public class SparkApplication extends BaseEntity {
     private String k8sServiceAccount;
 
     /** k8s namespace */
-    private String k8sNamespace = Constant.DEFAULT;
+    private String k8sNamespace = Constants.DEFAULT;
 
     @TableField("HADOOP_USER")
     private String hadoopUser;
@@ -223,7 +223,7 @@ public class SparkApplication extends BaseEntity {
     private transient AppControl appControl;
 
     public void setK8sNamespace(String k8sNamespace) {
-        this.k8sNamespace = StringUtils.isBlank(k8sNamespace) ? Constant.DEFAULT : k8sNamespace;
+        this.k8sNamespace = StringUtils.isBlank(k8sNamespace) ? Constants.DEFAULT : k8sNamespace;
     }
 
     public void setState(Integer state) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Variable.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.core.entity;
 
-import org.apache.streampark.common.Constant;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.console.base.mybatis.entity.BaseEntity;
 
 import com.baomidou.mybatisplus.annotation.IdType;
@@ -62,7 +62,7 @@ public class Variable extends BaseEntity {
 
     public void dataMasking() {
         if (desensitization) {
-            this.setVariableValue(Constant.DEFAULT_DATAMASK_STRING);
+            this.setVariableValue(Constants.DEFAULT_DATAMASK_STRING);
         }
     }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationActionServiceImpl.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.streampark.console.core.service.application.impl;
 
-import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.ConfigKeys;
 import org.apache.streampark.common.conf.Workspace;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.enums.ApplicationType;
 import org.apache.streampark.common.enums.ClusterState;
 import org.apache.streampark.common.enums.FlinkDevelopmentMode;
@@ -653,7 +653,7 @@ private Tuple2<String, String> getUserJarAndAppConf(FlinkEnv flinkEnv, Applicati
                     resource.getFilePath(), "pyflink file can't be null, start application failed.");
 
                 ApiAlertException.throwIfFalse(
-                    resource.getFilePath().endsWith(Constant.PYTHON_SUFFIX),
+                    resource.getFilePath().endsWith(Constants.PYTHON_SUFFIX),
                     "pyflink format error, must be a \".py\" suffix, start application failed.");
 
                 flinkUserJar = resource.getFilePath();
@@ -693,7 +693,7 @@ private Tuple2<String, String> getUserJarAndAppConf(FlinkEnv flinkEnv, Applicati
                             flinkUserJar = String.format(
                                 "%s/%s",
                                 application.getAppLib(),
-                                application.getModule().concat(Constant.JAR_SUFFIX));
+                                application.getModule().concat(Constants.JAR_SUFFIX));
                             break;
                         case APACHE_FLINK:
                             flinkUserJar = String.format("%s/%s", application.getAppHome(), application.getJar());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationInfoServiceImpl.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.streampark.console.core.service.application.impl;
 
-import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.Workspace;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.enums.ApplicationType;
 import org.apache.streampark.common.enums.FlinkExecutionMode;
 import org.apache.streampark.common.fs.LfsOperator;
@@ -340,7 +340,7 @@ public List<String> listHistoryUploadJars() {
             .filter(File::isFile)
             .sorted(Comparator.comparingLong(File::lastModified).reversed())
             .map(File::getName)
-            .filter(fn -> fn.endsWith(Constant.JAR_SUFFIX))
+            .filter(fn -> fn.endsWith(Constants.JAR_SUFFIX))
             .collect(Collectors.toList());
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationActionServiceImpl.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.streampark.console.core.service.application.impl;
 
-import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.ConfigKeys;
 import org.apache.streampark.common.conf.Workspace;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.enums.ApplicationType;
 import org.apache.streampark.common.enums.SparkDevelopmentMode;
 import org.apache.streampark.common.enums.SparkExecutionMode;
@@ -446,7 +446,7 @@ private Tuple2<String, String> getUserJarAndAppConf(
                     resource.getFilePath(), "pyflink file can't be null, start application failed.");
 
                 ApiAlertException.throwIfFalse(
-                    resource.getFilePath().endsWith(Constant.PYTHON_SUFFIX),
+                    resource.getFilePath().endsWith(Constants.PYTHON_SUFFIX),
                     "pyflink format error, must be a \".py\" suffix, start application failed.");
 
                 sparkUserJar = resource.getFilePath();
@@ -486,7 +486,7 @@ private Tuple2<String, String> getUserJarAndAppConf(
                             sparkUserJar = String.format(
                                 "%s/%s",
                                 application.getAppLib(),
-                                application.getModule().concat(Constant.JAR_SUFFIX));
+                                application.getModule().concat(Constants.JAR_SUFFIX));
                             break;
                         case APACHE_SPARK:
                             sparkUserJar = String.format("%s/%s", application.getAppHome(), application.getJar());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationInfoServiceImpl.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.streampark.console.core.service.application.impl;
 
-import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.Workspace;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.enums.ApplicationType;
 import org.apache.streampark.common.enums.SparkExecutionMode;
 import org.apache.streampark.common.fs.LfsOperator;
@@ -224,7 +224,7 @@ public List<String> listHistoryUploadJars() {
             .filter(File::isFile)
             .sorted(Comparator.comparingLong(File::lastModified).reversed())
             .map(File::getName)
-            .filter(fn -> fn.endsWith(Constant.JAR_SUFFIX))
+            .filter(fn -> fn.endsWith(Constants.JAR_SUFFIX))
             .limit(DEFAULT_HISTORY_RECORD_LIMIT)
             .collect(Collectors.toList());
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.streampark.console.core.service.impl;
 
-import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.Workspace;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.enums.ApplicationType;
 import org.apache.streampark.common.enums.FlinkDevelopmentMode;
 import org.apache.streampark.common.enums.FlinkExecutionMode;
@@ -456,7 +456,7 @@ private BuildPipeline createPipelineInstance(@Nonnull Application app) {
         }
 
         FlinkExecutionMode executionModeEnum = app.getFlinkExecutionMode();
-        String mainClass = Constant.STREAMPARK_FLINKSQL_CLIENT_CLASS;
+        String mainClass = Constants.STREAMPARK_FLINKSQL_CLIENT_CLASS;
         switch (executionModeEnum) {
             case YARN_APPLICATION:
                 String yarnProvidedPath = app.getAppLib();
@@ -580,7 +580,7 @@ private String retrieveFlinkUserJar(FlinkEnv flinkEnv, Application app) {
                 switch (app.getApplicationType()) {
                     case STREAMPARK_FLINK:
                         return String.format(
-                            "%s/%s", app.getAppLib(), app.getModule().concat(Constant.JAR_SUFFIX));
+                            "%s/%s", app.getAppLib(), app.getModule().concat(Constants.JAR_SUFFIX));
                     case APACHE_FLINK:
                         return String.format("%s/%s", app.getAppHome(), app.getJar());
                     default:

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -17,10 +17,10 @@
 
 package org.apache.streampark.console.core.service.impl;
 
-import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.CommonConfig;
 import org.apache.streampark.common.conf.InternalConfigHolder;
 import org.apache.streampark.common.conf.Workspace;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.util.AssertUtils;
 import org.apache.streampark.common.util.CompletableFutureUtils;
 import org.apache.streampark.common.util.FileUtils;
@@ -291,7 +291,7 @@ public List<String> listJars(Project project) {
         File projectModuleDir = new File(project.getDistHome(), project.getModule());
         return Arrays.stream(Objects.requireNonNull(projectModuleDir.listFiles()))
             .map(File::getName)
-            .filter(name -> name.endsWith(Constant.JAR_SUFFIX))
+            .filter(name -> name.endsWith(Constants.JAR_SUFFIX))
             .collect(Collectors.toList());
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.streampark.console.core.service.impl;
 
-import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.Workspace;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.fs.FsOperator;
 import org.apache.streampark.common.util.ExceptionUtils;
 import org.apache.streampark.common.util.Utils;
@@ -349,7 +349,7 @@ private RestResponse checkFlinkApp(Resource resourceParam) {
             jarFile == null || !jarFile.exists(), "flink app jar must exist.");
         Map<String, Serializable> resp = new HashMap<>(0);
         resp.put(STATE, 0);
-        if (jarFile.getName().endsWith(Constant.PYTHON_SUFFIX)) {
+        if (jarFile.getName().endsWith(Constants.PYTHON_SUFFIX)) {
             return RestResponse.success().data(resp);
         }
         String mainClass = Utils.getJarManClass(jarFile);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SparkAppBuildPipeServiceImpl.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.streampark.console.core.service.impl;
 
-import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.Workspace;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.enums.ApplicationType;
 import org.apache.streampark.common.enums.SparkDevelopmentMode;
 import org.apache.streampark.common.enums.SparkExecutionMode;
@@ -372,7 +372,7 @@ private BuildPipeline createPipelineInstance(@Nonnull SparkApplication app) {
         }
 
         SparkExecutionMode executionModeEnum = app.getSparkExecutionMode();
-        String mainClass = Constant.STREAMPARK_SPARKSQL_CLIENT_CLASS;
+        String mainClass = Constants.STREAMPARK_SPARKSQL_CLIENT_CLASS;
         switch (executionModeEnum) {
             case YARN_CLUSTER:
             case YARN_CLIENT:
@@ -404,7 +404,7 @@ private String retrieveSparkUserJar(SparkEnv sparkEnv, SparkApplication app) {
                 switch (app.getApplicationType()) {
                     case STREAMPARK_SPARK:
                         return String.format(
-                            "%s/%s", app.getAppLib(), app.getModule().concat(Constant.JAR_SUFFIX));
+                            "%s/%s", app.getAppLib(), app.getModule().concat(Constants.JAR_SUFFIX));
                     case APACHE_SPARK:
                         return String.format("%s/%s", app.getAppHome(), app.getJar());
                     default:

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/ProjectBuildTask.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.core.task;
 
-import org.apache.streampark.common.Constant;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.common.util.CommandUtils;
 import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.util.GitUtils;
@@ -177,7 +177,7 @@ private void deploy(Project project) throws Exception {
             } else {
                 // 2) .jar file(normal or official standard flink project)
                 Utils.requireCheckJarFile(app.toURI().toURL());
-                String moduleName = app.getName().replace(Constant.JAR_SUFFIX, "");
+                String moduleName = app.getName().replace(Constants.JAR_SUFFIX, "");
                 File distHome = project.getDistHome();
                 File targetDir = new File(distHome, moduleName);
                 if (!targetDir.exists()) {
@@ -207,7 +207,7 @@ private void findTarOrJar(List<File> list, File path) {
                         // 2) try look for jar files, there may be multiple jars found.
                         if (!targetFile.getName().startsWith("original-")
                             && !targetFile.getName().endsWith("-sources.jar")
-                            && targetFile.getName().endsWith(Constant.JAR_SUFFIX)) {
+                            && targetFile.getName().endsWith(Constants.JAR_SUFFIX)) {
                             if (jar == null) {
                                 jar = targetFile;
                             } else {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/entity/User.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.system.entity;
 
-import org.apache.streampark.common.Constant;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.console.base.mybatis.entity.BaseEntity;
 import org.apache.streampark.console.core.enums.LoginTypeEnum;
 import org.apache.streampark.console.core.enums.UserTypeEnum;
@@ -96,7 +96,7 @@ public class User extends BaseEntity {
     private Long lastTeamId;
 
     public void dataMasking() {
-        String dataMask = Constant.DEFAULT_DATAMASK_STRING;
+        String dataMask = Constants.DEFAULT_DATAMASK_STRING;
         this.setPassword(dataMask);
         this.setSalt(dataMask);
     }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/SpringUnitTestBase.java
Patch:
@@ -31,8 +31,8 @@
 import org.mockito.junit.jupiter.MockitoExtension;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
+import org.springframework.boot.autoconfigure.SpringBootApplication;
 import org.springframework.boot.test.autoconfigure.orm.jpa.AutoConfigureTestEntityManager;
-import org.springframework.boot.test.autoconfigure.web.reactive.AutoConfigureWebTestClient;
 import org.springframework.boot.test.context.SpringBootTest;
 import org.springframework.scheduling.annotation.EnableScheduling;
 import org.springframework.test.context.ActiveProfiles;
@@ -48,7 +48,6 @@
 @EnableScheduling
 @ActiveProfiles("test")
 @AutoConfigureTestEntityManager
-@AutoConfigureWebTestClient(timeout = "60000")
 @SpringBootTest(classes = StreamParkConsoleBootstrap.class, webEnvironment = SpringBootTest.WebEnvironment.DEFINED_PORT, properties = {
         "server.port=10000",
         "spring.application.name=Apache StreamPark",
@@ -73,6 +72,7 @@
         "spring.sql.init.mode=always"
 })
 @ExtendWith({MockitoExtension.class, SpringExtension.class})
+@SpringBootApplication(scanBasePackageClasses = {StreamParkConsoleBootstrap.class})
 public abstract class SpringUnitTestBase {
 
     protected static final Logger LOG = LoggerFactory.getLogger(SpringUnitTestBase.class);

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/base/util/EncryptUtilsTest.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.base.util;
 
-import org.apache.streampark.common.Constant;
+import org.apache.streampark.common.constants.Constants;
 
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
@@ -27,8 +27,8 @@ class EncryptUtilsTest {
     @Test
     void testEncrypt() throws Exception {
         String value = "apache streampark";
-        String encrypt = EncryptUtils.encrypt(value, Constant.STREAM_PARK);
-        String decrypt = EncryptUtils.decrypt(encrypt, Constant.STREAM_PARK);
+        String encrypt = EncryptUtils.encrypt(value, Constants.STREAM_PARK);
+        String decrypt = EncryptUtils.decrypt(encrypt, Constants.STREAM_PARK);
         Assertions.assertEquals(value, decrypt);
     }
 }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/base/util/ShaHashUtilsTest.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.base.util;
 
-import org.apache.streampark.common.Constant;
+import org.apache.streampark.common.constants.Constants;
 
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
@@ -28,7 +28,7 @@ class ShaHashUtilsTest {
     @Test
     void testEncrypt() {
         String randomSalt = "rh8b1ojwog777yrg0daesf04gk";
-        String encryptPassword = ShaHashUtils.encrypt(randomSalt, Constant.STREAM_PARK);
+        String encryptPassword = ShaHashUtils.encrypt(randomSalt, Constants.STREAM_PARK);
         Assertions.assertEquals(
             "2513f3748847298ea324dffbf67fe68681dd92315bda830065facd8efe08f54f", encryptPassword);
     }

File: streampark-flink/streampark-flink-sql-gateway/streampark-flink-sql-gateway-base/src/main/java/org/apache/streampark/gateway/factories/FactoryUtil.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.gateway.factories;
 
-import org.apache.streampark.common.Constant;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.gateway.ConfigOption;
 import org.apache.streampark.gateway.exception.ValidationException;
 
@@ -31,7 +31,7 @@
 /** Factory utils for {@link Factory}. */
 public class FactoryUtil {
 
-    private static final String DEFAULT_IDENTIFIER = Constant.DEFAULT;
+    private static final String DEFAULT_IDENTIFIER = Constants.DEFAULT;
     private static final Logger LOG = LoggerFactory.getLogger(FactoryUtil.class);
     public static final ConfigOption<String> SQL_GATEWAY_SERVICE_TYPE = ConfigOption
         .key("streampark.sql-gateway.service")

File: streampark-flink/streampark-flink-sql-gateway/streampark-flink-sql-gateway-base/src/main/java/org/apache/streampark/gateway/factories/SqlGatewayServiceFactoryUtils.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.gateway.factories;
 
-import org.apache.streampark.common.Constant;
+import org.apache.streampark.common.constants.Constants;
 import org.apache.streampark.gateway.ConfigOption;
 import org.apache.streampark.gateway.exception.ValidationException;
 import org.apache.streampark.gateway.service.SqlGatewayService;
@@ -55,7 +55,7 @@ public static List<SqlGatewayService> createSqlGatewayService(Map<String, String
                         "Service options do not contain an option key '%s' for discovering an service.",
                         SQL_GATEWAY_SERVICE_TYPE.getKey())));
 
-        List<String> identifiers = Arrays.asList(identifiersStr.split(Constant.SEMICOLON));
+        List<String> identifiers = Arrays.asList(identifiersStr.split(Constants.SEMICOLON));
 
         if (identifiers.isEmpty()) {
             throw new ValidationException(

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationInfoServiceImpl.java
Patch:
@@ -341,7 +341,6 @@ public List<String> listHistoryUploadJars() {
             .sorted(Comparator.comparingLong(File::lastModified).reversed())
             .map(File::getName)
             .filter(fn -> fn.endsWith(Constant.JAR_SUFFIX))
-            .limit(DEFAULT_HISTORY_RECORD_LIMIT)
             .collect(Collectors.toList());
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/entity/User.java
Patch:
@@ -52,6 +52,8 @@ public class User extends BaseEntity {
 
     public static final Integer DEFAULT_PASSWORD_LENGTH = 8;
 
+    public static final String DEFAULT_SECRET = "streampark";
+
     @TableId(type = IdType.AUTO)
     private Long userId;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/security/impl/AuthenticatorImpl.java
Patch:
@@ -119,6 +119,7 @@ private User newUserCreate(LoginTypeEnum loginTypeEnum, String username) throws
         newUser.setUserType(UserTypeEnum.USER);
         newUser.setStatus(User.STATUS_VALID);
         newUser.setSex(User.SEX_UNKNOWN);
+        newUser.setPassword(User.DEFAULT_SECRET);
         usersService.createUser(newUser);
         return newUser;
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/domain/Constant.java
Patch:
@@ -32,4 +32,6 @@ public class Constant {
     public static final String APP_DETAIL_MENU_ID = "100018";
 
     public static final Long DEFAULT_TEAM_ID = 100000L;
+
+    public static final Long DEFAULT_ROLE_ID = 100001L;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/annotation/AppChangeEvent.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.core.annotation;
 
-import org.apache.streampark.console.core.aspect.StreamParkAspect;
+import org.apache.streampark.console.core.aspect.AppChangeEventAspect;
 import org.apache.streampark.console.core.watcher.FlinkAppHttpWatcher;
 
 import org.aspectj.lang.ProceedingJoinPoint;
@@ -31,12 +31,12 @@
  * In the controller({@link org.apache.streampark.console.core.controller}), If some method causes
  * application state update, need to add this annotation, This annotation marks which methods will
  * cause the application to be updated, Will work together with {@link
- * StreamParkAspect#appUpdated(ProceedingJoinPoint)}, The final purpose will be refresh {@link
+ * AppChangeEventAspect#appChangeEvent(ProceedingJoinPoint)}, The final purpose will be refresh {@link
  * FlinkAppHttpWatcher#WATCHING_APPS}, Make the state of the job consistent with the database
  */
 @Target(ElementType.METHOD)
 @Retention(RetentionPolicy.RUNTIME)
-public @interface AppUpdated {
+public @interface AppChangeEvent {
 
     boolean value() default true;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/annotation/OpenAPI.java
Patch:
@@ -45,6 +45,7 @@
         String defaultValue() default "";
 
         String bindFor() default "";
+
     }
 
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ProjectController.java
Patch:
@@ -20,7 +20,7 @@
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.domain.RestResponse;
 import org.apache.streampark.console.base.exception.ApiAlertException;
-import org.apache.streampark.console.core.annotation.AppUpdated;
+import org.apache.streampark.console.core.annotation.AppChangeEvent;
 import org.apache.streampark.console.core.annotation.Permission;
 import org.apache.streampark.console.core.entity.Project;
 import org.apache.streampark.console.core.enums.GitAuthorizedErrorEnum;
@@ -59,7 +59,7 @@ public RestResponse create(Project project) {
         return projectService.create(project);
     }
 
-    @AppUpdated
+    @AppChangeEvent
     @PostMapping("update")
     @RequiresPermissions("project:update")
     @Permission(team = "#project.teamId")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -238,11 +238,11 @@ public class Application implements Serializable {
     private transient String flinkVersion;
     private transient String confPath;
     private transient Integer format;
-    private transient String savePoint;
-    private transient Boolean savePointed = false;
+    private transient String savepointPath;
+    private transient Boolean restoreOrTriggerSavepoint = false;
     private transient Boolean drain = false;
     private transient Boolean nativeFormat = false;
-    private transient Long savePointTimeout = 60L;
+    private transient Long savepointTimeout = 60L;
     private transient Boolean allowNonRestored = false;
     private transient Integer restoreMode;
     private transient String socketId;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Savepoint.java
Patch:
@@ -28,7 +28,7 @@
 @Data
 @TableName("t_flink_savepoint")
 @Slf4j
-public class SavePoint {
+public class Savepoint {
 
     @TableId(type = IdType.AUTO)
     private Long id;
@@ -41,7 +41,7 @@ public class SavePoint {
 
     /**
      * 1) checkPoint <br>
-     * 2) savePoint
+     * 2) savepoint
      */
     private Integer type;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/SparkApplication.java
Patch:
@@ -229,11 +229,11 @@ public class SparkApplication extends BaseEntity {
     private transient String sparkVersion;
     private transient String confPath;
     private transient Integer format;
-    private transient String savePoint;
-    private transient Boolean savePointed = false;
+    private transient String savepointPath;
+    private transient Boolean restoreOrTriggerSavepoint = false;
     private transient Boolean drain = false;
     private transient Boolean nativeFormat = false;
-    private transient Long savePointTimeout = 60L;
+    private transient Long savepointTimeout = 60L;
     private transient Boolean allowNonRestored = false;
     private transient Integer restoreMode;
     private transient String socketId;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/SavepointMapper.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.streampark.console.core.mapper;
 
-import org.apache.streampark.console.core.entity.SavePoint;
+import org.apache.streampark.console.core.entity.Savepoint;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;
 
-public interface SavePointMapper extends BaseMapper<SavePoint> {
+public interface SavepointMapper extends BaseMapper<Savepoint> {
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationManageServiceImpl.java
Patch:
@@ -49,7 +49,7 @@
 import org.apache.streampark.console.core.service.FlinkSqlService;
 import org.apache.streampark.console.core.service.ProjectService;
 import org.apache.streampark.console.core.service.ResourceService;
-import org.apache.streampark.console.core.service.SavePointService;
+import org.apache.streampark.console.core.service.SavepointService;
 import org.apache.streampark.console.core.service.SettingService;
 import org.apache.streampark.console.core.service.YarnQueueService;
 import org.apache.streampark.console.core.service.application.ApplicationManageService;
@@ -117,7 +117,7 @@ public class ApplicationManageServiceImpl extends ServiceImpl<ApplicationMapper,
     private FlinkSqlService flinkSqlService;
 
     @Autowired
-    private SavePointService savePointService;
+    private SavepointService savepointService;
 
     @Autowired
     private EffectiveService effectiveService;
@@ -208,7 +208,7 @@ public Boolean remove(Long appId) {
         backUpService.remove(application);
 
         // 6) remove savepoint
-        savePointService.remove(application);
+        savepointService.remove(application);
 
         // 7) remove BuildPipeline
         appBuildPipeService.removeByAppId(application.getId());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationInfoServiceImpl.java
Patch:
@@ -305,9 +305,9 @@ public String getMain(SparkApplication appParam) {
 
     @Override
     public String checkSavepointPath(SparkApplication appParam) throws Exception {
-        String savepointPath = appParam.getSavePoint();
+        String savepointPath = appParam.getSavepointPath();
         if (StringUtils.isBlank(savepointPath)) {
-            // savepointPath = savePointService.getSavePointPath(appParam);
+            // savepointPath = savepointService.getSavePointPath(appParam);
         }
 
         if (StringUtils.isNotBlank(savepointPath)) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/SparkApplicationManageServiceImpl.java
Patch:
@@ -179,7 +179,7 @@ public Boolean remove(Long appId) {
         // backUpService.remove(application);
 
         // 6) remove savepoint
-        // savePointService.remove(application);
+        // savepointService.remove(application);
 
         // 7) remove BuildPipeline
         appBuildPipeService.removeByAppId(application.getId());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/authentication/ShiroConfig.java
Patch:
@@ -74,6 +74,7 @@ public ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityMan
         filterChainDefinitionMap.put("/*.less", "anon");
         filterChainDefinitionMap.put("/*.ico", "anon");
         filterChainDefinitionMap.put("/", "anon");
+        filterChainDefinitionMap.put("/proxy/**", "anon");
         filterChainDefinitionMap.put("/**", "jwt");
 
         shiroFilterFactoryBean.setFilterChainDefinitionMap(filterChainDefinitionMap);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/AccessTokenController.java
Patch:
@@ -19,7 +19,6 @@
 
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.domain.RestResponse;
-import org.apache.streampark.console.base.exception.InternalException;
 import org.apache.streampark.console.core.enums.AccessTokenStateEnum;
 import org.apache.streampark.console.core.util.ServiceHelper;
 import org.apache.streampark.console.system.entity.AccessToken;
@@ -49,7 +48,7 @@ public class AccessTokenController {
     @RequiresPermissions("token:add")
     public RestResponse createToken(
                                     @NotNull(message = "{required}") Long userId,
-                                    @RequestParam(required = false) String description) throws InternalException {
+                                    @RequestParam(required = false) String description) throws Exception {
         return accessTokenService.create(userId, description);
     }
 
@@ -78,7 +77,7 @@ public RestResponse tokensList(RestRequest restRequest, AccessToken accessToken)
     @PostMapping("toggle")
     @RequiresPermissions("token:add")
     public RestResponse toggleToken(@NotNull(message = "{required}") Long tokenId) {
-        return accessTokenService.toggleToken(tokenId);
+        return accessTokenService.toggle(tokenId);
     }
 
     @DeleteMapping(value = "delete")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/SsoController.java
Patch:
@@ -89,7 +89,7 @@ public RestResponse token() throws Exception {
         ApiAlertException.throwIfNull(
             principal.getName(), "Please configure the correct Principal Name Attribute");
 
-        User user = authenticator.authenticate(principal.getName(), null, LoginTypeEnum.SSO.toString());
+        User user = authenticator.authenticate(principal.getName(), null, LoginTypeEnum.SSO);
 
         return userService.getLoginUserInfo(user);
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/UserController.java
Patch:
@@ -136,8 +136,9 @@ public RestResponse setTeam(Long teamId) {
 
         // 2) get latest userInfo
         user.dataMasking();
+        user.setLastTeamId(teamId);
 
-        Map<String, Object> infoMap = userService.generateFrontendUserInfo(user, teamId, null);
+        Map<String, Object> infoMap = userService.generateFrontendUserInfo(user, null);
         return new RestResponse().data(infoMap);
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/entity/AccessToken.java
Patch:
@@ -35,7 +35,6 @@
 @TableName("t_access_token")
 public class AccessToken extends BaseEntity {
 
-    public static final String DEFAULT_EXPIRE_TIME = "9999-01-01 00:00:00";
     public static final String IS_API_TOKEN = "is_api_token";
 
     public static final Integer STATUS_ENABLE = 1;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/runner/StartedUpRunner.java
Patch:
@@ -54,6 +54,7 @@ public void run(ApplicationArguments args) {
             System.out.println("    Info   :  streampark-console start successful                     ");
             System.out.println("    Local  :  http://localhost:" + port);
             System.out.println("    Time   :  " + LocalDateTime.now() + "\n\n");
+            System.setProperty("streampark.start.timestamp", System.currentTimeMillis() + "");
         }
     }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/security/Authenticator.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.system.security;
 
+import org.apache.streampark.console.core.enums.LoginTypeEnum;
 import org.apache.streampark.console.system.entity.User;
 
 public interface Authenticator {
@@ -28,5 +29,5 @@ public interface Authenticator {
      * @param password user password
      * @return result object
      */
-    User authenticate(String username, String password, String loginType) throws Exception;
+    User authenticate(String username, String password, LoginTypeEnum loginType) throws Exception;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/AccessTokenService.java
Patch:
@@ -36,7 +36,7 @@ public interface AccessTokenService extends IService<AccessToken> {
      * @return RestResponse
      * @throws InternalException
      */
-    RestResponse create(Long userId, String description) throws InternalException;
+    RestResponse create(Long userId, String description) throws Exception;
 
     /**
      * Retrieves a page of {@link AccessToken} objects based on the provided parameters.
@@ -53,7 +53,7 @@ public interface AccessTokenService extends IService<AccessToken> {
      * @param tokenId AccessToken id
      * @return RestResponse
      */
-    RestResponse toggleToken(Long tokenId);
+    RestResponse toggle(Long tokenId);
 
     /**
      * Get the corresponding AccessToken based on the user ID

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/UserService.java
Patch:
@@ -138,11 +138,10 @@ public interface UserService extends IService<User> {
      * Generate user information for the front end
      *
      * @param user User
-     * @param teamId team id
      * @param token JWTToken
      * @return
      */
-    Map<String, Object> generateFrontendUserInfo(User user, Long teamId, JWTToken token);
+    Map<String, Object> generateFrontendUserInfo(User user, JWTToken token);
 
     /**
      * transfer user resources to specified users
@@ -158,7 +157,7 @@ public interface UserService extends IService<User> {
      * @param user User
      * @return RestResponse
      */
-    RestResponse getLoginUserInfo(User user);
+    RestResponse getLoginUserInfo(User user) throws Exception;
 
     void deleteUser(Long userId);
 }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/ApplicationManageServiceTest.java
Patch:
@@ -82,7 +82,7 @@ void testRevoke() {
         app.setK8sHadoopIntegration(false);
         app.setBackUp(false);
         app.setRestart(false);
-        app.setSavePointed(false);
+        app.setRestoreOrTriggerSavepoint(false);
         app.setDrain(false);
         app.setAllowNonRestored(false);
 
@@ -95,7 +95,7 @@ void testStart() throws Exception {
         Application application = new Application();
         application.setId(1304056220683497473L);
         application.setRestart(false);
-        application.setSavePointed(false);
+        application.setRestoreOrTriggerSavepoint(false);
         application.setAllowNonRestored(false);
 
         applicationActionService.start(application, false);

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/flink/applications/ApplicationsPage.java
Patch:
@@ -180,7 +180,7 @@ public class StartJobForm {
             PageFactory.initElements(driver, this);
         }
 
-        @FindBy(xpath = "//button[@id='startApplicationModal_startSavePointed']//span[contains(text(), 'ON')]")
+        @FindBy(xpath = "//button[@id='startApplicationModal_restoreSavepoint']//span[contains(text(), 'ON')]")
         private WebElement radioFromSavepoint;
 
         @FindBy(xpath = "//div[contains(.,'Start Job')]//button[contains(@class, 'ant-btn')]//span[contains(., 'Apply')]")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/SsoController.java
Patch:
@@ -68,7 +68,6 @@ public ModelAndView signin() throws Exception {
     @GetMapping("token")
     @ResponseBody
     public RestResponse token() throws Exception {
-
         // Check SSO enable status
         ApiAlertException.throwIfTrue(
             !ssoEnable,

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/AccessTokenServiceImpl.java
Patch:
@@ -67,7 +67,7 @@ public RestResponse create(Long userId, String description) {
             JWTUtil.sign(
                 user.getUserId(), user.getUsername(), user.getSalt(),
                 AuthenticationType.OPENAPI));
-        JWTToken jwtToken = new JWTToken(token, AccessToken.DEFAULT_EXPIRE_TIME);
+        JWTToken jwtToken = new JWTToken(token, AccessToken.DEFAULT_EXPIRE_TIME, AuthenticationType.SIGN.get());
 
         AccessToken accessToken = new AccessToken();
         accessToken.setToken(jwtToken.getToken());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/bean/OpenAPISchema.java
Patch:
@@ -29,6 +29,8 @@ public class OpenAPISchema {
 
     private String url;
 
+    private String method;
+
     private List<Schema> header;
 
     private List<Schema> schema;

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/ExternalLinkTest.java
Patch:
@@ -32,7 +32,7 @@
 import static org.assertj.core.api.Assertions.assertThat;
 
 @StreamPark(composeFiles = "docker/basic/docker-compose.yaml")
-public class ExternalLinkPageTest {
+public class ExternalLinkTest {
 
     private static RemoteWebDriver browser;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/domain/router/RouterTree.java
Patch:
@@ -81,8 +81,6 @@ public RouterTree(Menu menu) {
         this.setTitle(menu.getMenuName());
         this.setIcon(menu.getIcon());
         this.setComponent(menu.getComponent());
-        this.setCreateTime(menu.getCreateTime());
-        this.setModifyTime(menu.getModifyTime());
         this.setPath(menu.getPath());
         this.setOrder(menu.getOrderNum());
         this.setPermission(menu.getPerms());

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/UploadManagementTest.java
Patch:
@@ -87,7 +87,7 @@ void testCreateUpload() {
     @Order(20)
     void testCreateDuplicateUpload() {
         final UploadsPage uploadsPage = new UploadsPage(browser);
-        browser.navigate().refresh();
+
         uploadsPage.createUpload(engineType, resourceType, resourceName, mavenPom, description);
 
         Awaitility.await()

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/SettingController.java
Patch:
@@ -71,7 +71,7 @@ public RestResponse update(Setting setting) {
     @PostMapping("docker")
     @RequiresPermissions("setting:view")
     public RestResponse docker() {
-        DockerConfig dockerConfig = DockerConfig.fromSetting();
+        DockerConfig dockerConfig = settingService.getDockerConfig();
         return RestResponse.success(dockerConfig);
     }
 

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/system/RoleManagementPage.java
Patch:
@@ -141,7 +141,7 @@ public class CreateRoleForm {
         @FindBy(xpath = "//div[@class='scrollbar__view']//*[@id='form_item_roleName']")
         private WebElement inputRoleName;
 
-        @FindBy(id = "form_item_remark")
+        @FindBy(id = "form_item_description")
         private WebElement inputDescription;
 
         @FindBys({

File: streampark-common/src/main/java/org/apache/streampark/common/enums/FlinkDevelopmentMode.java
Patch:
@@ -34,6 +34,7 @@ public enum FlinkDevelopmentMode {
 
     /** Py flink Mode */
     PYFLINK("Python Flink", 3);
+
     private final String name;
 
     private final Integer mode;

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/ApplicationsFlink116OnYarnWithFlinkSQLTest.java
Patch:
@@ -213,9 +213,8 @@ void testReleaseFlinkApplicationOnYarnPerJobMode() {
                                 .anyMatch(it -> it.contains("SUCCESS")));
     }
 
-    // This test cannot be executed due to a bug, and will be put online after issue #3761 fixed
-    // @Test
-    // @Order(70)
+    @Test
+    @Order(70)
     void testStartFlinkApplicationOnYarnPerJobMode() {
         final ApplicationsPage applicationsPage = new ApplicationsPage(browser);
 

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/cases/ApplicationsFlink117OnYarnWithFlinkSQLTest.java
Patch:
@@ -214,9 +214,8 @@ void testReleaseFlinkApplicationOnYarnPerJobMode() {
                                 .anyMatch(it -> it.contains("SUCCESS")));
     }
 
-    // This test cannot be executed due to a bug, and will be put online after issue #3761 fixed
-    // @Test
-    // @Order(70)
+    @Test
+    @Order(70)
     void testStartFlinkApplicationOnYarnPerJobMode() {
         final ApplicationsPage applicationsPage = new ApplicationsPage(browser);
 

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/common/Constants.java
Patch:
@@ -23,5 +23,5 @@
 
 @UtilityClass
 public class Constants {
-    public static final Integer DEFAULT_SLEEP_SECONDS = 1000;
+  public static final Integer DEFAULT_SLEEP_SECONDS = 1000;
 }

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/flink/applications/entity/ApplicationsDynamicParams.java
Patch:
@@ -17,11 +17,11 @@
  * under the License.
  *
  */
-package org.apache.streampark.e2e.pages.apacheflink.applications.entity;
+package org.apache.streampark.e2e.pages.flink.applications.entity;
 
 import lombok.Data;
 
 @Data
 public class ApplicationsDynamicParams {
-    private String flinkSQL;
+  private String flinkSQL;
 }

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/system/entity/UserManagementStatus.java
Patch:
@@ -20,6 +20,6 @@
 package org.apache.streampark.e2e.pages.system.entity;
 
 public enum UserManagementStatus {
-    LOCKED,
-    EFFECTIVE
+  LOCKED,
+  EFFECTIVE
 }

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/system/entity/UserManagementUserType.java
Patch:
@@ -20,6 +20,6 @@
 package org.apache.streampark.e2e.pages.system.entity;
 
 public enum UserManagementUserType {
-    ADMIN,
-    USER
+  ADMIN,
+  USER
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -208,6 +208,9 @@ public void updateResource(Resource resource) {
       }
     }
 
+    if (resource.getResourceType() == ResourceTypeEnum.FLINK_APP) {
+      findResource.setMainClass(resource.getMainClass());
+    }
     findResource.setDescription(resource.getDescription());
     baseMapper.updateById(findResource);
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -510,7 +510,7 @@ private FlinkK8sApplicationBuildRequest buildFlinkK8sApplicationBuildRequest(
             app.getDevelopmentMode(),
             flinkEnv.getFlinkVersion(),
             getMergedDependencyInfo(app),
-            app.getClusterId(),
+            app.getJobName(),
             app.getK8sNamespace(),
             app.getFlinkImage(),
             app.getK8sPodTemplates(),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SettingServiceImpl.java
Patch:
@@ -153,6 +153,7 @@ public ResponseResult checkDocker(DockerConfig dockerConfig) {
         result.setStatus(500);
         result.setMsg("Failed to validate Docker registry, error: " + e.getMessage());
       }
+      log.warn("Failed to validate Docker registry, error:", e);
     }
     return result;
   }

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/apacheflink/applications/ApplicationForm.java
Patch:
@@ -22,6 +22,7 @@
 import lombok.Getter;
 import lombok.SneakyThrows;
 import org.apache.streampark.e2e.pages.apacheflink.applications.entity.ApplicationsDynamicParams;
+import org.apache.streampark.e2e.pages.common.Constants;
 import org.openqa.selenium.JavascriptExecutor;
 import org.openqa.selenium.WebDriver;
 import org.openqa.selenium.WebElement;
@@ -78,7 +79,7 @@ public ApplicationForm addApplication(DevelopmentMode developmentMode,
                                           String applicationName,
                                           String flinkVersion,
                                           ApplicationsDynamicParams applicationsDynamicParams) {
-        Thread.sleep(1000);
+        Thread.sleep(Constants.DEFAULT_SLEEP_SECONDS);
         new WebDriverWait(driver, Duration.ofSeconds(10)).until(ExpectedConditions.elementToBeClickable(buttonDevelopmentModeDropdown));
         buttonDevelopmentModeDropdown.click();
         new WebDriverWait(driver, Duration.ofSeconds(10)).until(ExpectedConditions.visibilityOfAllElements(selectDevelopmentMode));

File: streampark-e2e/streampark-e2e-case/src/test/java/org/apache/streampark/e2e/pages/common/NavBarPage.java
Patch:
@@ -59,7 +59,7 @@ public NavBarPage(RemoteWebDriver driver) {
     public <T extends NavBarItem> T goToNav(Class<T> nav) {
         if (nav == ApacheFlinkPage.class) {
             new WebDriverWait(driver, Duration.ofSeconds(10)).until(ExpectedConditions.elementToBeClickable(apacheFlinkTab));
-            String tabOpenStateXpath = "//span[contains(@class, 'ml-2') and contains(@class, 'streampark-simple-menu-sub-title') and contains(text(), 'Apache Flink')]/../../li[contains(@class, 'streampark-menu-opened')]";
+            String tabOpenStateXpath = "//span[contains(@class, 'ml-2') and contains(@class, 'streampark-simple-menu-sub-title') and contains(text(), 'Apache Flink')]/../parent::li[contains(@class, 'streampark-menu-opened')]";
             if (driver.findElements(By.xpath(tabOpenStateXpath)).isEmpty()) {
                 apacheFlinkTab.click();
             }
@@ -68,7 +68,7 @@ public <T extends NavBarItem> T goToNav(Class<T> nav) {
 
         if (nav == SystemPage.class) {
             new WebDriverWait(driver, Duration.ofSeconds(10)).until(ExpectedConditions.elementToBeClickable(systemTab));
-            String tabOpenStateXpath = "//span[contains(@class, 'ml-2') and contains(@class, 'streampark-simple-menu-sub-title') and contains(text(), 'System')]/../../li[contains(@class, 'streampark-menu-opened')]";
+            String tabOpenStateXpath = "//span[contains(@class, 'ml-2') and contains(@class, 'streampark-simple-menu-sub-title') and contains(text(), 'System')]/../parent::li[contains(@class, 'streampark-menu-opened')]";
             if (driver.findElements(By.xpath(tabOpenStateXpath)).isEmpty()) {
                 systemTab.click();
             }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/domain/ApiDocConstant.java
Patch:
@@ -20,5 +20,5 @@
 /** Interface document constants */
 public class ApiDocConstant {
 
-  public static final String FLINK_APP_OP_TAG = "FLINK_APPLICATION_OPERATION_TAG";
+  public static final String OPENAPI_TAG = "OpenAPI";
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/domain/ResponseCode.java
Patch:
@@ -23,6 +23,8 @@ public interface ResponseCode {
 
   Long CODE_FAIL = 500L;
 
+  Long CODE_UNAUTHORIZED = 401L;
+
   Long CODE_FORBIDDEN = 403L;
 
   Long CODE_FAIL_ALERT = 501L;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/annotation/AppUpdated.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.core.annotation;
 
-import org.apache.streampark.console.core.aspect.ConsoleAspect;
+import org.apache.streampark.console.core.aspect.StreamParkAspect;
 import org.apache.streampark.console.core.watcher.FlinkAppHttpWatcher;
 
 import org.aspectj.lang.ProceedingJoinPoint;
@@ -31,7 +31,7 @@
  * In the controller({@link org.apache.streampark.console.core.controller}), If some method causes
  * application state update, need to add this annotation, This annotation marks which methods will
  * cause the application to be updated, Will work together with {@link
- * ConsoleAspect#appUpdated(ProceedingJoinPoint)}, The final purpose will be refresh {@link
+ * StreamParkAspect#appUpdated(ProceedingJoinPoint)}, The final purpose will be refresh {@link
  * FlinkAppHttpWatcher#WATCHING_APPS}, Make the state of the job consistent with the database
  */
 @Target(ElementType.METHOD)

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/annotation/OpenAPI.java
Patch:
@@ -24,6 +24,6 @@
 
 @Target(ElementType.METHOD)
 @Retention(RetentionPolicy.RUNTIME)
-public @interface ApiAccess {
+public @interface OpenAPI {
   boolean value() default true;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/bean/AlertTemplate.java
Patch:
@@ -67,7 +67,7 @@ public static AlertTemplate of(Application application, FlinkAppStateEnum appSta
     return new AlertTemplateBuilder()
         .setDuration(application.getStartTime(), application.getEndTime())
         .setJobName(application.getJobName())
-        .setLink(application.getFlinkExecutionMode(), application.getAppId())
+        .setLink(application.getFlinkExecutionMode(), application.getClusterId())
         .setStartTime(application.getStartTime())
         .setEndTime(application.getEndTime())
         .setRestart(application.isNeedRestartOnFailed(), application.getRestartCount())
@@ -87,7 +87,7 @@ public static AlertTemplate of(Application application, CheckPointStatusEnum sta
     return new AlertTemplateBuilder()
         .setDuration(application.getStartTime(), application.getEndTime())
         .setJobName(application.getJobName())
-        .setLink(application.getFlinkExecutionMode(), application.getAppId())
+        .setLink(application.getFlinkExecutionMode(), application.getClusterId())
         .setStartTime(application.getStartTime())
         .setType(2)
         .setCpFailureRateInterval(

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/alert/impl/LarkAlertNotifyServiceImpl.java
Patch:
@@ -134,6 +134,7 @@ private void sendMessage(AlertLarkParams params, Map<String, Object> body) throw
    * @return the webhook
    */
   private String getWebhook(AlertLarkParams params) {
+    larkProxyUrl = larkProxyUrl.replaceFirst("/open-apis/bot/v2/hook/(.*)", "");
     String url = String.format(larkProxyUrl + "/open-apis/bot/v2/hook/%s", params.getToken());
     if (log.isDebugEnabled()) {
       log.debug("The alarm robot url of Lark is {}", url);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ExternalLinkServiceImpl.java
Patch:
@@ -90,7 +90,7 @@ private void renderLinkUrl(ExternalLink link, Application app) {
     Map<String, String> placeholderValueMap = new HashMap<>();
     placeholderValueMap.put(PlaceholderTypeEnum.JOB_ID.get(), app.getJobId());
     placeholderValueMap.put(PlaceholderTypeEnum.JOB_NAME.get(), app.getJobName());
-    placeholderValueMap.put(PlaceholderTypeEnum.YARN_ID.get(), app.getAppId());
+    placeholderValueMap.put(PlaceholderTypeEnum.YARN_ID.get(), app.getClusterId());
     PropertyPlaceholderHelper propertyPlaceholderHelper = new PropertyPlaceholderHelper("{", "}");
     link.setRenderedLinkUrl(
         propertyPlaceholderHelper.replacePlaceholders(

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -26,9 +26,9 @@
 import org.apache.streampark.console.core.bean.ResponseResult;
 import org.apache.streampark.console.core.entity.FlinkCluster;
 import org.apache.streampark.console.core.mapper.FlinkClusterMapper;
-import org.apache.streampark.console.core.service.CommonService;
 import org.apache.streampark.console.core.service.FlinkClusterService;
 import org.apache.streampark.console.core.service.FlinkEnvService;
+import org.apache.streampark.console.core.service.ServiceHelper;
 import org.apache.streampark.console.core.service.YarnQueueService;
 import org.apache.streampark.console.core.service.application.ApplicationInfoService;
 import org.apache.streampark.console.core.watcher.FlinkClusterWatcher;
@@ -82,7 +82,7 @@ public class FlinkClusterServiceImpl extends ServiceImpl<FlinkClusterMapper, Fli
 
   @Autowired private FlinkEnvService flinkEnvService;
 
-  @Autowired private CommonService commonService;
+  @Autowired private ServiceHelper serviceHelper;
 
   @Autowired private ApplicationInfoService applicationInfoService;
 
@@ -142,7 +142,7 @@ public ResponseResult check(FlinkCluster cluster) {
 
   @Override
   public Boolean create(FlinkCluster flinkCluster) {
-    flinkCluster.setUserId(commonService.getUserId());
+    flinkCluster.setUserId(serviceHelper.getUserId());
     return internalCreate(flinkCluster);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -37,9 +37,9 @@
 import org.apache.streampark.console.core.entity.Resource;
 import org.apache.streampark.console.core.enums.ResourceTypeEnum;
 import org.apache.streampark.console.core.mapper.ResourceMapper;
-import org.apache.streampark.console.core.service.CommonService;
 import org.apache.streampark.console.core.service.FlinkSqlService;
 import org.apache.streampark.console.core.service.ResourceService;
+import org.apache.streampark.console.core.service.ServiceHelper;
 import org.apache.streampark.console.core.service.application.ApplicationManageService;
 import org.apache.streampark.flink.packer.maven.Artifact;
 import org.apache.streampark.flink.packer.maven.MavenTool;
@@ -96,7 +96,7 @@ public class ResourceServiceImpl extends ServiceImpl<ResourceMapper, Resource>
 
   @Autowired private ApplicationManageService applicationManageService;
 
-  @Autowired private CommonService commonService;
+  @Autowired private ServiceHelper serviceHelper;
 
   @Autowired private FlinkSqlService flinkSqlService;
 
@@ -150,7 +150,7 @@ public void addResource(Resource resource) throws Exception {
       transferTeamResource(resource.getTeamId(), upFile);
     }
 
-    resource.setCreatorId(commonService.getUserId());
+    resource.setCreatorId(serviceHelper.getUserId());
     this.save(resource);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/VariableServiceImpl.java
Patch:
@@ -26,8 +26,8 @@
 import org.apache.streampark.console.core.entity.Variable;
 import org.apache.streampark.console.core.enums.ReleaseStateEnum;
 import org.apache.streampark.console.core.mapper.VariableMapper;
-import org.apache.streampark.console.core.service.CommonService;
 import org.apache.streampark.console.core.service.FlinkSqlService;
+import org.apache.streampark.console.core.service.ServiceHelper;
 import org.apache.streampark.console.core.service.VariableService;
 import org.apache.streampark.console.core.service.application.ApplicationManageService;
 
@@ -69,7 +69,7 @@ public class VariableServiceImpl extends ServiceImpl<VariableMapper, Variable>
 
   @Autowired private FlinkSqlService flinkSqlService;
 
-  @Autowired private CommonService commonService;
+  @Autowired private ServiceHelper serviceHelper;
 
   @Override
   public void createVariable(Variable variable) {
@@ -78,7 +78,7 @@ public void createVariable(Variable variable) {
         this.findByVariableCode(variable.getTeamId(), variable.getVariableCode()) != null,
         "Sorry, the variable code already exists.");
 
-    variable.setCreatorId(commonService.getUserId());
+    variable.setCreatorId(serviceHelper.getUserId());
     this.save(variable);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/AccessTokenService.java
Patch:
@@ -32,13 +32,11 @@ public interface AccessTokenService extends IService<AccessToken> {
    * Generate token based on user ID's expiration time and description
    *
    * @param userId User id
-   * @param expireTime expiration
    * @param description more description
    * @return RestResponse
    * @throws InternalException
    */
-  RestResponse generateToken(Long userId, String expireTime, String description)
-      throws InternalException;
+  RestResponse create(Long userId, String description) throws InternalException;
 
   /**
    * Retrieves a page of {@link AccessToken} objects based on the provided parameters.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/UserService.java
Patch:
@@ -166,4 +166,6 @@ public interface UserService extends IService<User> {
    * @return RestResponse
    */
   RestResponse getLoginUserInfo(User user);
+
+  void deleteUser(Long userId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/TeamServiceImpl.java
Patch:
@@ -21,8 +21,8 @@
 import org.apache.streampark.console.base.exception.ApiAlertException;
 import org.apache.streampark.console.base.mybatis.pager.MybatisPager;
 import org.apache.streampark.console.core.enums.UserTypeEnum;
-import org.apache.streampark.console.core.service.CommonService;
 import org.apache.streampark.console.core.service.ProjectService;
+import org.apache.streampark.console.core.service.ServiceHelper;
 import org.apache.streampark.console.core.service.VariableService;
 import org.apache.streampark.console.core.service.application.ApplicationInfoService;
 import org.apache.streampark.console.system.entity.Team;
@@ -61,7 +61,7 @@ public class TeamServiceImpl extends ServiceImpl<TeamMapper, Team> implements Te
 
   @Autowired private VariableService variableService;
 
-  @Autowired private CommonService commonService;
+  @Autowired private ServiceHelper serviceHelper;
 
   @Override
   public IPage<Team> getPage(Team team, RestRequest request) {
@@ -93,7 +93,7 @@ public void createTeam(Team team) {
 
   @Override
   public void removeById(Long teamId) {
-    log.info("{} Proceed delete team[Id={}]", commonService.getCurrentUser().getUsername(), teamId);
+    log.info("{} Proceed delete team[Id={}]", serviceHelper.getLoginUser().getUsername(), teamId);
     Team team = this.getById(teamId);
 
     ApiAlertException.throwIfNull(team, "The team[Id=%s] doesn't exist.", teamId);

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/AccessTokenServiceTest.java
Patch:
@@ -43,7 +43,7 @@ public class AccessTokenServiceTest extends SpringUnitTestBase {
   void testCrudToken() throws Exception {
     Long mockUserId = 100000L;
     String expireTime = "9999-01-01 00:00:00";
-    RestResponse restResponse = accessTokenService.generateToken(mockUserId, expireTime, "");
+    RestResponse restResponse = accessTokenService.create(mockUserId, "");
     Assertions.assertNotNull(restResponse);
     Assertions.assertInstanceOf(AccessToken.class, restResponse.get(RestResponse.DATA_KEY));
 
@@ -57,7 +57,7 @@ void testCrudToken() throws Exception {
     Assertions.assertEquals("admin", username);
     User user = userService.getByUsername(username);
     Assertions.assertNotNull(user);
-    Assertions.assertTrue(JWTUtil.verify(jwtToken.getToken(), username));
+    Assertions.assertTrue(JWTUtil.verify(jwtToken.getToken(), username, user.getSalt()));
 
     // list
     AccessToken mockToken1 = new AccessToken();

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/alert/AlertServiceTest.java
Patch:
@@ -159,7 +159,7 @@ void testAlert() {
     Application application = new Application();
     application.setStartTime(new Date());
     application.setJobName("Test My Job");
-    application.setAppId("1234567890");
+    application.setClusterId("1234567890");
     application.setAlertId(1L);
 
     application.setRestartCount(5);
@@ -202,7 +202,7 @@ private AlertTemplate getAlertBaseInfo(Application application) {
       duration = application.getEndTime().getTime() - application.getStartTime().getTime();
     }
     String format = "%s/proxy/%s/";
-    String url = String.format(format, YarnUtils.getRMWebAppURL(false), application.getAppId());
+    String url = String.format(format, YarnUtils.getRMWebAppURL(false), application.getClusterId());
 
     AlertTemplate template = new AlertTemplate();
     template.setJobName(application.getJobName());

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/system/authentication/JWTTest.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.streampark.common.util.DateUtils;
 import org.apache.streampark.console.SpringUnitTestBase;
+import org.apache.streampark.console.core.enums.AuthenticationType;
 import org.apache.streampark.console.system.entity.AccessToken;
 
 import com.auth0.jwt.JWT;
@@ -38,6 +39,8 @@ void testExpireTime() {
         JWTUtil.sign(
             10000L,
             userName,
+            "streampark",
+            AuthenticationType.SIGN,
             DateUtils.getTime(expireTime, DateUtils.fullFormat(), TimeZone.getDefault()));
 
     assert token != null;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -712,7 +712,7 @@ private DependencyInfo getMergedDependencyInfo(Application application) {
               });
       return dependencyInfo.merge(mvnArtifacts, jarLibs);
     } catch (Exception e) {
-      log.warn("Merge team dependency failed.", e);
+      log.error("Merge team dependency failed.", e);
       return dependencyInfo;
     }
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -347,7 +347,7 @@ public List<Map<String, Object>> listConf(Project project) {
       }
       return confList;
     } catch (Exception e) {
-      log.info(e.getMessage());
+      log.error("List project conf failed", e);
     }
     return null;
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SavePointServiceImpl.java
Patch:
@@ -399,7 +399,7 @@ private Optional<Integer> tryGetChkNumRetainedFromDynamicProps(String dynamicPro
       log.warn(
           "This value of dynamicProperties key: state.checkpoints.num-retained is invalid, must be greater than 0");
     } catch (NumberFormatException e) {
-      log.warn(
+      log.error(
           "This value of dynamicProperties key: state.checkpoints.num-retained invalid, must be number");
     }
     return Optional.empty();
@@ -428,7 +428,7 @@ private int getChkNumRetainedFromFlinkEnv(
           "The value of key: state.checkpoints.num-retained in flink-conf.yaml is invalid, must be greater than 0, default value: {} will be used",
           MAX_RETAINED_CHECKPOINTS.defaultValue());
     } catch (NumberFormatException e) {
-      log.warn(
+      log.error(
           "The value of key: state.checkpoints.num-retained in flink-conf.yaml is invalid, must be number, flink env: {}, default value: {} will be used",
           flinkEnv.getFlinkHome(),
           flinkConfNumRetained);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SettingServiceImpl.java
Patch:
@@ -191,7 +191,7 @@ public SenderEmail getSenderEmail() {
       }
       return senderEmail;
     } catch (Exception e) {
-      log.warn("Fault Alert Email is not set.");
+      log.error("Fault Alert Email is not set.");
     }
     return null;
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SqlCompleteServiceImpl.java
Patch:
@@ -145,7 +145,7 @@ public SqlCompleteFstTree() {
         }
         scanner.close();
       } catch (Exception e) {
-        log.info("Error while FstTree ini that: {}", e.getMessage());
+        log.error("Error while FstTree ini that: {}", e.getMessage());
       }
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/authentication/SsoShiroPlugin.java
Patch:
@@ -39,7 +39,9 @@
 @Slf4j
 /** Plugin for {@link ShiroConfig.java} to load SSO config if enabled */
 public class SsoShiroPlugin {
+
   @Autowired private Config ssoConfig;
+
   @Autowired private ShiroService shiroService;
 
   @Value("${sso.enable:#{false}}")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/SsoController.java
Patch:
@@ -49,7 +49,7 @@ public class SsoController {
 
   @Autowired private Authenticator authenticator;
 
-  @Value("${pac4j.properties.principalNameAttribute:#{null}}")
+  @Value("${sso.properties.principalNameAttribute:#{null}}")
   private String principalNameAttribute;
 
   @Value("${sso.enable:#{false}}")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ProjectController.java
Patch:
@@ -105,7 +105,7 @@ public RestResponse list(Project project, RestRequest restRequest) {
   @Operation(summary = "List git project branches")
   @PostMapping("branches")
   public RestResponse branches(Project project) {
-    List<String> branches = project.getAllBranches();
+    List<String> branches = projectService.getAllBranches(project);
     return RestResponse.success().data(branches);
   }
 
@@ -120,7 +120,7 @@ public RestResponse delete(Long id) {
   @Operation(summary = "Authenticate git project")
   @PostMapping("gitcheck")
   public RestResponse gitCheck(Project project) {
-    GitAuthorizedErrorEnum error = project.gitCheck();
+    GitAuthorizedErrorEnum error = projectService.gitCheck(project);
     return RestResponse.success().data(error.getType());
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Project.java
Patch:
@@ -77,6 +77,9 @@ public class Project implements Serializable {
   @TableField(updateStrategy = FieldStrategy.IGNORED)
   private String prvkeyPath;
 
+  /** No salt value is returned */
+  @JsonIgnore private String salt;
+
   /** 1:git 2:svn */
   private Integer repository;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -88,8 +88,8 @@ public boolean create(FlinkEnv version) throws Exception {
     long count = this.baseMapper.selectCount(null);
     version.setIsDefault(count == 0);
     version.setCreateTime(new Date());
-    version.doSetFlinkConf();
     version.doSetVersion();
+    version.doSetFlinkConf();
     return save(version);
   }
 

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/YarnQueueServiceTest.java
Patch:
@@ -84,7 +84,7 @@ void testFindYarnQueues() {
 
     queryParams.setTeamId(targetTeamId);
     RestRequest request = new RestRequest();
-    request.setPageSize(2);
+    request.setPageSize(5);
     request.setPageNum(1);
     request.setSortField("create_time");
     request.setSortOrder("desc");
@@ -93,7 +93,7 @@ void testFindYarnQueues() {
             yarnQueues.getRecords().stream()
                 .map(YarnQueue::getQueueLabel)
                 .collect(Collectors.toList()))
-        .containsExactlyInAnyOrder(q3AtL3, q3AtL1);
+        .containsExactlyInAnyOrder(q3AtL3, q3AtL1, q2AtL1, q1AtL1);
 
     // Test for 1st page, size = 2, order by create time with queue_label
     queryParams.setQueueLabel("q3");

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/SettingController.java
Patch:
@@ -43,7 +43,7 @@
 @Slf4j
 @Validated
 @RestController
-@RequestMapping("flink/setting")
+@RequestMapping("setting")
 public class SettingController {
 
   @Autowired private SettingService settingService;
@@ -122,7 +122,7 @@ public RestResponse updateEmail(SenderEmail senderEmail) {
   }
 
   @Operation(summary = "Check hadoop status")
-  @PostMapping("checkHadoop")
+  @PostMapping("check/hadoop")
   public RestResponse checkHadoop() {
     try {
       HadoopUtils.hdfs().getStatus();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SavePointServiceImpl.java
Patch:
@@ -146,7 +146,7 @@ public String getSavePointPath(Application appParam) throws Exception {
     // task, see if Application conf is configured when the task is defined, if checkpoints are
     // configured
     // and enabled, read `state.savepoints.dir`
-    savepointPath = getSavepointFromAppCfgIfStreamParkOrSQLJob(application);
+    savepointPath = getSavepointFromConfig(application);
     if (StringUtils.isNotBlank(savepointPath)) {
       return savepointPath;
     }
@@ -340,7 +340,7 @@ public String getSavepointFromDynamicProps(String dynamicProps) {
    */
   @VisibleForTesting
   @Nullable
-  public String getSavepointFromAppCfgIfStreamParkOrSQLJob(Application application) {
+  public String getSavepointFromConfig(Application application) {
     if (!application.isStreamParkJob() && !application.isFlinkSqlJob()) {
       return null;
     }

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-doris/src/main/java/org/apache/streampark/flink/connector/doris/bean/DorisSinkBufferEntry.java
Patch:
@@ -26,11 +26,11 @@ public class DorisSinkBufferEntry implements Serializable {
 
   private static final long serialVersionUID = 1L;
 
-  public ArrayList<byte[]> getBuffer() {
+  public List<byte[]> getBuffer() {
     return buffer;
   }
 
-  private ArrayList<byte[]> buffer = new ArrayList<>();
+  private List<byte[]> buffer = new ArrayList<>();
   private int batchCount = 0;
   private long batchSize = 0;
   private String label;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/AlertRestTemplateConfig.java
Patch:
@@ -21,6 +21,7 @@
 import org.springframework.context.annotation.Configuration;
 import org.springframework.web.client.RestTemplate;
 
+/** Alarm module configuration */
 @Configuration
 public class AlertRestTemplateConfig {
   /**

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/OpenapiConfig.java
Patch:
@@ -35,6 +35,7 @@
 
 import java.util.Collections;
 
+/** Provide interface documentation externally */
 @EnableKnife4j
 @Configuration
 @ConditionalOnWebApplication

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/P6spySqlFormatConfig.java
Patch:
@@ -25,6 +25,7 @@
 
 import java.time.LocalDateTime;
 
+/** Specifies the log output format of SQL statements in the console */
 public class P6spySqlFormatConfig implements MessageFormattingStrategy {
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/domain/ApiDocConstant.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.base.domain;
 
+/** Interface document constants */
 public class ApiDocConstant {
 
   public static final String FLINK_APP_OP_TAG = "FLINK_APPLICATION_OPERATION_TAG";

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/domain/Constant.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.base.domain;
 
+/** System constants */
 public class Constant {
 
   // order rules: descend

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/exception/ApplicationException.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.base.exception;
 
+/** Applies to all application exceptions */
 public class ApplicationException extends ApiAlertException {
   public ApplicationException(String message) {
     super(message);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/exception/IllegalFileTypeException.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.base.exception;
 
+/** This exception is thrown when there is an error in the file type */
 public class IllegalFileTypeException extends ApiAlertException {
   public IllegalFileTypeException(String message) {
     super(message);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/handler/GlobalExceptionHandler.java
Patch:
@@ -43,6 +43,7 @@
 import java.util.List;
 import java.util.Set;
 
+/** A global exception handler that takes over all exceptions */
 @Slf4j
 @RestControllerAdvice
 @Order(value = Ordered.HIGHEST_PRECEDENCE)

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/interceptor/UploadFileTypeInterceptor.java
Patch:
@@ -42,6 +42,7 @@
 import java.io.InputStream;
 import java.util.Map;
 
+/** An interceptor used to handle file uploads */
 @Component
 public class UploadFileTypeInterceptor implements HandlerInterceptor {
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/util/GitUtils.java
Patch:
@@ -45,7 +45,7 @@
 import java.util.Collections;
 import java.util.List;
 
-/** */
+/** used to build project and project build task */
 public class GitUtils {
 
   private GitUtils() {}

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/util/JacksonUtils.java
Patch:
@@ -28,6 +28,7 @@
 
 import java.text.SimpleDateFormat;
 
+/** Serialization utils */
 public final class JacksonUtils {
 
   private JacksonUtils() {}

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/AccessTokenStateEnum.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.core.enums;
 
+/** Used to authenticate access rights */
 public enum AccessTokenStateEnum {
 
   /** not added token */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/AppExistsStateEnum.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.core.enums;
 
+/** Application status, whether it exists, and where it exists */
 public enum AppExistsStateEnum {
 
   /** no exists */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/BuildStateEnum.java
Patch:
@@ -19,6 +19,7 @@
 
 import java.util.Arrays;
 
+/** Describe the construction status of Project */
 public enum BuildStateEnum {
 
   /** has changed, need rebuild */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/CheckPointStatusEnum.java
Patch:
@@ -19,6 +19,7 @@
 
 import java.util.Arrays;
 
+/** Describe the status of Check Point */
 public enum CheckPointStatusEnum {
   /** IN_PROGRESS */
   IN_PROGRESS(1),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/CheckPointTypeEnum.java
Patch:
@@ -19,6 +19,7 @@
 
 import java.util.Arrays;
 
+/** Describe the type of Check Point */
 public enum CheckPointTypeEnum {
   /** CHECKPOINT */
   CHECKPOINT(1),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/FailoverStrategyEnum.java
Patch:
@@ -19,6 +19,7 @@
 
 import java.util.Arrays;
 
+/** Provides how to deal with problems when encountering them */
 public enum FailoverStrategyEnum {
 
   /** send alert */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/FlinkAppStateEnum.java
Patch:
@@ -23,6 +23,7 @@
 
 import scala.Enumeration;
 
+/** Describe the status of Flink Application */
 @Getter
 public enum FlinkAppStateEnum {
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/GatewayTypeEnum.java
Patch:
@@ -22,6 +22,7 @@
 
 import java.util.Arrays;
 
+/** Flink GateWay Type */
 @Getter
 public enum GatewayTypeEnum {
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/GitAuthorizedErrorEnum.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.core.enums;
 
+/** Git authentication results */
 public enum GitAuthorizedErrorEnum {
 
   /** Success. */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/GitCredentialEnum.java
Patch:
@@ -19,6 +19,7 @@
 
 import java.util.Arrays;
 
+/** Git connection method */
 public enum GitCredentialEnum {
   HTTPS(1),
   SSH(2);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/NoticeTypeEnum.java
Patch:
@@ -19,6 +19,7 @@
 
 import java.util.Arrays;
 
+/** notification type */
 public enum NoticeTypeEnum {
   /** exception */
   EXCEPTION(1),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/OperationEnum.java
Patch:
@@ -21,6 +21,7 @@
 
 import java.util.Arrays;
 
+/** Operation type */
 @Getter
 public enum OperationEnum {
   RELEASE(0),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/OptionStateEnum.java
Patch:
@@ -21,6 +21,7 @@
 
 import java.util.Arrays;
 
+/** Option status */
 @Getter
 public enum OptionStateEnum {
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/ReleaseStateEnum.java
Patch:
@@ -19,6 +19,7 @@
 
 import java.util.Arrays;
 
+/** Release Status */
 public enum ReleaseStateEnum {
 
   /** release failed */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/SettingService.java
Patch:
@@ -26,6 +26,7 @@
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
+/** System setting service */
 public interface SettingService extends IService<Setting> {
 
   Map<String, Setting> SETTINGS = new ConcurrentHashMap<>();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/authentication/JWTUtil.java
Patch:
@@ -33,6 +33,7 @@
 
 import java.util.Date;
 
+/** Verification and parsing Token */
 @Slf4j
 public class JWTUtil {
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/RoleController.java
Patch:
@@ -21,7 +21,7 @@
 import org.apache.streampark.console.base.domain.RestResponse;
 import org.apache.streampark.console.system.entity.Role;
 import org.apache.streampark.console.system.entity.RoleMenu;
-import org.apache.streampark.console.system.service.RoleMenuServie;
+import org.apache.streampark.console.system.service.RoleMenuService;
 import org.apache.streampark.console.system.service.RoleService;
 
 import org.apache.shiro.authz.annotation.RequiresPermissions;
@@ -52,7 +52,7 @@
 public class RoleController {
 
   @Autowired private RoleService roleService;
-  @Autowired private RoleMenuServie roleMenuServie;
+  @Autowired private RoleMenuService roleMenuService;
 
   @Operation(summary = "List roles")
   @PostMapping("list")
@@ -72,7 +72,7 @@ public RestResponse checkRoleName(@NotBlank(message = "{required}") String roleN
   @Operation(summary = "List role menus")
   @PostMapping("menu")
   public RestResponse getRoleMenus(@NotBlank(message = "{required}") String roleId) {
-    List<RoleMenu> roleMenuList = this.roleMenuServie.listByRoleId(roleId);
+    List<RoleMenu> roleMenuList = this.roleMenuService.listByRoleId(roleId);
     List<String> menuIdList =
         roleMenuList.stream()
             .map(roleMenu -> String.valueOf(roleMenu.getMenuId()))

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/MenuServiceImpl.java
Patch:
@@ -26,7 +26,7 @@
 import org.apache.streampark.console.system.entity.User;
 import org.apache.streampark.console.system.mapper.MenuMapper;
 import org.apache.streampark.console.system.service.MenuService;
-import org.apache.streampark.console.system.service.RoleMenuServie;
+import org.apache.streampark.console.system.service.RoleMenuService;
 import org.apache.streampark.console.system.service.UserService;
 
 import org.apache.commons.lang3.StringUtils;
@@ -57,7 +57,7 @@ public class MenuServiceImpl extends ServiceImpl<MenuMapper, Menu> implements Me
 
   @Autowired private UserService userService;
 
-  @Autowired private RoleMenuServie roleMenuServie;
+  @Autowired private RoleMenuService roleMenuService;
 
   @Override
   public List<String> listPermissions(Long userId, Long teamId) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/RoleMenuServiceImpl.java
Patch:
@@ -19,7 +19,7 @@
 
 import org.apache.streampark.console.system.entity.RoleMenu;
 import org.apache.streampark.console.system.mapper.RoleMenuMapper;
-import org.apache.streampark.console.system.service.RoleMenuServie;
+import org.apache.streampark.console.system.service.RoleMenuService;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
 import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;
@@ -33,7 +33,7 @@
 @Service
 @Transactional(propagation = Propagation.SUPPORTS, readOnly = true, rollbackFor = Exception.class)
 public class RoleMenuServiceImpl extends ServiceImpl<RoleMenuMapper, RoleMenu>
-    implements RoleMenuServie {
+    implements RoleMenuService {
 
   @Override
   @Transactional

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/RoleServiceImpl.java
Patch:
@@ -26,7 +26,7 @@
 import org.apache.streampark.console.system.mapper.RoleMapper;
 import org.apache.streampark.console.system.mapper.RoleMenuMapper;
 import org.apache.streampark.console.system.service.MemberService;
-import org.apache.streampark.console.system.service.RoleMenuServie;
+import org.apache.streampark.console.system.service.RoleMenuService;
 import org.apache.streampark.console.system.service.RoleService;
 
 import org.apache.commons.collections.CollectionUtils;
@@ -57,7 +57,7 @@ public class RoleServiceImpl extends ServiceImpl<RoleMapper, Role> implements Ro
 
   @Autowired private MemberService memberService;
 
-  @Autowired private RoleMenuServie roleMenuService;
+  @Autowired private RoleMenuService roleMenuService;
 
   @Override
   public IPage<Role> getPage(Role role, RestRequest request) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/AlertController.java
Patch:
@@ -92,7 +92,7 @@ public RestResponse getAlertConfig(@RequestBody AlertConfigParams params) {
   @PostMapping(value = "/list")
   public RestResponse alertConfigsPaginationList(
       @RequestBody AlertConfigParams params, RestRequest request) {
-    IPage<AlertConfigParams> page = alertConfigService.page(params, request);
+    IPage<AlertConfigParams> page = alertConfigService.page(params.getUserId(), request);
     return RestResponse.success(page);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ConfigController.java
Patch:
@@ -73,7 +73,7 @@ public RestResponse list(ApplicationConfig config, RestRequest request) {
   @Operation(summary = "List application config histories")
   @PostMapping("history")
   public RestResponse history(Application application) {
-    List<ApplicationConfig> history = applicationConfigService.list(application);
+    List<ApplicationConfig> history = applicationConfigService.list(application.getId());
     return RestResponse.success(history);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkClusterController.java
Patch:
@@ -118,7 +118,7 @@ public RestResponse shutdown(FlinkCluster cluster) {
   @Operation(summary = "Delete flink cluster")
   @PostMapping("delete")
   public RestResponse delete(FlinkCluster cluster) {
-    flinkClusterService.remove(cluster);
+    flinkClusterService.remove(cluster.getId());
     return RestResponse.success();
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkSqlController.java
Patch:
@@ -118,7 +118,7 @@ public RestResponse get(String id) throws InternalException {
   @Operation(summary = "List the applications sql histories")
   @PostMapping("history")
   public RestResponse sqlhistory(Application application) {
-    List<FlinkSql> sqlList = flinkSqlService.listFlinkSqlHistory(application);
+    List<FlinkSql> sqlList = flinkSqlService.listFlinkSqlHistory(application.getId());
     return RestResponse.success(sqlList);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ResourceController.java
Patch:
@@ -84,7 +84,7 @@ public RestResponse updateResource(@Valid Resource resource) {
   @DeleteMapping("delete")
   @RequiresPermissions("resource:delete")
   public RestResponse deleteResource(@Valid Resource resource) {
-    this.resourceService.remove(resource);
+    this.resourceService.remove(resource.getId());
     return RestResponse.success();
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ApplicationMapper.java
Patch:
@@ -31,7 +31,7 @@ public interface ApplicationMapper extends BaseMapper<Application> {
 
   IPage<Application> selectPage(Page<Application> page, @Param("app") Application application);
 
-  Application selectApp(@Param("app") Application application);
+  Application selectApp(@Param("id") Long id);
 
   void persistMetrics(@Param("app") Application application);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationConfigService.java
Patch:
@@ -105,10 +105,10 @@ public interface ApplicationConfigService extends IService<ApplicationConfig> {
   /**
    * Retrieves the history of application configurations for a given application.
    *
-   * @param appParam The application for which to retrieve the history.
+   * @param appId The application's id for which to retrieve the history.
    * @return The list of application configurations representing the history.
    */
-  List<ApplicationConfig> list(Application appParam);
+  List<ApplicationConfig> list(Long appId);
 
   /**
    * Reads a template from a file or a database.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkClusterService.java
Patch:
@@ -35,7 +35,7 @@ public interface FlinkClusterService extends IService<FlinkCluster> {
 
   Boolean create(FlinkCluster flinkCluster);
 
-  void remove(FlinkCluster flinkCluster);
+  void remove(Long id);
 
   void update(FlinkCluster flinkCluster);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkSqlService.java
Patch:
@@ -38,7 +38,7 @@ public interface FlinkSqlService extends IService<FlinkSql> {
 
   FlinkSql getLatestFlinkSql(Long appId, boolean decode);
 
-  List<FlinkSql> listFlinkSqlHistory(Application application);
+  List<FlinkSql> listFlinkSqlHistory(Long appId);
 
   FlinkSql getCandidate(Long appId, CandidateTypeEnum type);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ResourceService.java
Patch:
@@ -71,9 +71,9 @@ public interface ResourceService extends IService<Resource> {
   /**
    * delete resource
    *
-   * @param resource
+   * @param id
    */
-  void remove(Resource resource);
+  void remove(Long id);
 
   /**
    * Get resource through team id.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/alert/AlertConfigService.java
Patch:
@@ -26,7 +26,7 @@
 import com.baomidou.mybatisplus.extension.service.IService;
 
 public interface AlertConfigService extends IService<AlertConfig> {
-  IPage<AlertConfigParams> page(AlertConfigParams params, RestRequest request);
+  IPage<AlertConfigParams> page(Long userId, RestRequest request);
 
   boolean exist(AlertConfig alertConfig);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/alert/impl/AlertConfigServiceImpl.java
Patch:
@@ -50,10 +50,10 @@ public class AlertConfigServiceImpl extends ServiceImpl<AlertConfigMapper, Alert
   @Autowired private ApplicationInfoService applicationInfoService;
 
   @Override
-  public IPage<AlertConfigParams> page(AlertConfigParams params, RestRequest request) {
+  public IPage<AlertConfigParams> page(Long userId, RestRequest request) {
     // build query conditions
     LambdaQueryWrapper<AlertConfig> wrapper = new LambdaQueryWrapper<>();
-    wrapper.eq(params.getUserId() != null, AlertConfig::getUserId, params.getUserId());
+    wrapper.eq(userId != null, AlertConfig::getUserId, userId);
 
     Page<AlertConfig> page = MybatisPager.getPage(request);
     IPage<AlertConfig> resultPage = getBaseMapper().selectPage(page, wrapper);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationConfigServiceImpl.java
Patch:
@@ -211,14 +211,14 @@ public IPage<ApplicationConfig> getPage(ApplicationConfig config, RestRequest re
   }
 
   @Override
-  public List<ApplicationConfig> list(Application appParam) {
+  public List<ApplicationConfig> list(Long appId) {
     LambdaQueryWrapper<ApplicationConfig> queryWrapper =
         new LambdaQueryWrapper<ApplicationConfig>()
-            .eq(ApplicationConfig::getAppId, appParam.getId())
+            .eq(ApplicationConfig::getAppId, appId)
             .orderByDesc(ApplicationConfig::getVersion);
 
     List<ApplicationConfig> configList = this.baseMapper.selectList(queryWrapper);
-    fillEffectiveField(appParam.getId(), configList);
+    fillEffectiveField(appId, configList);
     return configList;
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -342,8 +342,7 @@ public void updateClusterState(Long id, ClusterState state) {
   }
 
   @Override
-  public void remove(FlinkCluster cluster) {
-    Long id = cluster.getId();
+  public void remove(Long id) {
     FlinkCluster flinkCluster = getById(id);
     ApiAlertException.throwIfNull(flinkCluster, "Flink cluster not exist, please check.");
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -117,14 +117,14 @@ public void setCandidate(CandidateTypeEnum candidateTypeEnum, Long appId, Long s
   }
 
   @Override
-  public List<FlinkSql> listFlinkSqlHistory(Application application) {
+  public List<FlinkSql> listFlinkSqlHistory(Long appId) {
     LambdaQueryWrapper<FlinkSql> queryWrapper =
         new LambdaQueryWrapper<FlinkSql>()
-            .eq(FlinkSql::getAppId, application.getId())
+            .eq(FlinkSql::getAppId, appId)
             .orderByDesc(FlinkSql::getVersion);
 
     List<FlinkSql> sqlList = this.baseMapper.selectList(queryWrapper);
-    FlinkSql effective = getEffective(application.getId(), false);
+    FlinkSql effective = getEffective(appId, false);
     if (effective != null && !sqlList.isEmpty()) {
       for (FlinkSql sql : sqlList) {
         if (sql.getId().equals(effective.getId())) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -207,8 +207,8 @@ public void updateResource(Resource resource) {
   }
 
   @Override
-  public void remove(Resource resource) {
-    Resource findResource = getById(resource.getId());
+  public void remove(Long id) {
+    Resource findResource = getById(id);
     checkOrElseAlert(findResource);
 
     String filePath =
@@ -224,7 +224,7 @@ public void remove(Resource resource) {
 
     FsOperator.lfs().delete(filePath);
 
-    this.removeById(resource);
+    this.removeById(id);
   }
 
   public List<Resource> listByTeamId(Long teamId) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/MemberController.java
Patch:
@@ -96,7 +96,7 @@ public RestResponse create(@Valid Member member) {
   @DeleteMapping("delete")
   @RequiresPermissions("member:delete")
   public RestResponse delete(Member member) {
-    this.memberService.remove(member);
+    this.memberService.remove(member.getId());
     return RestResponse.success();
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/MemberService.java
Patch:
@@ -47,7 +47,7 @@ public interface MemberService extends IService<Member> {
 
   void createMember(Member member);
 
-  void remove(Member member);
+  void remove(Long id);
 
   void updateMember(Member member);
 }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/ApplicationManageServiceITest.java
Patch:
@@ -110,7 +110,7 @@ void testStartAppOnRemoteSessionMode() throws Exception {
     Application appParam = new Application();
     appParam.setId(100000L);
     appParam.setTeamId(100000L);
-    Application application = applicationManageService.getApp(appParam);
+    Application application = applicationManageService.getApp(appParam.getId());
     application.setFlinkClusterId(1L);
     application.setSqlId(100000L);
     application.setVersionId(1L);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationActionServiceImpl.java
Patch:
@@ -803,7 +803,7 @@ private void doStopped(Application appParam) {
 
   private String getSavePointed(Application appParam) {
     if (appParam.getSavePointed()) {
-      if (appParam.getSavePoint() == null) {
+      if (StringUtils.isBlank(appParam.getSavePoint())) {
         SavePoint savePoint = savePointService.getLatest(appParam.getId());
         if (savePoint != null) {
           return savePoint.getPath();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkEnvController.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.core.controller;
 
+import org.apache.streampark.common.enums.FlinkEnvStatus;
 import org.apache.streampark.console.base.domain.RestResponse;
 import org.apache.streampark.console.base.exception.ApiDetailException;
 import org.apache.streampark.console.core.entity.FlinkEnv;
@@ -52,8 +53,8 @@ public RestResponse list() {
   @Operation(summary = "Verify flink environment")
   @PostMapping("check")
   public RestResponse check(FlinkEnv version) {
-    Integer checkResp = flinkEnvService.check(version);
-    return RestResponse.success(checkResp);
+    FlinkEnvStatus checkResp = flinkEnvService.check(version);
+    return RestResponse.success(checkResp.getCode());
   }
 
   @Operation(summary = "Create flink environment")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -33,7 +33,6 @@
 import org.apache.streampark.console.core.entity.Application;
 import org.apache.streampark.console.core.entity.Project;
 import org.apache.streampark.console.core.enums.BuildStateEnum;
-import org.apache.streampark.console.core.enums.GitCredentialEnum;
 import org.apache.streampark.console.core.enums.ReleaseStateEnum;
 import org.apache.streampark.console.core.mapper.ProjectMapper;
 import org.apache.streampark.console.core.service.ProjectService;
@@ -118,14 +117,13 @@ public boolean update(Project projectParam) {
     project.setName(projectParam.getName());
     project.setUrl(projectParam.getUrl());
     project.setBranches(projectParam.getBranches());
-    project.setGitCredential(projectParam.getGitCredential());
     project.setPrvkeyPath(projectParam.getPrvkeyPath());
     project.setUserName(projectParam.getUserName());
     project.setPassword(projectParam.getPassword());
     project.setPom(projectParam.getPom());
     project.setDescription(projectParam.getDescription());
     project.setBuildArgs(projectParam.getBuildArgs());
-    if (GitCredentialEnum.isSSH(project.getGitCredential())) {
+    if (project.isSshRepositoryUrl()) {
       project.setUserName(null);
     } else {
       project.setPrvkeyPath(null);

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/entity/ProjectTest.java
Patch:
@@ -18,7 +18,6 @@
 package org.apache.streampark.console.core.entity;
 
 import org.apache.streampark.console.core.enums.GitAuthorizedErrorEnum;
-import org.apache.streampark.console.core.enums.GitCredentialEnum;
 
 import lombok.extern.slf4j.Slf4j;
 import org.junit.jupiter.api.BeforeEach;
@@ -35,7 +34,6 @@ class ProjectTest {
   @BeforeEach
   void before() {
     project.setUrl("https://github.com/apache/incubator-streampark.git");
-    project.setGitCredential(GitCredentialEnum.HTTPS.getValue());
   }
 
   @Disabled("This test case can't be runnable due to external service is not available.")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationManageServiceImpl.java
Patch:
@@ -324,6 +324,7 @@ public boolean create(Application appParam) {
     appParam.setRelease(ReleaseStateEnum.NEED_RELEASE.get());
     appParam.setOptionState(OptionStateEnum.NONE.getValue());
     appParam.setCreateTime(new Date());
+    appParam.setModifyTime(new Date());
     appParam.setDefaultModeIngress(settingService.getIngressModeDefault());
 
     boolean success = validateQueueIfNeeded(appParam);
@@ -432,6 +433,7 @@ public Long copy(Application appParam) {
     newApp.setRelease(ReleaseStateEnum.NEED_RELEASE.get());
     newApp.setOptionState(OptionStateEnum.NONE.getValue());
     newApp.setCreateTime(new Date());
+    newApp.setModifyTime(new Date());
     newApp.setHotParams(oldApp.getHotParams());
 
     newApp.setJar(oldApp.getJar());

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-hbase/src/main/java/org/apache/streampark/flink/connector/hbase/source/HBaseJavaSource.java
Patch:
@@ -42,8 +42,8 @@ public DataStreamSource<T> getDataStream(
       HBaseResultFunction<T> resultFunction,
       RunningFunction runningFunc) {
 
-    Utils.notNull(queryFunction, "QueryFunction must not be null");
-    Utils.notNull(resultFunction, "ResultFunction must not be null");
+    Utils.requireNotNull(queryFunction, "QueryFunction must not be null");
+    Utils.requireNotNull(resultFunction, "ResultFunction must not be null");
     HBaseSourceFunction<T> sourceFunction =
         new HBaseSourceFunction<>(property, queryFunction, resultFunction, runningFunc, null);
     return context.getJavaEnv().addSource(sourceFunction);

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-jdbc/src/main/java/org/apache/streampark/flink/connector/jdbc/sink/JdbcJavaSink.java
Patch:
@@ -55,7 +55,7 @@ public JdbcJavaSink<T> sql(TransformFunction<T, String> func) {
   }
 
   public DataStreamSink<T> sink(DataStream<T> dataStream) {
-    Utils.notNull(sqlFunc, "TransformFunction can not be null");
+    Utils.requireNotNull(sqlFunc, "TransformFunction can not be null");
     this.jdbc =
         this.jdbc == null ? ConfigUtils.getJdbcConf(context.parameter().toMap(), alias) : this.jdbc;
     JdbcSinkFunction<T> sinkFun = new JdbcSinkFunction<>(this.jdbc, this.sqlFunc);

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-jdbc/src/main/java/org/apache/streampark/flink/connector/jdbc/source/JdbcJavaSource.java
Patch:
@@ -54,8 +54,8 @@ public DataStreamSource<T> getDataStream(
       SQLResultFunction<T> resultFunction,
       RunningFunction runningFunc) {
 
-    Utils.notNull(queryFunction, "'queryFunction' must not be null");
-    Utils.notNull(resultFunction, "'resultFunction' must not be null");
+    Utils.requireNotNull(queryFunction, "'queryFunction' must not be null");
+    Utils.requireNotNull(resultFunction, "'resultFunction' must not be null");
     this.jdbc =
         this.jdbc == null ? ConfigUtils.getJdbcConf(context.parameter().toMap(), alias) : this.jdbc;
     JdbcSourceFunction<T> sourceFunction =

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-mongo/src/main/java/org/apache/streampark/flink/connector/mongo/source/MongoJavaSource.java
Patch:
@@ -43,9 +43,9 @@ public DataStreamSource<T> getDataStream(
       MongoResultFunction<T> resultFunction,
       RunningFunction runningFunc) {
 
-    Utils.notNull(collectionName, "'collectionName' must not be null");
-    Utils.notNull(queryFunction, "'queryFunction' must not be null");
-    Utils.notNull(resultFunction, "'resultFunction' must not be null");
+    Utils.requireNotNull(collectionName, "'collectionName' must not be null");
+    Utils.requireNotNull(queryFunction, "'queryFunction' must not be null");
+    Utils.requireNotNull(resultFunction, "'resultFunction' must not be null");
     MongoSourceFunction<T> sourceFunction =
         new MongoSourceFunction<>(
             collectionName, property, queryFunction, resultFunction, runningFunc, null);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkClusterService.java
Patch:
@@ -29,6 +29,8 @@
 
 public interface FlinkClusterService extends IService<FlinkCluster> {
 
+  List<FlinkCluster> listAvailableCluster();
+
   ResponseResult check(FlinkCluster flinkCluster);
 
   Boolean create(FlinkCluster flinkCluster);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -48,7 +48,7 @@ public class FlinkEnvServiceImpl extends ServiceImpl<FlinkEnvMapper, FlinkEnv>
   /**
    * two places will be checked: <br>
    * 1) name repeated <br>
-   * 2) flink-dist <br>
+   * 2) flink-dist repeated <br>
    * -1) invalid path <br>
    * 0) ok <br>
    */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ExternalLinkController.java
Patch:
@@ -82,7 +82,7 @@ public RestResponse create(@Valid ExternalLink externalLink) {
   @PostMapping("/update")
   @RequiresPermissions("externalLink:update")
   public RestResponse update(@Valid ExternalLink externalLink) {
-    Utils.notNull(externalLink.getId(), "The link id cannot be null");
+    Utils.requireNotNull(externalLink.getId(), "The link id cannot be null");
     externalLinkService.update(externalLink);
     return RestResponse.success();
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/runner/EnvInitializer.java
Patch:
@@ -113,7 +113,7 @@ private void initInternalConfig(Environment springEnv) {
         .forEach(
             key -> {
               InternalOption config = InternalConfigHolder.getConfig(key);
-              Utils.notNull(config);
+              Utils.requireNotNull(config);
               InternalConfigHolder.set(config, springEnv.getProperty(key, config.classType()));
             });
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationActionServiceImpl.java
Patch:
@@ -385,7 +385,7 @@ public void cancel(Application appParam) throws Exception {
   public void start(Application appParam, boolean auto) throws Exception {
     // 1) check application
     final Application application = getById(appParam.getId());
-    Utils.notNull(application);
+    Utils.requireNotNull(application);
     ApiAlertException.throwIfTrue(
         !application.isCanBeStart(), "[StreamPark] The application cannot be started repeatedly.");
 
@@ -397,7 +397,7 @@ public void start(Application appParam, boolean auto) throws Exception {
     }
 
     AppBuildPipeline buildPipeline = appBuildPipeService.getById(application.getId());
-    Utils.notNull(buildPipeline);
+    Utils.requireNotNull(buildPipeline);
 
     FlinkEnv flinkEnv = flinkEnvService.getByIdOrDefault(application.getVersionId());
 
@@ -625,7 +625,7 @@ private Tuple2<String, String> getUserJarAndAppConf(FlinkEnv flinkEnv, Applicati
     switch (application.getDevelopmentMode()) {
       case FLINK_SQL:
         FlinkSql flinkSql = flinkSqlService.getEffective(application.getId(), false);
-        Utils.notNull(flinkSql);
+        Utils.requireNotNull(flinkSql);
         // 1) dist_userJar
         String sqlDistJar = commonService.getSqlClientJar(flinkEnv);
         // 2) appConfig

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -206,7 +206,7 @@ public boolean buildApplication(@NotNull Long appId, boolean forceBuild) {
     FlinkSql effectiveFlinkSql = flinkSqlService.getEffective(app.getId(), false);
     if (app.isFlinkSqlJobOrPyFlinkJob()) {
       FlinkSql flinkSql = newFlinkSql == null ? effectiveFlinkSql : newFlinkSql;
-      Utils.notNull(flinkSql);
+      Utils.requireNotNull(flinkSql);
       app.setDependency(flinkSql.getDependency());
       app.setTeamResource(flinkSql.getTeamResource());
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ExternalLinkServiceImpl.java
Patch:
@@ -76,7 +76,7 @@ public void removeById(Long linkId) {
   @Override
   public List<ExternalLink> render(Long appId) {
     Application app = applicationManageService.getById(appId);
-    Utils.notNull(app, "Application doesn't exist");
+    Utils.requireNotNull(app, "Application doesn't exist");
     List<ExternalLink> externalLink = this.list();
     if (externalLink != null && externalLink.size() > 0) {
       // Render the placeholder

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -173,11 +173,11 @@ public void removeByAppId(Long appId) {
   @Transactional(propagation = Propagation.REQUIRES_NEW, rollbackFor = Exception.class)
   public void rollback(Application application) {
     FlinkSql sql = getCandidate(application.getId(), CandidateTypeEnum.HISTORY);
-    Utils.notNull(sql);
+    Utils.requireNotNull(sql);
     try {
       // check and backup current job
       FlinkSql effectiveSql = getEffective(application.getId(), false);
-      Utils.notNull(effectiveSql);
+      Utils.requireNotNull(effectiveSql);
       // rollback history sql
       backUpService.rollbackFlinkSql(application, sql);
     } catch (Exception e) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SqlCompleteServiceImpl.java
Patch:
@@ -184,7 +184,7 @@ public void buildTree(String word, int count, TreeNode buildWay) {
         nowStep = nowStep.get(nowChar).getNext();
         loc += 1;
       }
-      Utils.notNull(preNode);
+      Utils.requireNotNull(preNode);
       preNode.setStop();
       preNode.setCount(count);
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/UserServiceImpl.java
Patch:
@@ -95,7 +95,7 @@ public IPage<User> getPage(User user, RestRequest request) {
     page.setSize(request.getPageSize());
     IPage<User> resPage = this.baseMapper.selectPage(page, user);
 
-    Utils.notNull(resPage);
+    Utils.requireNotNull(resPage);
     if (resPage.getTotal() == 0) {
       resPage.setRecords(Collections.emptyList());
     }
@@ -197,15 +197,15 @@ public List<User> listNoTokenUser() {
   @Override
   public void setLastTeam(Long teamId, Long userId) {
     User user = getById(userId);
-    Utils.notNull(user);
+    Utils.requireNotNull(user);
     user.setLastTeamId(teamId);
     this.baseMapper.updateById(user);
   }
 
   @Override
   public void clearLastTeam(Long userId, Long teamId) {
     User user = getById(userId);
-    Utils.notNull(user);
+    Utils.requireNotNull(user);
     if (!teamId.equals(user.getLastTeamId())) {
       return;
     }

File: streampark-common/src/main/java/org/apache/streampark/common/enums/ResolveOrder.java
Patch:
@@ -38,6 +38,7 @@ public enum ResolveOrder {
     this.order = order;
   }
 
+  /** Try to resolve the given resolve order value into a known {@link ResolveOrder} enum. */
   @Nullable
   public static ResolveOrder of(@Nullable Integer value) {
     for (ResolveOrder order : values()) {

File: streampark-common/src/main/java/org/apache/streampark/common/enums/Semantic.java
Patch:
@@ -34,6 +34,7 @@ public enum Semantic {
   /** After the fault occurs, the counting results may be lost. */
   NONE;
 
+  /** Try to resolve the given semantic name into a known {@link Semantic}. */
   @Nullable
   public static Semantic of(@Nonnull String name) {
     for (Semantic semantic : Semantic.values()) {

File: streampark-common/src/main/java/org/apache/streampark/common/enums/StorageType.java
Patch:
@@ -22,6 +22,7 @@
 import javax.annotation.Nonnull;
 import javax.annotation.Nullable;
 
+/** Storage type enum. */
 public enum StorageType {
 
   /** hdfs */
@@ -41,6 +42,7 @@ public String getType() {
     return type;
   }
 
+  /** Try to resolve the given storage type identifier into a known {@link StorageType}. */
   @Nonnull
   public static StorageType of(@Nullable String identifier) {
     if (StringUtils.isBlank(identifier)) {

File: streampark-common/src/main/java/org/apache/streampark/common/enums/FlinkSqlValidationFailedType.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.streampark.common.enums;
 
+import javax.annotation.Nullable;
+
 public enum FlinkSqlValidationFailedType {
 
   /** Basic test failed (such as null, etc.) */
@@ -40,6 +42,7 @@ public enum FlinkSqlValidationFailedType {
     this.failedType = failedType;
   }
 
+  @Nullable
   public static FlinkSqlValidationFailedType of(Integer value) {
     for (FlinkSqlValidationFailedType type : values()) {
       if (type.failedType == value) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/MybatisConfig.java
Patch:
@@ -77,6 +77,7 @@ public PostgreSQLPrepareInterceptor postgreSQLPrepareInterceptor() {
   public MybatisPlusPropertiesCustomizer mybatisPlusPropertiesCustomizer() {
     return properties -> {
       properties.setTypeAliasesPackage("org.apache.streampark.console.*.entity");
+      properties.setTypeEnumsPackage("org.apache.streampark.console.*.enums");
       properties.setMapperLocations(new String[] {"classpath:mapper/*/*.xml"});
       MybatisConfiguration mybatisConfiguration = new MybatisConfiguration();
       mybatisConfiguration.setJdbcTypeForNull(JdbcType.NULL);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Message.java
Patch:
@@ -40,7 +40,7 @@ public class Message {
   private String title;
 
   /** 1) build failure report 2) task monitoring exception */
-  private Integer type;
+  private NoticeTypeEnum type;
 
   private String context;
 
@@ -54,7 +54,7 @@ public Message(
     this.appId = appId;
     this.title = title;
     this.context = context;
-    this.type = noticeTypeEnum.get();
+    this.type = noticeTypeEnum;
     this.createTime = new Date();
     this.isRead = false;
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/MessageServiceImpl.java
Patch:
@@ -53,7 +53,7 @@ public IPage<Message> getUnReadPage(NoticeTypeEnum noticeTypeEnum, RestRequest r
         new LambdaQueryWrapper<Message>()
             .eq(Message::getIsRead, false)
             .orderByDesc(Message::getCreateTime)
-            .eq(Message::getType, noticeTypeEnum.get());
+            .eq(Message::getType, noticeTypeEnum);
     return this.baseMapper.selectPage(page, queryWrapper);
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkSqlController.java
Patch:
@@ -118,7 +118,7 @@ public RestResponse get(String id) throws InternalException {
   @Operation(summary = "List the applications sql histories")
   @PostMapping("history")
   public RestResponse sqlhistory(Application application) {
-    List<FlinkSql> sqlList = flinkSqlService.history(application);
+    List<FlinkSql> sqlList = flinkSqlService.listFlinkSqlHistory(application);
     return RestResponse.success(sqlList);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ProjectController.java
Patch:
@@ -134,14 +134,14 @@ public RestResponse exists(Project project) {
   @Operation(summary = "List project modules")
   @PostMapping("modules")
   public RestResponse modules(Long id) {
-    List<String> result = projectService.modules(id);
+    List<String> result = projectService.listModules(id);
     return RestResponse.success().data(result);
   }
 
   @Operation(summary = "List project jars")
   @PostMapping("jars")
   public RestResponse jars(Project project) {
-    List<String> result = projectService.jars(project);
+    List<String> result = projectService.listJars(project);
     return RestResponse.success().data(result);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkSqlService.java
Patch:
@@ -38,7 +38,7 @@ public interface FlinkSqlService extends IService<FlinkSql> {
 
   FlinkSql getLatestFlinkSql(Long appId, boolean decode);
 
-  List<FlinkSql> history(Application application);
+  List<FlinkSql> listFlinkSqlHistory(Application application);
 
   FlinkSql getCandidate(Long appId, CandidateTypeEnum type);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ProjectService.java
Patch:
@@ -46,9 +46,9 @@ public interface ProjectService extends IService<Project> {
 
   RestResponse getBuildLog(Long id, Long startOffset);
 
-  List<String> modules(Long id);
+  List<String> listModules(Long id);
 
-  List<String> jars(Project project);
+  List<String> listJars(Project project);
 
   List<Map<String, Object>> listConf(Project project);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -118,7 +118,7 @@ public void setCandidate(CandidateTypeEnum candidateTypeEnum, Long appId, Long s
   }
 
   @Override
-  public List<FlinkSql> history(Application application) {
+  public List<FlinkSql> listFlinkSqlHistory(Application application) {
     LambdaQueryWrapper<FlinkSql> queryWrapper =
         new LambdaQueryWrapper<FlinkSql>()
             .eq(FlinkSql::getAppId, application.getId())

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -229,7 +229,7 @@ public void build(Long id) throws Exception {
   }
 
   @Override
-  public List<String> modules(Long id) {
+  public List<String> listModules(Long id) {
     Project project = getById(id);
     Utils.notNull(project);
 
@@ -245,7 +245,7 @@ public List<String> modules(Long id) {
   }
 
   @Override
-  public List<String> jars(Project project) {
+  public List<String> listJars(Project project) {
     List<String> jarList = new ArrayList<>(0);
     ApiAlertException.throwIfNull(
         project.getModule(), "Project module can't be null, please check.");

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationController.java
Patch:
@@ -139,8 +139,8 @@ public RestResponse update(Application app) {
   @Operation(summary = "Get applications dashboard data")
   @PostMapping("dashboard")
   public RestResponse dashboard(Long teamId) {
-    Map<String, Serializable> map = applicationInfoService.getDashboardDataMap(teamId);
-    return RestResponse.success(map);
+    Map<String, Serializable> dashboardMap = applicationInfoService.getDashboardDataMap(teamId);
+    return RestResponse.success(dashboardMap);
   }
 
   @Operation(summary = "List applications")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/AlertTypeEnum.java
Patch:
@@ -66,11 +66,11 @@ public enum AlertTypeEnum {
   private static final Map<Integer, AlertTypeEnum> CACHE_MAP = createCacheMap();
 
   private static Map<Integer, AlertTypeEnum> createCacheMap() {
-    Map<Integer, AlertTypeEnum> map = new HashMap<>();
+    Map<Integer, AlertTypeEnum> cacheMap = new HashMap<>();
     for (AlertTypeEnum notifyType : AlertTypeEnum.values()) {
-      map.put(notifyType.code, notifyType);
+      cacheMap.put(notifyType.code, notifyType);
     }
-    return Collections.unmodifiableMap(map);
+    return Collections.unmodifiableMap(cacheMap);
   }
 
   AlertTypeEnum(Integer code, Class<? extends AlertNotifyService> clazz) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/MenuController.java
Patch:
@@ -60,7 +60,7 @@ public RestResponse getUserRouters(Long teamId) {
   @PostMapping("list")
   @RequiresPermissions("menu:view")
   public RestResponse menuList(Menu menu) {
-    Map<String, Object> maps = this.menuService.listMenuMap(menu);
-    return RestResponse.success(maps);
+    Map<String, Object> menuMap = this.menuService.listMenuMap(menu);
+    return RestResponse.success(menuMap);
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/util/VueRouterUtils.java
Patch:
@@ -110,14 +110,14 @@ public static <T> List<VueRouter<T>> buildVueRouter(List<VueRouter<T>> routes) {
           }
         });
 
-    List<VueRouter<T>> list = new ArrayList<>();
+    List<VueRouter<T>> routerList = new ArrayList<>();
     VueRouter<T> root = new VueRouter<>();
     root.setName("Root");
     root.setComponent("BasicView");
     root.setPath("/");
     root.setChildren(topRoutes);
-    list.add(root);
+    routerList.add(root);
 
-    return list;
+    return routerList;
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkEnvController.java
Patch:
@@ -45,8 +45,8 @@ public class FlinkEnvController {
   @Operation(summary = "Get flink environment")
   @PostMapping("list")
   public RestResponse list() {
-    List<FlinkEnv> list = flinkEnvService.list();
-    return RestResponse.success(list);
+    List<FlinkEnv> flinkEnvList = flinkEnvService.list();
+    return RestResponse.success(flinkEnvList);
   }
 
   @Operation(summary = "Verify flink environment")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/MemberServiceImpl.java
Patch:
@@ -114,8 +114,8 @@ private Member findByUserId(Long teamId, Long userId) {
   public List<Long> listUserIdsByRoleId(Long roleId) {
     LambdaQueryWrapper<Member> queryWrapper =
         new LambdaQueryWrapper<Member>().eq(Member::getRoleId, roleId);
-    List<Member> list = baseMapper.selectList(queryWrapper);
-    return list.stream().map(Member::getUserId).collect(Collectors.toList());
+    List<Member> memberList = baseMapper.selectList(queryWrapper);
+    return memberList.stream().map(Member::getUserId).collect(Collectors.toList());
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/RoleMenuServiceImpl.java
Patch:
@@ -46,9 +46,9 @@ public void removeByRoleId(Long roleId) {
   @Override
   @Transactional
   public void removeByMenuIds(String[] menuIds) {
-    List<String> list = Arrays.asList(menuIds);
+    List<String> menuIdList = Arrays.asList(menuIds);
     LambdaQueryWrapper<RoleMenu> queryWrapper =
-        new LambdaQueryWrapper<RoleMenu>().in(RoleMenu::getMenuId, list);
+        new LambdaQueryWrapper<RoleMenu>().in(RoleMenu::getMenuId, menuIdList);
     baseMapper.delete(queryWrapper);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/FlinkClusterMapper.java
Patch:
@@ -25,7 +25,7 @@
 
 public interface FlinkClusterMapper extends BaseMapper<FlinkCluster> {
 
-  Boolean existsByClusterId(@Param("clusterId") String clusterId, @Param("id") Long id);
+  boolean existsByClusterId(@Param("clusterId") String clusterId, @Param("id") Long id);
 
-  Boolean existsByClusterName(@Param("clusterName") String clusterName, @Param("id") Long id);
+  boolean existsByClusterName(@Param("clusterName") String clusterName, @Param("id") Long id);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ProjectMapper.java
Patch:
@@ -35,7 +35,7 @@ public interface ProjectMapper extends BaseMapper<Project> {
 
   IPage<Project> selectPage(Page<Project> page, @Param("project") Project project);
 
-  Boolean existsByTeamId(@Param("teamId") Long teamId);
+  boolean existsByTeamId(@Param("teamId") Long teamId);
 
   List<Project> selectProjectsByTeamId(@Param("teamId") Long teamId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/VariableMapper.java
Patch:
@@ -33,5 +33,5 @@ public interface VariableMapper extends BaseMapper<Variable> {
 
   List<Variable> selectVarsByTeamId(@Param("teamId") Long teamId, @Param("keyword") String keyword);
 
-  Boolean existsByTeamId(@Param("teamId") Long teamId);
+  boolean existsByTeamId(@Param("teamId") Long teamId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/mapper/MemberMapper.java
Patch:
@@ -36,15 +36,15 @@ public interface MemberMapper extends BaseMapper<Member> {
    * @param userId user id
    * @return boolean
    */
-  Boolean deleteByUserId(@Param("userId") Long userId);
+  boolean deleteByUserId(@Param("userId") Long userId);
 
   /**
    * delete user by role id
    *
    * @param roleId role id
    * @return boolean
    */
-  Boolean deleteByRoleId(@Param("roleId") Long roleId);
+  boolean deleteByRoleId(@Param("roleId") Long roleId);
 
   IPage<Member> selectPage(Page<Member> page, @Param("member") Member member);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/AccessTokenController.java
Patch:
@@ -150,7 +150,7 @@ public RestResponse toggleToken(@NotNull(message = "{required}") Long tokenId) {
   @DeleteMapping(value = "delete")
   @RequiresPermissions("token:delete")
   public RestResponse deleteToken(@NotBlank(message = "{required}") Long tokenId) {
-    boolean res = accessTokenService.deleteToken(tokenId);
+    boolean res = accessTokenService.removeById(tokenId);
     return RestResponse.success(res);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/MemberController.java
Patch:
@@ -96,7 +96,7 @@ public RestResponse create(@Valid Member member) {
   @DeleteMapping("delete")
   @RequiresPermissions("member:delete")
   public RestResponse delete(Member member) {
-    this.memberService.deleteMember(member);
+    this.memberService.remove(member);
     return RestResponse.success();
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/RoleController.java
Patch:
@@ -92,7 +92,7 @@ public RestResponse addRole(@Valid Role role) {
   @DeleteMapping("delete")
   @RequiresPermissions("role:delete")
   public RestResponse deleteRole(Long roleId) {
-    this.roleService.deleteRole(roleId);
+    this.roleService.removeById(roleId);
     return RestResponse.success();
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/TeamController.java
Patch:
@@ -74,7 +74,7 @@ public RestResponse addTeam(@Valid Team team) {
   @DeleteMapping("delete")
   @RequiresPermissions("team:delete")
   public RestResponse deleteTeam(Team team) {
-    this.teamService.deleteTeam(team.getId());
+    this.teamService.removeById(team.getId());
     return RestResponse.success();
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/AccessTokenService.java
Patch:
@@ -30,8 +30,6 @@ public interface AccessTokenService extends IService<AccessToken> {
   RestResponse generateToken(Long userId, String expireTime, String description)
       throws InternalException;
 
-  boolean deleteToken(Long id);
-
   IPage<AccessToken> getPage(AccessToken tokenParam, RestRequest request);
 
   boolean checkTokenEffective(Long userId, String token);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/RoleMenuServie.java
Patch:
@@ -25,9 +25,9 @@
 
 public interface RoleMenuServie extends IService<RoleMenu> {
 
-  void deleteByRoleId(Long roleId);
+  void removeByRoleId(Long roleId);
 
-  void deleteByMenuId(String[] menuIds);
+  void removeByMenuIds(String[] menuIds);
 
   List<RoleMenu> listByRoleId(String roleId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/RoleService.java
Patch:
@@ -31,7 +31,7 @@ public interface RoleService extends IService<Role> {
 
   void createRole(Role role);
 
-  void deleteRole(Long roleId);
+  void removeById(Long roleId);
 
   void updateRole(Role role);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/TeamService.java
Patch:
@@ -33,7 +33,7 @@ public interface TeamService extends IService<Team> {
 
   void createTeam(Team team);
 
-  void deleteTeam(Long teamId);
+  void removeById(Long teamId);
 
   void updateTeam(Team team);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/RoleMenuServiceImpl.java
Patch:
@@ -37,15 +37,15 @@ public class RoleMenuServiceImpl extends ServiceImpl<RoleMenuMapper, RoleMenu>
 
   @Override
   @Transactional
-  public void deleteByRoleId(Long roleId) {
+  public void removeByRoleId(Long roleId) {
     LambdaQueryWrapper<RoleMenu> queryWrapper =
         new LambdaQueryWrapper<RoleMenu>().eq(RoleMenu::getRoleId, roleId);
     baseMapper.delete(queryWrapper);
   }
 
   @Override
   @Transactional
-  public void deleteByMenuId(String[] menuIds) {
+  public void removeByMenuIds(String[] menuIds) {
     List<String> list = Arrays.asList(menuIds);
     LambdaQueryWrapper<RoleMenu> queryWrapper =
         new LambdaQueryWrapper<RoleMenu>().in(RoleMenu::getMenuId, list);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/RoleServiceImpl.java
Patch:
@@ -81,7 +81,7 @@ public void createRole(Role role) {
   }
 
   @Override
-  public void deleteRole(Long roleId) {
+  public void removeById(Long roleId) {
     Role role =
         Optional.ofNullable(this.getById(roleId))
             .orElseThrow(
@@ -94,8 +94,8 @@ public void deleteRole(Long roleId) {
         String.format(
             "There are some users of role %s, delete role failed, please unbind it first.",
             role.getRoleName()));
-    this.removeById(roleId);
-    this.roleMenuService.deleteByRoleId(roleId);
+    super.removeById(roleId);
+    this.roleMenuService.removeByRoleId(roleId);
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/TeamServiceImpl.java
Patch:
@@ -92,7 +92,7 @@ public void createTeam(Team team) {
   }
 
   @Override
-  public void deleteTeam(Long teamId) {
+  public void removeById(Long teamId) {
     log.info("{} Proceed delete team[Id={}]", commonService.getCurrentUser().getUsername(), teamId);
     Team team = this.getById(teamId);
 
@@ -113,9 +113,9 @@ public void deleteTeam(Long teamId) {
         String.format(
             "Please delete the variables under the team[name=%s] first!", team.getTeamName()));
 
-    memberService.deleteByTeamId(teamId);
+    memberService.removeByTeamId(teamId);
     userService.clearLastTeam(teamId);
-    this.removeById(teamId);
+    super.removeById(teamId);
   }
 
   @Override

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/AccessTokenServiceTest.java
Patch:
@@ -81,6 +81,6 @@ void testCrudToken() throws Exception {
     Assertions.assertEquals(AccessToken.STATUS_DISABLE, afterToggle.getStatus());
 
     // delete
-    Assertions.assertTrue(accessTokenService.deleteToken(tokenId));
+    Assertions.assertTrue(accessTokenService.removeById(tokenId));
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/aspect/ConsoleAspect.java
Patch:
@@ -1,6 +1,4 @@
 /*
- * Copyright (c) 2019 The StreamX Project
- *
  * Licensed to the Apache Software Foundation (ASF) under one or more
  * contributor license agreements.  See the NOTICE file distributed with
  * this work for additional information regarding copyright ownership.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/AlertController.java
Patch:
@@ -108,7 +108,7 @@ public RestResponse alertConfigsList() {
   @DeleteMapping("/delete")
   public RestResponse deleteAlertConfig(
       @RequestParam("id") @NotNull(message = "config id must be not null") Long id) {
-    boolean result = alertConfigService.deleteById(id);
+    boolean result = alertConfigService.removeById(id);
     return RestResponse.success(result);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ExternalLinkController.java
Patch:
@@ -93,7 +93,7 @@ public RestResponse update(@Valid ExternalLink externalLink) {
   @RequiresPermissions("externalLink:delete")
   public RestResponse delete(
       @NotNull(message = "The link id cannot be null") @RequestParam("id") Long id) {
-    externalLinkService.delete(id);
+    externalLinkService.removeById(id);
     return RestResponse.success();
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkClusterController.java
Patch:
@@ -111,7 +111,7 @@ public RestResponse shutdown(FlinkCluster cluster) {
   @Operation(summary = "Delete flink cluster")
   @PostMapping("delete")
   public RestResponse delete(FlinkCluster cluster) {
-    flinkClusterService.delete(cluster);
+    flinkClusterService.remove(cluster);
     return RestResponse.success();
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkEnvController.java
Patch:
@@ -96,7 +96,7 @@ public RestResponse update(FlinkEnv version) throws Exception {
   @Operation(summary = "Delete flink environment")
   @PostMapping("delete")
   public RestResponse delete(Long id) {
-    flinkEnvService.delete(id);
+    flinkEnvService.removeById(id);
     return RestResponse.success();
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ProjectController.java
Patch:
@@ -113,7 +113,7 @@ public RestResponse branches(Project project) {
   @PostMapping("delete")
   @RequiresPermissions("project:delete")
   public RestResponse delete(Long id) {
-    Boolean deleted = projectService.delete(id);
+    Boolean deleted = projectService.removeById(id);
     return RestResponse.success().data(deleted);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ResourceController.java
Patch:
@@ -84,7 +84,7 @@ public RestResponse updateResource(@Valid Resource resource) {
   @DeleteMapping("delete")
   @RequiresPermissions("resource:delete")
   public RestResponse deleteResource(@Valid Resource resource) {
-    this.resourceService.deleteResource(resource);
+    this.resourceService.remove(resource);
     return RestResponse.success();
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/SavePointController.java
Patch:
@@ -74,7 +74,7 @@ public RestResponse history(SavePoint savePoint, RestRequest request) {
   public RestResponse delete(Long id) throws InternalException {
     SavePoint savePoint = savePointService.getById(id);
     Application application = applicationManageService.getById(savePoint.getAppId());
-    Boolean deleted = savePointService.delete(id, application);
+    Boolean deleted = savePointService.remove(id, application);
     return RestResponse.success(deleted);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/VariableController.java
Patch:
@@ -123,7 +123,7 @@ public RestResponse showOriginal(@RequestParam Long id) {
   @DeleteMapping("delete")
   @RequiresPermissions("variable:delete")
   public RestResponse deleteVariable(@Valid Variable variable) {
-    this.variableService.deleteVariable(variable);
+    this.variableService.remove(variable);
     return RestResponse.success();
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/YarnQueueController.java
Patch:
@@ -90,7 +90,7 @@ public RestResponse update(YarnQueue yarnQueue) {
   @PostMapping("delete")
   @RequiresPermissions("yarnQueue:delete")
   public RestResponse delete(YarnQueue yarnQueue) {
-    yarnQueueService.deleteYarnQueue(yarnQueue);
+    yarnQueueService.remove(yarnQueue);
     return RestResponse.success();
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/AppBuildPipeService.java
Patch:
@@ -62,5 +62,5 @@ public interface AppBuildPipeService extends IService<AppBuildPipeline> {
    *
    * @param appId
    */
-  void removeApp(Long appId);
+  void removeByAppId(Long appId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationBackUpService.java
Patch:
@@ -36,7 +36,7 @@ public interface ApplicationBackUpService extends IService<ApplicationBackUp> {
    * @return true if the object was successfully deleted, false otherwise.
    * @throws InternalException if an internal error occurs during the deletion process.
    */
-  Boolean delete(Long id) throws InternalException;
+  Boolean removeById(Long id) throws InternalException;
 
   /**
    * Performs a backup for the given application and Flink SQL parameters.
@@ -74,7 +74,7 @@ public interface ApplicationBackUpService extends IService<ApplicationBackUp> {
    *
    * @param appParam the application to be removed
    */
-  void removeApp(Application appParam);
+  void remove(Application appParam);
 
   /**
    * Rolls back a Flink SQL application to its previous state.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationConfigService.java
Patch:
@@ -122,5 +122,5 @@ public interface ApplicationConfigService extends IService<ApplicationConfig> {
    *
    * @param appId The id of the app to be removed.
    */
-  void removeApp(Long appId);
+  void removeByAppId(Long appId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationLogService.java
Patch:
@@ -27,7 +27,5 @@ public interface ApplicationLogService extends IService<ApplicationLog> {
 
   IPage<ApplicationLog> getPage(ApplicationLog applicationLog, RestRequest request);
 
-  void removeApp(Long appId);
-
-  Boolean delete(ApplicationLog applicationLog);
+  void removeByAppId(Long appId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/EffectiveService.java
Patch:
@@ -24,11 +24,11 @@
 
 public interface EffectiveService extends IService<Effective> {
 
-  void delete(Long appId, EffectiveTypeEnum config);
+  void remove(Long appId, EffectiveTypeEnum config);
 
   Effective get(Long appId, EffectiveTypeEnum config);
 
   void saveOrUpdate(Long appId, EffectiveTypeEnum type, Long id);
 
-  void removeApp(Long appId);
+  void removeByAppId(Long appId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ExternalLinkService.java
Patch:
@@ -27,7 +27,7 @@ public interface ExternalLinkService extends IService<ExternalLink> {
 
   void create(ExternalLink externalLink);
 
-  void delete(Long linkId);
+  void removeById(Long linkId);
 
   void update(ExternalLink externalLink);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkClusterService.java
Patch:
@@ -33,7 +33,7 @@ public interface FlinkClusterService extends IService<FlinkCluster> {
 
   Boolean create(FlinkCluster flinkCluster);
 
-  void delete(FlinkCluster flinkCluster);
+  void remove(FlinkCluster flinkCluster);
 
   void update(FlinkCluster flinkCluster);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkEnvService.java
Patch:
@@ -49,7 +49,7 @@ public interface FlinkEnvService extends IService<FlinkEnv> {
    *
    * @param id the ID of the Flink environment to delete
    */
-  void delete(Long id);
+  void removeById(Long id);
 
   /**
    * Updates the specified version of Flink environment.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkSqlService.java
Patch:
@@ -46,7 +46,7 @@ public interface FlinkSqlService extends IService<FlinkSql> {
 
   void cleanCandidate(Long id);
 
-  void removeApp(Long appId);
+  void removeByAppId(Long appId);
 
   void rollback(Application application);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ProjectService.java
Patch:
@@ -34,7 +34,7 @@ public interface ProjectService extends IService<Project> {
 
   boolean update(Project projectParam);
 
-  boolean delete(Long id);
+  boolean removeById(Long id);
 
   IPage<Project> getPage(Project project, RestRequest restRequest);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ResourceService.java
Patch:
@@ -73,7 +73,7 @@ public interface ResourceService extends IService<Resource> {
    *
    * @param resource
    */
-  void deleteResource(Resource resource);
+  void remove(Resource resource);
 
   /**
    * Get resource through team id.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/SavePointService.java
Patch:
@@ -62,7 +62,7 @@ public interface SavePointService extends IService<SavePoint> {
    * @return true if the application is successfully deleted, false otherwise
    * @throws InternalException if there is an internal error during the deletion process
    */
-  Boolean delete(Long id, Application appParam) throws InternalException;
+  Boolean remove(Long id, Application appParam) throws InternalException;
 
   /**
    * Retrieves a page of savepoint objects based on the specified parameters.
@@ -78,7 +78,7 @@ public interface SavePointService extends IService<SavePoint> {
    *
    * @param appParam the application to be removed
    */
-  void removeApp(Application appParam);
+  void remove(Application appParam);
 
   /**
    * Returns the savepoint path for the given application.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/VariableService.java
Patch:
@@ -75,7 +75,7 @@ public interface VariableService extends IService<Variable> {
    *
    * @param variable the Variable object to be deleted
    */
-  void deleteVariable(Variable variable);
+  void remove(Variable variable);
 
   /**
    * Find a Variable by its code and team ID.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/YarnQueueService.java
Patch:
@@ -35,7 +35,7 @@ public interface YarnQueueService extends IService<YarnQueue> {
 
   void updateYarnQueue(YarnQueue yarnQueue);
 
-  void deleteYarnQueue(YarnQueue yarnQueue);
+  void remove(YarnQueue yarnQueue);
 
   void checkQueueLabel(FlinkExecutionMode executionModeEnum, String queueLabel);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/alert/AlertConfigService.java
Patch:
@@ -30,5 +30,5 @@ public interface AlertConfigService extends IService<AlertConfig> {
 
   boolean exist(AlertConfig alertConfig);
 
-  boolean deleteById(Long id) throws AlertException;
+  boolean removeById(Long id) throws AlertException;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/alert/impl/AlertConfigServiceImpl.java
Patch:
@@ -74,7 +74,7 @@ public boolean exist(AlertConfig alertConfig) {
   }
 
   @Override
-  public boolean deleteById(Long id) throws AlertException {
+  public boolean removeById(Long id) throws AlertException {
     long count =
         applicationInfoService.count(
             new LambdaQueryWrapper<Application>().eq(id != null, Application::getAlertId, id));
@@ -84,6 +84,6 @@ public boolean deleteById(Long id) throws AlertException {
               "AlertId:%d, this is bound by application. Please clear the configuration first",
               id));
     }
-    return removeById(id);
+    return super.removeById(id);
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/ApplicationManageService.java
Patch:
@@ -105,7 +105,7 @@ public interface ApplicationManageService extends IService<Application> {
    * @param appParam The Application to be deleted.
    * @return True if the deletion was successful, false otherwise.
    */
-  Boolean delete(Application appParam);
+  Boolean remove(Application appParam);
 
   /**
    * Retrieves the Application with the specified details from the system.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -215,7 +215,7 @@ public boolean buildApplication(@NotNull Long appId, boolean forceBuild) {
     BuildPipeline pipeline = createPipelineInstance(app);
 
     // clear history
-    removeApp(app.getId());
+    removeByAppId(app.getId());
     // register pipeline progress event watcher.
     // save snapshot of pipeline to db when status of pipeline was changed.
     pipeline.registerWatcher(
@@ -593,7 +593,7 @@ public Map<Long, PipelineStatusEnum> listAppIdPipelineStatusMap(List<Long> appId
   }
 
   @Override
-  public void removeApp(Long appId) {
+  public void removeByAppId(Long appId) {
     baseMapper.delete(
         new LambdaQueryWrapper<AppBuildPipeline>().eq(AppBuildPipeline::getAppId, appId));
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationConfigServiceImpl.java
Patch:
@@ -107,7 +107,7 @@ public synchronized void update(Application appParam, Boolean latest) {
       ApplicationConfig effectiveConfig = getEffective(appParam.getId());
       if (Utils.isEmpty(appParam.getConfig())) {
         if (effectiveConfig != null) {
-          effectiveService.delete(appParam.getId(), EffectiveTypeEnum.CONFIG);
+          effectiveService.remove(appParam.getId(), EffectiveTypeEnum.CONFIG);
         }
       } else {
         // there was no configuration before, is a new configuration
@@ -245,7 +245,7 @@ public synchronized String readTemplate() {
   }
 
   @Override
-  public void removeApp(Long appId) {
+  public void removeByAppId(Long appId) {
     baseMapper.delete(
         new LambdaQueryWrapper<ApplicationConfig>().eq(ApplicationConfig::getAppId, appId));
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/EffectiveServiceImpl.java
Patch:
@@ -39,7 +39,7 @@ public class EffectiveServiceImpl extends ServiceImpl<EffectiveMapper, Effective
     implements EffectiveService {
 
   @Override
-  public void delete(Long appId, EffectiveTypeEnum effectiveTypeEnum) {
+  public void remove(Long appId, EffectiveTypeEnum effectiveTypeEnum) {
     LambdaQueryWrapper<Effective> queryWrapper =
         new LambdaQueryWrapper<Effective>()
             .eq(Effective::getAppId, appId)
@@ -80,7 +80,7 @@ public void saveOrUpdate(Long appId, EffectiveTypeEnum type, Long id) {
   }
 
   @Override
-  public void removeApp(Long appId) {
+  public void removeByAppId(Long appId) {
     LambdaQueryWrapper<Effective> queryWrapper =
         new LambdaQueryWrapper<Effective>().eq(Effective::getAppId, appId);
     this.remove(queryWrapper);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ExternalLinkServiceImpl.java
Patch:
@@ -69,7 +69,7 @@ public void update(ExternalLink externalLink) {
   }
 
   @Override
-  public void delete(Long linkId) {
+  public void removeById(Long linkId) {
     baseMapper.deleteById(linkId);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -342,7 +342,7 @@ public void updateClusterState(Long id, ClusterState state) {
   }
 
   @Override
-  public void delete(FlinkCluster cluster) {
+  public void remove(FlinkCluster cluster) {
     Long id = cluster.getId();
     FlinkCluster flinkCluster = getById(id);
     ApiAlertException.throwIfNull(flinkCluster, "Flink cluster not exist, please check.");

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -89,7 +89,7 @@ public boolean create(FlinkEnv version) throws Exception {
   }
 
   @Override
-  public void delete(Long id) {
+  public void removeById(Long id) {
     FlinkEnv flinkEnv = getById(id);
     checkOrElseAlert(flinkEnv);
     Long count = this.baseMapper.selectCount(null);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -163,7 +163,7 @@ public void cleanCandidate(Long id) {
   }
 
   @Override
-  public void removeApp(Long appId) {
+  public void removeByAppId(Long appId) {
     LambdaQueryWrapper<FlinkSql> queryWrapper =
         new LambdaQueryWrapper<FlinkSql>().eq(FlinkSql::getAppId, appId);
     baseMapper.delete(queryWrapper);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -158,7 +158,7 @@ public boolean update(Project projectParam) {
   }
 
   @Override
-  public boolean delete(Long id) {
+  public boolean removeById(Long id) {
     Project project = getById(id);
     Utils.notNull(project);
     LambdaQueryWrapper<Application> queryWrapper =
@@ -169,7 +169,7 @@ public boolean delete(Long id) {
     }
     try {
       project.delete();
-      removeById(id);
+      super.removeById(id);
       return true;
     } catch (IOException e) {
       return false;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -203,7 +203,7 @@ public void updateResource(Resource resource) {
   }
 
   @Override
-  public void deleteResource(Resource resource) {
+  public void remove(Resource resource) {
     Resource findResource = getById(resource.getId());
     checkOrElseAlert(findResource);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SavePointServiceImpl.java
Patch:
@@ -199,7 +199,7 @@ public void trigger(Long appId, @Nullable String savepointPath, @Nullable Boolea
   }
 
   @Override
-  public Boolean delete(Long id, Application appParam) throws InternalException {
+  public Boolean remove(Long id, Application appParam) throws InternalException {
     SavePoint savePoint = getById(id);
     try {
       if (StringUtils.isNotEmpty(savePoint.getPath())) {
@@ -221,7 +221,7 @@ public IPage<SavePoint> getPage(SavePoint savePoint, RestRequest request) {
   }
 
   @Override
-  public void removeApp(Application appParam) {
+  public void remove(Application appParam) {
     Long appId = appParam.getId();
 
     LambdaQueryWrapper<SavePoint> queryWrapper =

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/VariableServiceImpl.java
Patch:
@@ -83,7 +83,7 @@ public void createVariable(Variable variable) {
   }
 
   @Override
-  public void deleteVariable(Variable variable) {
+  public void remove(Variable variable) {
     ApiAlertException.throwIfTrue(
         isDependByApplications(variable), "Sorry, the variable is actually used.");
     this.removeById(variable);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/YarnQueueServiceImpl.java
Patch:
@@ -157,7 +157,7 @@ public void updateYarnQueue(YarnQueue yarnQueue) {
   }
 
   @Override
-  public void deleteYarnQueue(YarnQueue yarnQueue) {
+  public void remove(YarnQueue yarnQueue) {
     YarnQueue queueFromDB = getYarnQueueByIdWithPreconditions(yarnQueue);
 
     checkNotReferencedByApplications(

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/ApplicationBackUpCleanTask.java
Patch:
@@ -52,7 +52,7 @@ public void backUpClean() {
                   .forEach(
                       backUp -> {
                         try {
-                          backUpService.delete(backUp.getId());
+                          backUpService.removeById(backUp.getId());
                         } catch (Exception e) {
                           log.error(
                               "Clean application backup failed for app id: {} , backup id: {}",

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/aspect/ConsoleAspect.java
Patch:
@@ -126,14 +126,14 @@ public RestResponse permissionAction(ProceedingJoinPoint joinPoint) throws Throw
           break;
         case TEAM:
           ApiAlertException.throwIfTrue(
-              memberService.findByUserName(paramId, currentUser.getUsername()) == null,
+              memberService.getByTeamIdUserName(paramId, currentUser.getUsername()) == null,
               "Permission denied, only user belongs to this team can access this permission");
           break;
         case APP:
           Application app = applicationManageService.getById(paramId);
           ApiAlertException.throwIfTrue(app == null, "Invalid operation, application is null");
           ApiAlertException.throwIfTrue(
-              memberService.findByUserName(app.getTeamId(), currentUser.getUsername()) == null,
+              memberService.getByTeamIdUserName(app.getTeamId(), currentUser.getUsername()) == null,
               "Permission denied, only user belongs to this team can access this permission");
           break;
         default:

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/authentication/ShiroRealm.java
Patch:
@@ -63,7 +63,7 @@ protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection token) {
     SimpleAuthorizationInfo simpleAuthorizationInfo = new SimpleAuthorizationInfo();
 
     // Get user permission set
-    Set<String> permissionSet = userService.getPermissions(userId, null);
+    Set<String> permissionSet = userService.listPermissions(userId, null);
     simpleAuthorizationInfo.setStringPermissions(permissionSet);
     return simpleAuthorizationInfo;
   }
@@ -85,7 +85,7 @@ protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authent
       throw new AuthenticationException("Token verification failed");
     }
     // Query user information by username
-    User user = userService.findByName(username);
+    User user = userService.getByUsername(username);
 
     if (user == null) {
       throw new AuthenticationException("ERROR Incorrect username or password!");

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/AccessTokenController.java
Patch:
@@ -117,7 +117,7 @@ public RestResponse verifyToken() {
   @RequiresPermissions("token:view")
   public RestResponse tokensList(
       RestRequest restRequest, @Parameter(hidden = true) AccessToken accessToken) {
-    IPage<AccessToken> accessTokens = accessTokenService.findAccessTokens(accessToken, restRequest);
+    IPage<AccessToken> accessTokens = accessTokenService.getPage(accessToken, restRequest);
     return RestResponse.success(accessTokens);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/MenuController.java
Patch:
@@ -52,16 +52,15 @@ public class MenuController {
   @PostMapping("router")
   public RestResponse getUserRouters(Long teamId) {
     // TODO The teamId is required, get routers should be called after choose teamId.
-    List<VueRouter<Menu>> routers =
-        this.menuService.getUserRouters(commonService.getUserId(), teamId);
+    List<VueRouter<Menu>> routers = this.menuService.listRouters(commonService.getUserId(), teamId);
     return RestResponse.success(routers);
   }
 
   @Operation(summary = "List menus")
   @PostMapping("list")
   @RequiresPermissions("menu:view")
   public RestResponse menuList(Menu menu) {
-    Map<String, Object> maps = this.menuService.findMenus(menu);
+    Map<String, Object> maps = this.menuService.listMenuMap(menu);
     return RestResponse.success(maps);
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/RoleController.java
Patch:
@@ -58,21 +58,21 @@ public class RoleController {
   @PostMapping("list")
   @RequiresPermissions("role:view")
   public RestResponse roleList(RestRequest restRequest, Role role) {
-    IPage<Role> roleList = roleService.findRoles(role, restRequest);
+    IPage<Role> roleList = roleService.getPage(role, restRequest);
     return RestResponse.success(roleList);
   }
 
   @Operation(summary = "Check the role name")
   @PostMapping("check/name")
   public RestResponse checkRoleName(@NotBlank(message = "{required}") String roleName) {
-    Role result = this.roleService.findByName(roleName);
+    Role result = this.roleService.getByName(roleName);
     return RestResponse.success(result == null);
   }
 
   @Operation(summary = "List role menus")
   @PostMapping("menu")
   public RestResponse getRoleMenus(@NotBlank(message = "{required}") String roleId) {
-    List<RoleMenu> list = this.roleMenuServie.getByRoleId(roleId);
+    List<RoleMenu> list = this.roleMenuServie.listByRoleId(roleId);
     List<String> roleMenus =
         list.stream()
             .map(roleMenu -> String.valueOf(roleMenu.getMenuId()))

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/TeamController.java
Patch:
@@ -51,14 +51,14 @@ public class TeamController {
   @Operation(summary = "List teams")
   @PostMapping("list")
   public RestResponse teamList(RestRequest restRequest, Team team) {
-    IPage<Team> teamList = teamService.findTeams(team, restRequest);
+    IPage<Team> teamList = teamService.getPage(team, restRequest);
     return RestResponse.success(teamList);
   }
 
   @Operation(summary = "Check the team name")
   @PostMapping("check/name")
   public RestResponse checkTeamName(@NotBlank(message = "{required}") String teamName) {
-    Team result = this.teamService.findByName(teamName);
+    Team result = this.teamService.getByName(teamName);
     return RestResponse.success(result == null);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/security/impl/AuthenticatorImpl.java
Patch:
@@ -58,7 +58,7 @@ public User authenticate(String username, String password, String loginType) thr
   }
 
   private User passwordAuthenticate(String username, String password) {
-    User user = usersService.findByName(username);
+    User user = usersService.getByUsername(username);
 
     ApiAlertException.throwIfNull(user, String.format("User [%s] does not exist", username));
 
@@ -81,7 +81,7 @@ private User ldapAuthenticate(String username, String password) throws Exception
       return null;
     }
     // check if user exist
-    User user = usersService.findByName(username);
+    User user = usersService.getByUsername(username);
 
     if (user != null) {
       ApiAlertException.throwIfTrue(
@@ -95,7 +95,7 @@ private User ldapAuthenticate(String username, String password) throws Exception
 
   private User ssoAuthenticate(String username) throws Exception {
     // check if user exist
-    User user = usersService.findByName(username);
+    User user = usersService.getByUsername(username);
 
     if (user != null) {
       ApiAlertException.throwIfTrue(

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/AccessTokenService.java
Patch:
@@ -32,7 +32,7 @@ RestResponse generateToken(Long userId, String expireTime, String description)
 
   boolean deleteToken(Long id);
 
-  IPage<AccessToken> findAccessTokens(AccessToken tokenParam, RestRequest request);
+  IPage<AccessToken> getPage(AccessToken tokenParam, RestRequest request);
 
   boolean checkTokenEffective(Long userId, String token);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/RoleMenuServie.java
Patch:
@@ -29,5 +29,5 @@ public interface RoleMenuServie extends IService<RoleMenu> {
 
   void deleteByMenuId(String[] menuIds);
 
-  List<RoleMenu> getByRoleId(String roleId);
+  List<RoleMenu> listByRoleId(String roleId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/RoleService.java
Patch:
@@ -25,9 +25,9 @@
 
 public interface RoleService extends IService<Role> {
 
-  IPage<Role> findRoles(Role role, RestRequest request);
+  IPage<Role> getPage(Role role, RestRequest request);
 
-  Role findByName(String roleName);
+  Role getByName(String roleName);
 
   void createRole(Role role);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/TeamService.java
Patch:
@@ -27,15 +27,15 @@
 
 public interface TeamService extends IService<Team> {
 
-  IPage<Team> findTeams(Team team, RestRequest request);
+  IPage<Team> getPage(Team team, RestRequest request);
 
-  Team findByName(String teamName);
+  Team getByName(String teamName);
 
   void createTeam(Team team);
 
   void deleteTeam(Long teamId);
 
   void updateTeam(Team team);
 
-  List<Team> findUserTeams(Long userId);
+  List<Team> listByUserId(Long userId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/AccessTokenServiceImpl.java
Patch:
@@ -87,7 +87,7 @@ public boolean deleteToken(Long id) {
   }
 
   @Override
-  public IPage<AccessToken> findAccessTokens(AccessToken tokenParam, RestRequest request) {
+  public IPage<AccessToken> getPage(AccessToken tokenParam, RestRequest request) {
     Page<AccessToken> page = new MybatisPager<AccessToken>().getDefaultPage(request);
     this.baseMapper.selectPage(page, tokenParam);
     List<AccessToken> records = page.getRecords();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/RoleMenuServiceImpl.java
Patch:
@@ -53,7 +53,7 @@ public void deleteByMenuId(String[] menuIds) {
   }
 
   @Override
-  public List<RoleMenu> getByRoleId(String roleId) {
+  public List<RoleMenu> listByRoleId(String roleId) {
     LambdaQueryWrapper<RoleMenu> queryWrapper =
         new LambdaQueryWrapper<RoleMenu>().eq(RoleMenu::getRoleId, roleId);
     return baseMapper.selectList(queryWrapper);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/RoleServiceImpl.java
Patch:
@@ -59,15 +59,15 @@ public class RoleServiceImpl extends ServiceImpl<RoleMapper, Role> implements Ro
   @Autowired private RoleMenuServie roleMenuService;
 
   @Override
-  public IPage<Role> findRoles(Role role, RestRequest request) {
+  public IPage<Role> getPage(Role role, RestRequest request) {
     Page<Role> page = new Page<>();
     page.setCurrent(request.getPageNum());
     page.setSize(request.getPageSize());
     return this.baseMapper.selectPage(page, role);
   }
 
   @Override
-  public Role findByName(String roleName) {
+  public Role getByName(String roleName) {
     return baseMapper.selectOne(new LambdaQueryWrapper<Role>().eq(Role::getRoleName, roleName));
   }
 
@@ -88,7 +88,7 @@ public void deleteRole(Long roleId) {
                 () ->
                     new ApiAlertException(
                         String.format("Role id [%s] not found. Delete role failed.", roleId)));
-    List<Long> userIdsByRoleId = memberService.findUserIdsByRoleId(roleId);
+    List<Long> userIdsByRoleId = memberService.listUserIdsByRoleId(roleId);
     ApiAlertException.throwIfFalse(
         CollectionUtils.isEmpty(userIdsByRoleId),
         String.format(

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/AccessTokenServiceTest.java
Patch:
@@ -55,18 +55,18 @@ void testCrudToken() throws Exception {
     String username = JWTUtil.getUserName(jwtToken.getToken());
     Assertions.assertNotNull(username);
     Assertions.assertEquals("admin", username);
-    User user = userService.findByName(username);
+    User user = userService.getByUsername(username);
     Assertions.assertNotNull(user);
     Assertions.assertTrue(JWTUtil.verify(jwtToken.getToken(), username));
 
     // list
     AccessToken mockToken1 = new AccessToken();
     mockToken1.setUserId(100000L);
-    IPage<AccessToken> tokens1 = accessTokenService.findAccessTokens(mockToken1, new RestRequest());
+    IPage<AccessToken> tokens1 = accessTokenService.getPage(mockToken1, new RestRequest());
     Assertions.assertEquals(1, tokens1.getRecords().size());
     AccessToken mockToken2 = new AccessToken();
     mockToken2.setUserId(100001L);
-    IPage<AccessToken> tokens2 = accessTokenService.findAccessTokens(mockToken2, new RestRequest());
+    IPage<AccessToken> tokens2 = accessTokenService.getPage(mockToken2, new RestRequest());
     Assertions.assertTrue(tokens2.getRecords().isEmpty());
 
     // toggle

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationController.java
Patch:
@@ -139,7 +139,7 @@ public RestResponse update(Application app) {
   @Operation(summary = "Get applications dashboard data")
   @PostMapping("dashboard")
   public RestResponse dashboard(Long teamId) {
-    Map<String, Serializable> map = applicationInfoService.dashboard(teamId);
+    Map<String, Serializable> map = applicationInfoService.getDashboardDataMap(teamId);
     return RestResponse.success(map);
   }
 
@@ -319,14 +319,14 @@ public RestResponse getMain(Application application) {
   @Operation(summary = "List application backups")
   @PostMapping("backups")
   public RestResponse backups(ApplicationBackUp backUp, RestRequest request) {
-    IPage<ApplicationBackUp> backups = backUpService.page(backUp, request);
+    IPage<ApplicationBackUp> backups = backUpService.getPage(backUp, request);
     return RestResponse.success(backups);
   }
 
   @Operation(summary = "List application operation logs")
   @PostMapping("optionlog")
   public RestResponse optionlog(ApplicationLog applicationLog, RestRequest request) {
-    IPage<ApplicationLog> applicationList = applicationLogService.page(applicationLog, request);
+    IPage<ApplicationLog> applicationList = applicationLogService.getPage(applicationLog, request);
     return RestResponse.success(applicationList);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ConfigController.java
Patch:
@@ -66,14 +66,14 @@ public RestResponse template() {
   @Operation(summary = "List the application configs")
   @PostMapping("list")
   public RestResponse list(ApplicationConfig config, RestRequest request) {
-    IPage<ApplicationConfig> page = applicationConfigService.page(config, request);
+    IPage<ApplicationConfig> page = applicationConfigService.getPage(config, request);
     return RestResponse.success(page);
   }
 
   @Operation(summary = "List application config histories")
   @PostMapping("history")
   public RestResponse history(Application application) {
-    List<ApplicationConfig> history = applicationConfigService.history(application);
+    List<ApplicationConfig> history = applicationConfigService.list(application);
     return RestResponse.success(history);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkSqlController.java
Patch:
@@ -90,7 +90,7 @@ public RestResponse verify(String sql, Long versionId, Long teamId) {
   @Operation(summary = "List the application sql")
   @PostMapping("list")
   public RestResponse list(Long appId, RestRequest request) {
-    IPage<FlinkSql> page = flinkSqlService.page(appId, request);
+    IPage<FlinkSql> page = flinkSqlService.getPage(appId, request);
     return RestResponse.success(page);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/MessageController.java
Patch:
@@ -46,7 +46,7 @@ public class MessageController {
   @PostMapping("notice")
   public RestResponse notice(Integer type, RestRequest request) {
     NoticeTypeEnum noticeTypeEnum = NoticeTypeEnum.of(type);
-    IPage<Message> pages = messageService.getUnRead(noticeTypeEnum, request);
+    IPage<Message> pages = messageService.getUnReadPage(noticeTypeEnum, request);
     return RestResponse.success(pages);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ProjectController.java
Patch:
@@ -98,7 +98,7 @@ public RestResponse list(Project project, RestRequest restRequest) {
     if (project.getTeamId() == null) {
       return RestResponse.success(Collections.emptyList());
     }
-    IPage<Project> page = projectService.page(project, restRequest);
+    IPage<Project> page = projectService.getPage(project, restRequest);
     return RestResponse.success().data(page);
   }
 
@@ -127,7 +127,7 @@ public RestResponse gitCheck(Project project) {
   @Operation(summary = "Check the project")
   @PostMapping("exists")
   public RestResponse exists(Project project) {
-    boolean exists = projectService.checkExists(project);
+    boolean exists = projectService.exists(project);
     return RestResponse.success().data(exists);
   }
 
@@ -155,7 +155,7 @@ public RestResponse listConf(Project project) {
   @Operation(summary = "List the team projects")
   @PostMapping("select")
   public RestResponse select(@RequestParam Long teamId) {
-    List<Project> list = projectService.findByTeamId(teamId);
+    List<Project> list = projectService.listByTeamId(teamId);
     return RestResponse.success().data(list);
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ResourceController.java
Patch:
@@ -68,7 +68,7 @@ public RestResponse checkResource(@Valid Resource resource) throws Exception {
   @Operation(summary = "List resources")
   @PostMapping("page")
   public RestResponse page(RestRequest restRequest, Resource resource) {
-    IPage<Resource> page = resourceService.page(resource, restRequest);
+    IPage<Resource> page = resourceService.getPage(resource, restRequest);
     return RestResponse.success(page);
   }
 
@@ -91,7 +91,7 @@ public RestResponse deleteResource(@Valid Resource resource) {
   @Operation(summary = "List resource")
   @PostMapping("list")
   public RestResponse listResource(@RequestParam Long teamId) {
-    List<Resource> resourceList = resourceService.findByTeamId(teamId);
+    List<Resource> resourceList = resourceService.listByTeamId(teamId);
     return RestResponse.success(resourceList);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/SavePointController.java
Patch:
@@ -64,7 +64,7 @@ public RestResponse latest(Long appId) {
   @Operation(summary = "List application savepoint histories")
   @PostMapping("history")
   public RestResponse history(SavePoint savePoint, RestRequest request) {
-    IPage<SavePoint> page = savePointService.page(savePoint, request);
+    IPage<SavePoint> page = savePointService.getPage(savePoint, request);
     return RestResponse.success(page);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/VariableController.java
Patch:
@@ -63,7 +63,7 @@ public class VariableController {
   @PostMapping("page")
   @RequiresPermissions("variable:view")
   public RestResponse page(RestRequest restRequest, Variable variable) {
-    IPage<Variable> page = variableService.page(variable, restRequest);
+    IPage<Variable> page = variableService.getPage(variable, restRequest);
     for (Variable v : page.getRecords()) {
       v.dataMasking();
     }
@@ -80,7 +80,7 @@ public RestResponse page(RestRequest restRequest, Variable variable) {
   @Operation(summary = "List variables")
   @PostMapping("list")
   public RestResponse variableList(@RequestParam Long teamId, String keyword) {
-    List<Variable> variableList = variableService.findByTeamId(teamId, keyword);
+    List<Variable> variableList = variableService.listByTeamId(teamId, keyword);
     for (Variable v : variableList) {
       v.dataMasking();
     }
@@ -91,7 +91,7 @@ public RestResponse variableList(@RequestParam Long teamId, String keyword) {
   @PostMapping("dependApps")
   @RequiresPermissions("variable:depend_apps")
   public RestResponse dependApps(RestRequest restRequest, Variable variable) {
-    IPage<Application> dependApps = variableService.dependAppsPage(variable, restRequest);
+    IPage<Application> dependApps = variableService.getDependAppsPage(variable, restRequest);
     return RestResponse.success(dependApps);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/YarnQueueController.java
Patch:
@@ -55,7 +55,7 @@ public class YarnQueueController {
   @ApiAccess
   @PostMapping("list")
   public RestResponse list(RestRequest restRequest, YarnQueue yarnQueue) {
-    IPage<YarnQueue> queuePage = yarnQueueService.findYarnQueues(yarnQueue, restRequest);
+    IPage<YarnQueue> queuePage = yarnQueueService.getPage(yarnQueue, restRequest);
     return RestResponse.success(queuePage);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/AppBuildPipeService.java
Patch:
@@ -55,7 +55,7 @@ public interface AppBuildPipeService extends IService<AppBuildPipeline> {
   boolean allowToBuildNow(@Nonnull Long appId);
 
   /** list pipeline status on application id list */
-  Map<Long, PipelineStatusEnum> listPipelineStatus(List<Long> appIds);
+  Map<Long, PipelineStatusEnum> listAppIdPipelineStatusMap(List<Long> appIds);
 
   /**
    * delete appBuildPipeline By application

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationBackUpService.java
Patch:
@@ -53,7 +53,7 @@ public interface ApplicationBackUpService extends IService<ApplicationBackUp> {
    * @param request The {@link RestRequest} object used for pagination and sorting.
    * @return An {@link IPage} containing the retrieved {@link ApplicationBackUp} objects.
    */
-  IPage<ApplicationBackUp> page(ApplicationBackUp bakParam, RestRequest request);
+  IPage<ApplicationBackUp> getPage(ApplicationBackUp bakParam, RestRequest request);
 
   /**
    * Rolls back the changes made by the specified application backup.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationConfigService.java
Patch:
@@ -100,15 +100,15 @@ public interface ApplicationConfigService extends IService<ApplicationConfig> {
    * @return an IPage containing the ApplicationConfig objects that match the filter criteria
    *     specified in the config object, limited by the settings in the request object
    */
-  IPage<ApplicationConfig> page(ApplicationConfig config, RestRequest request);
+  IPage<ApplicationConfig> getPage(ApplicationConfig config, RestRequest request);
 
   /**
    * Retrieves the history of application configurations for a given application.
    *
    * @param appParam The application for which to retrieve the history.
    * @return The list of application configurations representing the history.
    */
-  List<ApplicationConfig> history(Application appParam);
+  List<ApplicationConfig> list(Application appParam);
 
   /**
    * Reads a template from a file or a database.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationLogService.java
Patch:
@@ -25,7 +25,7 @@
 
 public interface ApplicationLogService extends IService<ApplicationLog> {
 
-  IPage<ApplicationLog> page(ApplicationLog applicationLog, RestRequest request);
+  IPage<ApplicationLog> getPage(ApplicationLog applicationLog, RestRequest request);
 
   void removeApp(Long appId);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkClusterService.java
Patch:
@@ -49,7 +49,7 @@ public interface FlinkClusterService extends IService<FlinkCluster> {
 
   Boolean existsByFlinkEnvId(Long id);
 
-  List<FlinkCluster> getByExecutionModes(Collection<FlinkExecutionMode> executionModeEnums);
+  List<FlinkCluster> listByExecutionModes(Collection<FlinkExecutionMode> executionModeEnums);
 
   void updateClusterState(Long id, ClusterState state);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkSqlService.java
Patch:
@@ -52,7 +52,7 @@ public interface FlinkSqlService extends IService<FlinkSql> {
 
   FlinkSqlValidationResult verifySql(String sql, Long versionId);
 
-  List<FlinkSql> getByTeamId(Long teamId);
+  List<FlinkSql> listByTeamId(Long teamId);
 
-  IPage<FlinkSql> page(Long appId, RestRequest request);
+  IPage<FlinkSql> getPage(Long appId, RestRequest request);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/MessageService.java
Patch:
@@ -28,5 +28,5 @@ public interface MessageService extends IService<Message> {
 
   void push(Message message);
 
-  IPage<Message> getUnRead(NoticeTypeEnum noticeTypeEnum, RestRequest request);
+  IPage<Message> getUnReadPage(NoticeTypeEnum noticeTypeEnum, RestRequest request);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ResourceService.java
Patch:
@@ -37,7 +37,7 @@ public interface ResourceService extends IService<Resource> {
    * @param restRequest queryRequest
    * @return IPage
    */
-  IPage<Resource> page(Resource resource, RestRequest restRequest);
+  IPage<Resource> getPage(Resource resource, RestRequest restRequest);
 
   /**
    * check resource exists by user id
@@ -81,7 +81,7 @@ public interface ResourceService extends IService<Resource> {
    * @param teamId
    * @return team resources
    */
-  List<Resource> findByTeamId(Long teamId);
+  List<Resource> listByTeamId(Long teamId);
 
   /**
    * change resource owner

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/SavePointService.java
Patch:
@@ -71,7 +71,7 @@ public interface SavePointService extends IService<SavePoint> {
    * @param request The RestRequest object containing additional request parameters.
    * @return An instance of IPage<SavePoint> representing the page of SavePoint objects.
    */
-  IPage<SavePoint> page(SavePoint savePoint, RestRequest request);
+  IPage<SavePoint> getPage(SavePoint savePoint, RestRequest request);
 
   /**
    * Removes all savepoints for the specified application.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/YarnQueueService.java
Patch:
@@ -27,7 +27,7 @@
 
 public interface YarnQueueService extends IService<YarnQueue> {
 
-  IPage<YarnQueue> findYarnQueues(YarnQueue yarnQueue, RestRequest restRequest);
+  IPage<YarnQueue> getPage(YarnQueue yarnQueue, RestRequest restRequest);
 
   ResponseResult<String> checkYarnQueue(YarnQueue yarnQueue);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -577,7 +577,7 @@ public boolean allowToBuildNow(@Nonnull Long appId) {
   }
 
   @Override
-  public Map<Long, PipelineStatusEnum> listPipelineStatus(List<Long> appIds) {
+  public Map<Long, PipelineStatusEnum> listAppIdPipelineStatusMap(List<Long> appIds) {
     if (CollectionUtils.isEmpty(appIds)) {
       return Collections.emptyMap();
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationBackUpServiceImpl.java
Patch:
@@ -62,7 +62,7 @@ public class ApplicationBackUpServiceImpl
   @Autowired private FlinkSqlService flinkSqlService;
 
   @Override
-  public IPage<ApplicationBackUp> page(ApplicationBackUp bakParam, RestRequest request) {
+  public IPage<ApplicationBackUp> getPage(ApplicationBackUp bakParam, RestRequest request) {
     Page<ApplicationBackUp> page = new MybatisPager<ApplicationBackUp>().getDefaultPage(request);
     LambdaQueryWrapper<ApplicationBackUp> queryWrapper =
         new LambdaQueryWrapper<ApplicationBackUp>()

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationConfigServiceImpl.java
Patch:
@@ -202,7 +202,7 @@ public ApplicationConfig get(Long id) {
   }
 
   @Override
-  public IPage<ApplicationConfig> page(ApplicationConfig config, RestRequest request) {
+  public IPage<ApplicationConfig> getPage(ApplicationConfig config, RestRequest request) {
     Page<ApplicationConfig> page =
         new MybatisPager<ApplicationConfig>().getPage(request, "version", Constant.ORDER_DESC);
     IPage<ApplicationConfig> configList =
@@ -212,7 +212,7 @@ public IPage<ApplicationConfig> page(ApplicationConfig config, RestRequest reque
   }
 
   @Override
-  public List<ApplicationConfig> history(Application appParam) {
+  public List<ApplicationConfig> list(Application appParam) {
     LambdaQueryWrapper<ApplicationConfig> queryWrapper =
         new LambdaQueryWrapper<ApplicationConfig>()
             .eq(ApplicationConfig::getAppId, appParam.getId())

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationLogServiceImpl.java
Patch:
@@ -40,7 +40,7 @@ public class ApplicationLogServiceImpl extends ServiceImpl<ApplicationLogMapper,
     implements ApplicationLogService {
 
   @Override
-  public IPage<ApplicationLog> page(ApplicationLog applicationLog, RestRequest request) {
+  public IPage<ApplicationLog> getPage(ApplicationLog applicationLog, RestRequest request) {
     Page<ApplicationLog> page =
         new MybatisPager<ApplicationLog>().getPage(request, "option_time", Constant.ORDER_DESC);
     LambdaQueryWrapper<ApplicationLog> queryWrapper =

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -304,7 +304,8 @@ public Boolean existsByFlinkEnvId(Long flinkEnvId) {
   }
 
   @Override
-  public List<FlinkCluster> getByExecutionModes(Collection<FlinkExecutionMode> executionModeEnums) {
+  public List<FlinkCluster> listByExecutionModes(
+      Collection<FlinkExecutionMode> executionModeEnums) {
     return getBaseMapper()
         .selectList(
             new LambdaQueryWrapper<FlinkCluster>()

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -210,12 +210,12 @@ public FlinkSqlValidationResult verifySql(String sql, Long versionId) {
   }
 
   @Override
-  public List<FlinkSql> getByTeamId(Long teamId) {
+  public List<FlinkSql> listByTeamId(Long teamId) {
     return this.baseMapper.selectSqlsByTeamId(teamId);
   }
 
   @Override
-  public IPage<FlinkSql> page(Long appId, RestRequest request) {
+  public IPage<FlinkSql> getPage(Long appId, RestRequest request) {
     Page<FlinkSql> page =
         new MybatisPager<FlinkSql>().getPage(request, "version", Constant.ORDER_DESC);
     LambdaQueryWrapper<FlinkSql> queryWrapper =

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/MessageServiceImpl.java
Patch:
@@ -47,7 +47,7 @@ public void push(Message message) {
   }
 
   @Override
-  public IPage<Message> getUnRead(NoticeTypeEnum noticeTypeEnum, RestRequest request) {
+  public IPage<Message> getUnReadPage(NoticeTypeEnum noticeTypeEnum, RestRequest request) {
     Page<Message> page = new MybatisPager<Message>().getDefaultPage(request);
     LambdaQueryWrapper<Message> queryWrapper =
         new LambdaQueryWrapper<Message>()

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SavePointServiceImpl.java
Patch:
@@ -212,7 +212,7 @@ public Boolean delete(Long id, Application appParam) throws InternalException {
   }
 
   @Override
-  public IPage<SavePoint> page(SavePoint savePoint, RestRequest request) {
+  public IPage<SavePoint> getPage(SavePoint savePoint, RestRequest request) {
     Page<SavePoint> page =
         new MybatisPager<SavePoint>().getPage(request, "trigger_time", Constant.ORDER_DESC);
     LambdaQueryWrapper<SavePoint> queryWrapper =

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/YarnQueueServiceImpl.java
Patch:
@@ -71,7 +71,7 @@ public class YarnQueueServiceImpl extends ServiceImpl<YarnQueueMapper, YarnQueue
   @Autowired private FlinkClusterService flinkClusterService;
 
   @Override
-  public IPage<YarnQueue> findYarnQueues(YarnQueue yarnQueue, RestRequest request) {
+  public IPage<YarnQueue> getPage(YarnQueue yarnQueue, RestRequest request) {
     Utils.notNull(yarnQueue, "Yarn queue query params mustn't be null.");
     Utils.notNull(yarnQueue.getTeamId(), "Team id of yarn queue query params mustn't be null.");
     Page<YarnQueue> page = new Page<>();
@@ -217,7 +217,7 @@ public YarnQueue getYarnQueueByIdWithPreconditions(YarnQueue yarnQueue) {
   public void checkNotReferencedByFlinkClusters(
       @Nonnull String queueLabel, @Nonnull String operation) {
     List<FlinkCluster> clustersReferenceYarnQueueLabel =
-        flinkClusterService.getByExecutionModes(Sets.newHashSet(FlinkExecutionMode.YARN_SESSION))
+        flinkClusterService.listByExecutionModes(Sets.newHashSet(FlinkExecutionMode.YARN_SESSION))
             .stream()
             .filter(flinkCluster -> StringUtils.equals(flinkCluster.getYarnQueue(), queueLabel))
             .collect(Collectors.toList());
@@ -231,7 +231,7 @@ public void checkNotReferencedByApplications(
       @Nonnull Long teamId, @Nonnull String queueLabel, @Nonnull String operation) {
     List<Application> appsReferenceQueueLabel =
         applicationManageService
-            .getByTeamIdAndExecutionModes(
+            .listByTeamIdAndExecutionModes(
                 teamId,
                 Sets.newHashSet(
                     FlinkExecutionMode.YARN_APPLICATION, FlinkExecutionMode.YARN_PER_JOB))

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/watcher/FlinkAppLostWatcher.java
Patch:
@@ -87,7 +87,7 @@ private void start() {
 
   public void watch(List<Application> applications) {
     List<Application> probeApplication =
-        applications.isEmpty() ? applicationManageService.getProbeApps() : applications;
+        applications.isEmpty() ? applicationManageService.listProbeApps() : applications;
     if (probeApplication.isEmpty()) {
       log.info("there is no application that needs to be probe");
       return;
@@ -113,7 +113,7 @@ private void updateState(List<Application> applications) {
   }
 
   private void handleProbeResults() {
-    List<Application> probeApps = applicationManageService.getProbeApps();
+    List<Application> probeApps = applicationManageService.listProbeApps();
     if (shouldRetry(probeApps)) {
       watch(probeApps);
     } else {

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/YarnQueueServiceTest.java
Patch:
@@ -87,7 +87,7 @@ void testFindYarnQueues() {
     RestRequest request = new RestRequest();
     request.setPageSize(2);
     request.setPageNum(1);
-    IPage<YarnQueue> yarnQueues = yarnQueueService.findYarnQueues(queryParams, request);
+    IPage<YarnQueue> yarnQueues = yarnQueueService.getPage(queryParams, request);
     assertThat(
             yarnQueues.getRecords().stream()
                 .map(YarnQueue::getQueueLabel)
@@ -97,7 +97,7 @@ void testFindYarnQueues() {
     // Test for 1st page, size = 2, order by create time with queue_label
     queryParams.setQueueLabel("q3");
     IPage<YarnQueue> yarnQueuesWithQueueLabelLikeQuery =
-        yarnQueueService.findYarnQueues(queryParams, request);
+        yarnQueueService.getPage(queryParams, request);
     assertThat(
             yarnQueuesWithQueueLabelLikeQuery.getRecords().stream()
                 .map(YarnQueue::getQueueLabel)

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/AlertConfigMapper.java
Patch:
@@ -24,5 +24,5 @@
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;
 
 public interface AlertConfigMapper extends BaseMapper<AlertConfig> {
-  AlertConfig getAlertConfByName(@Param("alertConfig") AlertConfig alertConfig);
+  AlertConfig selectAlertConfByName(@Param("alertConfig") AlertConfig alertConfig);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/FlinkEnvMapper.java
Patch:
@@ -25,7 +25,7 @@
 
 public interface FlinkEnvMapper extends BaseMapper<FlinkEnv> {
 
-  FlinkEnv getByAppId(@Param("appId") Long appId);
+  FlinkEnv selectByAppId(@Param("appId") Long appId);
 
   void setDefault(@Param("id") Long id);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/FlinkSqlMapper.java
Patch:
@@ -31,5 +31,5 @@ public interface FlinkSqlMapper extends BaseMapper<FlinkSql> {
 
   Integer getLatestVersion(@Param("appId") Long appId);
 
-  List<FlinkSql> getByTeamId(@Param("teamId") Long teamId);
+  List<FlinkSql> selectSqlsByTeamId(@Param("teamId") Long teamId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ProjectMapper.java
Patch:
@@ -33,9 +33,9 @@ public interface ProjectMapper extends BaseMapper<Project> {
 
   void updateBuildTime(@Param("id") Long id);
 
-  IPage<Project> page(Page<Project> page, @Param("project") Project project);
+  IPage<Project> selectPage(Page<Project> page, @Param("project") Project project);
 
   Boolean existsByTeamId(@Param("teamId") Long teamId);
 
-  List<Project> selectByTeamId(@Param("teamId") Long teamId);
+  List<Project> selectProjectsByTeamId(@Param("teamId") Long teamId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ResourceMapper.java
Patch:
@@ -27,7 +27,7 @@
 
 public interface ResourceMapper extends BaseMapper<Resource> {
 
-  IPage<Resource> page(Page<Resource> page, @Param("resource") Resource resource);
+  IPage<Resource> selectPage(Page<Resource> page, @Param("resource") Resource resource);
 
   boolean existsByUserId(@Param("userId") Long userId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/VariableMapper.java
Patch:
@@ -29,9 +29,9 @@
 
 public interface VariableMapper extends BaseMapper<Variable> {
 
-  IPage<Variable> page(Page<Variable> page, @Param("variable") Variable variable);
+  IPage<Variable> selectPage(Page<Variable> page, @Param("variable") Variable variable);
 
-  List<Variable> selectByTeamId(@Param("teamId") Long teamId, @Param("keyword") String keyword);
+  List<Variable> selectVarsByTeamId(@Param("teamId") Long teamId, @Param("keyword") String keyword);
 
   Boolean existsByTeamId(@Param("teamId") Long teamId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/YarnQueueMapper.java
Patch:
@@ -27,7 +27,7 @@
 
 /** Yarn queue mapper definition. */
 public interface YarnQueueMapper extends BaseMapper<YarnQueue> {
-  IPage<YarnQueue> findQueues(Page<YarnQueue> page, @Param("yarnQueue") YarnQueue yarnQueue);
+  IPage<YarnQueue> selectPage(Page<YarnQueue> page, @Param("yarnQueue") YarnQueue yarnQueue);
 
   boolean existsByQueueLabel(@Param("yarnQueue") YarnQueue yarnQueue);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/alert/impl/AlertConfigServiceImpl.java
Patch:
@@ -69,7 +69,7 @@ public IPage<AlertConfigParams> page(AlertConfigParams params, RestRequest reque
 
   @Override
   public boolean exist(AlertConfig alertConfig) {
-    AlertConfig confByName = this.baseMapper.getAlertConfByName(alertConfig);
+    AlertConfig confByName = this.baseMapper.selectAlertConfByName(alertConfig);
     return confByName != null;
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationActionServiceImpl.java
Patch:
@@ -205,7 +205,7 @@ public void restart(Application appParam) throws Exception {
   public void forcedStop(Application appParam) {
     CompletableFuture<SubmitResponse> startFuture = startFutureMap.remove(appParam.getId());
     CompletableFuture<CancelResponse> cancelFuture = cancelFutureMap.remove(appParam.getId());
-    Application application = this.baseMapper.getApp(appParam);
+    Application application = this.baseMapper.selectApp(appParam);
     if (isKubernetesApp(application)) {
       KubernetesDeploymentHelper.watchPodTerminatedLog(
           application.getK8sNamespace(), application.getJobName(), application.getJobId());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -121,7 +121,7 @@ public void setDefault(Long id) {
 
   @Override
   public FlinkEnv getByAppId(Long appId) {
-    return this.baseMapper.getByAppId(appId);
+    return this.baseMapper.selectByAppId(appId);
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -211,7 +211,7 @@ public FlinkSqlValidationResult verifySql(String sql, Long versionId) {
 
   @Override
   public List<FlinkSql> getByTeamId(Long teamId) {
-    return this.baseMapper.getByTeamId(teamId);
+    return this.baseMapper.selectSqlsByTeamId(teamId);
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -179,7 +179,7 @@ public boolean delete(Long id) {
   @Override
   public IPage<Project> page(Project project, RestRequest request) {
     Page<Project> page = new MybatisPager<Project>().getDefaultPage(request);
-    return this.baseMapper.page(page, project);
+    return this.baseMapper.selectPage(page, project);
   }
 
   @Override
@@ -189,7 +189,7 @@ public Boolean existsByTeamId(Long teamId) {
 
   @Override
   public List<Project> findByTeamId(Long teamId) {
-    return this.baseMapper.selectByTeamId(teamId);
+    return this.baseMapper.selectProjectsByTeamId(teamId);
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -104,7 +104,7 @@ public IPage<Resource> page(Resource resource, RestRequest restRequest) {
       return null;
     }
     Page<Resource> page = new MybatisPager<Resource>().getDefaultPage(restRequest);
-    return this.baseMapper.page(page, resource);
+    return this.baseMapper.selectPage(page, resource);
   }
 
   /**

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/VariableServiceImpl.java
Patch:
@@ -95,7 +95,7 @@ public IPage<Variable> page(Variable variable, RestRequest request) {
       return null;
     }
     Page<Variable> page = new MybatisPager<Variable>().getDefaultPage(request);
-    return this.baseMapper.page(page, variable);
+    return this.baseMapper.selectPage(page, variable);
   }
 
   @Override
@@ -170,7 +170,7 @@ public List<Variable> findByTeamId(Long teamId) {
    */
   @Override
   public List<Variable> findByTeamId(Long teamId, String keyword) {
-    return baseMapper.selectByTeamId(teamId, keyword);
+    return baseMapper.selectVarsByTeamId(teamId, keyword);
   }
 
   /**

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/YarnQueueServiceImpl.java
Patch:
@@ -77,7 +77,7 @@ public IPage<YarnQueue> findYarnQueues(YarnQueue yarnQueue, RestRequest request)
     Page<YarnQueue> page = new Page<>();
     page.setCurrent(request.getPageNum());
     page.setSize(request.getPageSize());
-    return this.baseMapper.findQueues(page, yarnQueue);
+    return this.baseMapper.selectPage(page, yarnQueue);
   }
 
   /**

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationActionServiceImpl.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.core.service.application.impl;
 
+import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.ConfigConst;
 import org.apache.streampark.common.conf.K8sFlinkConfig;
 import org.apache.streampark.common.conf.Workspace;
@@ -651,7 +652,8 @@ private Tuple2<String, String> getUserJarAndAppConf(FlinkEnv flinkEnv, Applicati
             case STREAMPARK_FLINK:
               flinkUserJar =
                   String.format(
-                      "%s/%s", application.getAppLib(), application.getModule().concat(".jar"));
+                      "%s/%s",
+                      application.getAppLib(), application.getModule().concat(Constant.JAR_SUFFIX));
               break;
             case APACHE_FLINK:
               flinkUserJar = String.format("%s/%s", application.getAppHome(), application.getJar());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationInfoServiceImpl.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.core.service.application.impl;
 
+import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.K8sFlinkConfig;
 import org.apache.streampark.common.conf.Workspace;
 import org.apache.streampark.common.enums.FlinkExecutionMode;
@@ -311,7 +312,7 @@ public List<String> historyUploadJars() {
         .filter(File::isFile)
         .sorted(Comparator.comparingLong(File::lastModified).reversed())
         .map(File::getName)
-        .filter(fn -> fn.endsWith(".jar"))
+        .filter(fn -> fn.endsWith(Constant.JAR_SUFFIX))
         .limit(DEFAULT_HISTORY_RECORD_LIMIT)
         .collect(Collectors.toList());
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.core.service.impl;
 
+import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.ConfigConst;
 import org.apache.streampark.common.conf.K8sFlinkConfig;
 import org.apache.streampark.common.conf.Workspace;
@@ -532,7 +533,8 @@ private String retrieveFlinkUserJar(FlinkEnv flinkEnv, Application app) {
       case CUSTOM_CODE:
         switch (app.getApplicationType()) {
           case STREAMPARK_FLINK:
-            return String.format("%s/%s", app.getAppLib(), app.getModule().concat(".jar"));
+            return String.format(
+                "%s/%s", app.getAppLib(), app.getModule().concat(Constant.JAR_SUFFIX));
           case APACHE_FLINK:
             return String.format("%s/%s", app.getAppHome(), app.getJar());
           default:

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.core.service.impl;
 
+import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.conf.CommonConfig;
 import org.apache.streampark.common.conf.InternalConfigHolder;
 import org.apache.streampark.common.conf.Workspace;
@@ -251,7 +252,7 @@ public List<String> jars(Project project) {
         project.getModule(), "Project module can't be null, please check.");
     File apps = new File(project.getDistHome(), project.getModule());
     for (File file : Objects.requireNonNull(apps.listFiles())) {
-      if (file.getName().endsWith(".jar")) {
+      if (file.getName().endsWith(Constant.JAR_SUFFIX)) {
         list.add(file.getName());
       }
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/ProjectBuildTask.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.core.task;
 
+import org.apache.streampark.common.Constant;
 import org.apache.streampark.common.util.CommandUtils;
 import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.util.GitUtils;
@@ -181,7 +182,7 @@ private void deploy(Project project) throws Exception {
       } else {
         // 2) .jar file(normal or official standard flink project)
         Utils.checkJarFile(app.toURI().toURL());
-        String moduleName = app.getName().replace(".jar", "");
+        String moduleName = app.getName().replace(Constant.JAR_SUFFIX, "");
         File distHome = project.getDistHome();
         File targetDir = new File(distHome, moduleName);
         if (!targetDir.exists()) {
@@ -211,7 +212,7 @@ private void findTarOrJar(List<File> list, File path) {
             // 2) try look for jar files, there may be multiple jars found.
             if (!targetFile.getName().startsWith("original-")
                 && !targetFile.getName().endsWith("-sources.jar")
-                && targetFile.getName().endsWith(".jar")) {
+                && targetFile.getName().endsWith(Constant.JAR_SUFFIX)) {
               if (jar == null) {
                 jar = targetFile;
               } else {

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/base/util/ShaHashUtilsTest.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.streampark.console.base.util;
 
+import org.apache.streampark.common.Constant;
+
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
 
@@ -26,7 +28,7 @@ class ShaHashUtilsTest {
   @Test
   void testEncrypt() {
     String randomSalt = "rh8b1ojwog777yrg0daesf04gk";
-    String encryptPassword = ShaHashUtils.encrypt(randomSalt, "streampark");
+    String encryptPassword = ShaHashUtils.encrypt(randomSalt, Constant.STREAM_PARK);
     Assertions.assertEquals(
         "2513f3748847298ea324dffbf67fe68681dd92315bda830065facd8efe08f54f", encryptPassword);
   }

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-hbase/src/main/java/org/apache/streampark/flink/connector/hbase/source/HBaseJavaSource.java
Patch:
@@ -42,8 +42,8 @@ public DataStreamSource<T> getDataStream(
       HBaseResultFunction<T> resultFunction,
       RunningFunction runningFunc) {
 
-    Utils.notNull(queryFunction, "queryFunction must not be null");
-    Utils.notNull(resultFunction, "resultFunction must not be null");
+    Utils.notNull(queryFunction, "QueryFunction must not be null");
+    Utils.notNull(resultFunction, "ResultFunction must not be null");
     HBaseSourceFunction<T> sourceFunction =
         new HBaseSourceFunction<>(property, queryFunction, resultFunction, runningFunc, null);
     return context.getJavaEnv().addSource(sourceFunction);

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-jdbc/src/main/java/org/apache/streampark/flink/connector/jdbc/sink/JdbcJavaSink.java
Patch:
@@ -55,7 +55,7 @@ public JdbcJavaSink<T> sql(TransformFunction<T, String> func) {
   }
 
   public DataStreamSink<T> sink(DataStream<T> dataStream) {
-    Utils.notNull(sqlFunc, "transformFunction can not be null");
+    Utils.notNull(sqlFunc, "TransformFunction can not be null");
     this.jdbc =
         this.jdbc == null ? ConfigUtils.getJdbcConf(context.parameter().toMap(), alias) : this.jdbc;
     JdbcSinkFunction<T> sinkFun = new JdbcSinkFunction<>(this.jdbc, this.sqlFunc);

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-jdbc/src/main/java/org/apache/streampark/flink/connector/jdbc/source/JdbcJavaSource.java
Patch:
@@ -54,8 +54,8 @@ public DataStreamSource<T> getDataStream(
       SQLResultFunction<T> resultFunction,
       RunningFunction runningFunc) {
 
-    Utils.notNull(queryFunction, "queryFunction must not be null");
-    Utils.notNull(resultFunction, "resultFunction must not be null");
+    Utils.notNull(queryFunction, "'queryFunction' must not be null");
+    Utils.notNull(resultFunction, "'resultFunction' must not be null");
     this.jdbc =
         this.jdbc == null ? ConfigUtils.getJdbcConf(context.parameter().toMap(), alias) : this.jdbc;
     JdbcSourceFunction<T> sourceFunction =

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-mongo/src/main/java/org/apache/streampark/flink/connector/mongo/source/MongoJavaSource.java
Patch:
@@ -43,9 +43,9 @@ public DataStreamSource<T> getDataStream(
       MongoResultFunction<T> resultFunction,
       RunningFunction runningFunc) {
 
-    Utils.notNull(collectionName, "collectionName must not be null");
-    Utils.notNull(queryFunction, "queryFunction must not be null");
-    Utils.notNull(resultFunction, "resultFunction must not be null");
+    Utils.notNull(collectionName, "'collectionName' must not be null");
+    Utils.notNull(queryFunction, "'queryFunction' must not be null");
+    Utils.notNull(resultFunction, "'resultFunction' must not be null");
     MongoSourceFunction<T> sourceFunction =
         new MongoSourceFunction<>(
             collectionName, property, queryFunction, resultFunction, runningFunc, null);

File: streampark-flink/streampark-flink-sql-gateway/streampark-flink-sql-gateway-base/src/main/java/org/apache/streampark/gateway/factories/FactoryUtil.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.gateway.factories;
 
+import org.apache.streampark.common.Constant;
 import org.apache.streampark.gateway.ConfigOption;
 import org.apache.streampark.gateway.exception.ValidationException;
 
@@ -30,7 +31,7 @@
 /** Factory utils for {@link Factory}. */
 public class FactoryUtil {
 
-  private static final String DEFAULT_IDENTIFIER = "default";
+  private static final String DEFAULT_IDENTIFIER = Constant.DEFAULT;
   private static final Logger LOG = LoggerFactory.getLogger(FactoryUtil.class);
   public static final ConfigOption<String> SQL_GATEWAY_SERVICE_TYPE =
       ConfigOption.key("streampark.sql-gateway.service")

File: streampark-flink/streampark-flink-sql-gateway/streampark-flink-sql-gateway-base/src/main/java/org/apache/streampark/gateway/factories/SqlGatewayServiceFactoryUtils.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.gateway.factories;
 
+import org.apache.streampark.common.Constant;
 import org.apache.streampark.gateway.ConfigOption;
 import org.apache.streampark.gateway.exception.ValidationException;
 import org.apache.streampark.gateway.service.SqlGatewayService;
@@ -56,7 +57,7 @@ public static List<SqlGatewayService> createSqlGatewayService(Map<String, String
                             "Service options do not contain an option key '%s' for discovering an service.",
                             SQL_GATEWAY_SERVICE_TYPE.getKey())));
 
-    List<String> identifiers = Arrays.asList(identifiersStr.split(";"));
+    List<String> identifiers = Arrays.asList(identifiersStr.split(Constant.SEMICOLON));
 
     if (identifiers.isEmpty()) {
       throw new ValidationException(

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/util/SpringContextUtils.java
Patch:
@@ -28,7 +28,8 @@ public class SpringContextUtils implements ApplicationContextAware {
   private static ApplicationContext applicationContext;
 
   @Override
-  public synchronized void setApplicationContext(ApplicationContext applicationContext) throws BeansException {
+  public synchronized void setApplicationContext(ApplicationContext applicationContext)
+      throws BeansException {
     SpringContextUtils.applicationContext = applicationContext;
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -94,6 +94,7 @@
 import com.github.benmanes.caffeine.cache.Cache;
 import com.github.benmanes.caffeine.cache.Caffeine;
 import lombok.extern.slf4j.Slf4j;
+import org.jetbrains.annotations.NotNull;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.stereotype.Service;
 import org.springframework.transaction.annotation.Propagation;
@@ -175,7 +176,7 @@ public class AppBuildPipeServiceImpl
    * @return Whether the pipeline was successfully started
    */
   @Override
-  public boolean buildApplication(Long appId, boolean forceBuild) {
+  public boolean buildApplication(@NotNull Long appId, boolean forceBuild) {
     // check the build environment
     checkBuildEnv(appId, forceBuild);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/watcher/FlinkAppHttpWatcher.java
Patch:
@@ -253,7 +253,7 @@ private void getStateFromFlink(Application application) throws Exception {
               ? jobsOverview.getJobs().stream()
                   .filter(a -> StringUtils.equals(application.getJobId(), a.getId()))
                   .findFirst()
-              : jobsOverview.getJobs().stream().findFirst();
+              : Optional.empty();
     } else {
       optional =
           jobsOverview.getJobs().stream()

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/authentication/JWTUtil.java
Patch:
@@ -114,7 +114,7 @@ public static String sign(Long userId, String userName, Long expireTime) {
           .withExpiresAt(date)
           .sign(algorithm);
     } catch (Exception e) {
-      log.error("error：{}", e);
+      log.error("error：{}", e.getMessage());
       return null;
     }
   }

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-doris/src/main/java/org/apache/streampark/flink/connector/doris/internal/DorisSinkFunction.java
Patch:
@@ -39,6 +39,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import java.util.Arrays;
 import java.util.Map;
 import java.util.Properties;
 
@@ -84,7 +85,7 @@ public void invoke(T value, SinkFunction.Context context) throws Exception {
         LOGGER.warn(
             String.format(
                 " row data not fulfilled. {database: %s, table: %s, dataRows: %s}",
-                data.getDatabase(), data.getTable(), data.getDataRows()));
+                data.getDatabase(), data.getTable(), Arrays.toString(data.getDataRows())));
         return;
       }
       dorisSinkWriter.writeRecords(data.getDatabase(), data.getTable(), data.getDataRows());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationController.java
Patch:
@@ -157,7 +157,7 @@ public RestResponse list(Application app, RestRequest request) {
   @PostMapping("mapping")
   @RequiresPermissions("app:mapping")
   public RestResponse mapping(Application app) {
-    boolean flag = applicationInfoService.mapping(app);
+    boolean flag = applicationManageService.mapping(app);
     return RestResponse.success(flag);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ProjectController.java
Patch:
@@ -46,7 +46,7 @@
 @Slf4j
 @Validated
 @RestController
-@RequestMapping("flink/project")
+@RequestMapping("project")
 public class ProjectController {
 
   @Autowired private ProjectService projectService;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/ApplicationBackUp.java
Patch:
@@ -47,6 +47,8 @@ public class ApplicationBackUp {
 
   private transient boolean backup;
 
+  public ApplicationBackUp() {}
+
   public ApplicationBackUp(Application application) {
     this.appId = application.getId();
     this.sqlId = application.getSqlId();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationActionServiceImpl.java
Patch:
@@ -63,7 +63,6 @@
 import org.apache.streampark.console.core.service.SettingService;
 import org.apache.streampark.console.core.service.VariableService;
 import org.apache.streampark.console.core.service.application.ApplicationActionService;
-import org.apache.streampark.console.core.service.application.ApplicationInfoService;
 import org.apache.streampark.console.core.service.application.ApplicationManageService;
 import org.apache.streampark.console.core.utils.FlinkK8sDataTypeConverterStub;
 import org.apache.streampark.console.core.watcher.FlinkAppHttpWatcher;
@@ -133,9 +132,8 @@ public class ApplicationActionServiceImpl extends ServiceImpl<ApplicationMapper,
           new ThreadPoolExecutor.AbortPolicy());
 
   @Autowired private ApplicationBackUpService backUpService;
-  @Autowired private ApplicationManageService applicationManageService;
 
-  @Autowired private ApplicationInfoService applicationInfoService;
+  @Autowired private ApplicationManageService applicationManageService;
 
   @Autowired private ApplicationConfigService configService;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/watcher/FlinkAppHttpWatcher.java
Patch:
@@ -186,7 +186,7 @@ public void init() {
   public void doStop() {
     log.info(
         "FlinkAppHttpWatcher StreamPark Console will be shutdown,persistent application to database.");
-    WATCHING_APPS.forEach((k, v) -> applicationInfoService.persistMetrics(v));
+    WATCHING_APPS.forEach((k, v) -> applicationManageService.persistMetrics(v));
   }
 
   /**
@@ -529,7 +529,7 @@ private void doPersistMetrics(Application application, boolean stopWatch) {
     } else {
       WATCHING_APPS.put(application.getId(), application);
     }
-    applicationInfoService.persistMetrics(application);
+    applicationManageService.persistMetrics(application);
   }
 
   /**

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/watcher/FlinkK8sChangeEventListener.java
Patch:
@@ -102,7 +102,7 @@ public void subscribeJobStatusChange(FlinkJobStatusChangeEvent event) {
     }
     // update application record
     setByJobStatusCV(app, jobStatus);
-    applicationInfoService.persistMetrics(app);
+    applicationManageService.persistMetrics(app);
 
     // email alerts when necessary
     FlinkAppStateEnum state = app.getStateEnum();
@@ -148,7 +148,7 @@ public void subscribeMetricsChange(FlinkClusterMetricChangeEvent event) {
     app.setTotalSlot(metrics.totalSlot());
     app.setAvailableSlot(metrics.availableSlot());
 
-    applicationInfoService.persistMetrics(app);
+    applicationManageService.persistMetrics(app);
   }
 
   @SuppressWarnings("UnstableApiUsage")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/security/impl/AuthenticatorImpl.java
Patch:
@@ -76,8 +76,8 @@ private User passwordAuthenticate(String username, String password) {
   }
 
   private User ldapAuthenticate(String username, String password) throws Exception {
-    String ldapEmail = ldapService.ldapLogin(username, password);
-    if (StringUtils.isBlank(ldapEmail)) {
+    boolean ldapLoginStatus = ldapService.ldapLogin(username, password);
+    if (!ldapLoginStatus) {
       return null;
     }
     // check if user exist

File: streampark-tests/streampark-testcontainer/src/main/java/org/apache/streampark/testcontainer/flink/FlinkContainer.java
Patch:
@@ -37,9 +37,8 @@
  */
 class FlinkContainer extends GenericContainer<FlinkContainer> {
 
-  public static final AtomicInteger TM_INDEX_SUFFIX = new AtomicInteger(0);
-
-  public static final String FLINK_PROPS_KEY = "FLINK_PROPERTIES";
+  private static final String FLINK_PROPS_KEY = "FLINK_PROPERTIES";
+  private static final AtomicInteger TM_INDEX_SUFFIX = new AtomicInteger(0);
 
   private final @Nonnull FlinkComponent component;
 

File: streampark-tests/streampark-testcontainer/src/main/java/org/apache/streampark/testcontainer/hadoop/HadoopContainer.java
Patch:
@@ -37,7 +37,7 @@ public class HadoopContainer extends GenericContainer<HadoopContainer> {
   public static final Logger LOG = LoggerFactory.getLogger(HadoopContainer.class);
 
   // Hadoop version is 2.7.0
-  public static final DockerImageName DOCKER_IMAGE_NAME =
+  private static final DockerImageName DOCKER_IMAGE_NAME =
       DockerImageName.parse("sequenceiq/hadoop-docker:latest");
 
   public static final Map<Integer, Integer> MAPPED_PORTS =

File: streampark-tests/streampark-testcontainer/src/main/java/org/apache/streampark/testcontainer/flink/FlinkComponent.java
Patch:
@@ -19,8 +19,10 @@
 
 import javax.annotation.Nonnull;
 
+/** The enum is used to represent the type of the flink component. */
 enum FlinkComponent {
   JOBMANAGER("jobmanager"),
+
   TASKMANAGER("taskmanager");
 
   private final String name;

File: streampark-tests/streampark-testcontainer/src/main/java/org/apache/streampark/testcontainer/flink/FlinkContainer.java
Patch:
@@ -55,6 +55,7 @@ class FlinkContainer extends GenericContainer<FlinkContainer> {
     Optional.ofNullable(slf4jLogConsumer).ifPresent(this::withLogConsumer);
   }
 
+  @Nonnull
   protected String getFlinkContainerName() {
     if (component == JOBMANAGER) {
       return JOBMANAGER.getName();

File: streampark-tests/streampark-testcontainer/src/main/java/org/apache/streampark/testcontainer/flink/FlinkStandaloneSessionCluster.java
Patch:
@@ -27,6 +27,7 @@
 import org.testcontainers.lifecycle.Startable;
 import org.testcontainers.utility.DockerImageName;
 
+import javax.annotation.Nonnull;
 import javax.annotation.Nullable;
 
 import java.time.Duration;
@@ -93,6 +94,7 @@ private FlinkStandaloneSessionCluster(
     }
   }
 
+  @Nonnull
   public String getFlinkJobManagerUrl() {
     return String.format(
         "http://%s:%s", jobManagerContainer.getHost(), jobManagerContainer.getMappedPort(WEB_PORT));

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -438,7 +438,7 @@ private DeployResponse deployInternal(FlinkCluster flinkCluster)
             flinkCluster.getClusterId(),
             flinkCluster.getId(),
             getKubernetesDeployDesc(flinkCluster, "start"));
-    log.info("Deploy cluster request " + deployRequest);
+    log.info("Deploy cluster request {}", deployRequest);
     Future<DeployResponse> future = executorService.submit(() -> FlinkClient.deploy(deployRequest));
     return future.get(60, TimeUnit.SECONDS);
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/interceptor/UploadFileTypeInterceptor.java
Patch:
@@ -75,8 +75,8 @@ private boolean isPythonFileType(String contentType, InputStream input) {
     try {
       Metadata metadata = new Metadata();
       AutoDetectParser parser = new AutoDetectParser();
-      parser.parse(stream, new DefaultHandler(), metadata, new ParseContext());
-      String mimeType = metadata.get(HttpHeaders.CONTENT_TYPE);  
+      parser.parse(input, new DefaultHandler(), metadata, new ParseContext());
+      String mimeType = metadata.get(HttpHeaders.CONTENT_TYPE);
       return contentType.contains("text/x-python")
           && MediaType.TEXT_PLAIN.toString().equals(mimeType);
     } catch (Exception e) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/WebMvcConfig.java
Patch:
@@ -79,6 +79,8 @@ public Module jacksonModule() {
 
   @Override
   public void addInterceptors(InterceptorRegistry registry) {
-    registry.addInterceptor(uploadFileTypeInterceptor).addPathPatterns("/flink/app/upload");
+    registry
+        .addInterceptor(uploadFileTypeInterceptor)
+        .addPathPatterns("/flink/app/upload", "/resource/upload");
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkSqlController.java
Patch:
@@ -68,7 +68,7 @@ public RestResponse verify(String sql, Long versionId, Long teamId) {
           RestResponse.success()
               .data(false)
               .message(exception)
-              .put("type", flinkSqlValidationResult.failedType().getValue())
+              .put("type", flinkSqlValidationResult.failedType().getFailedType())
               .put("start", flinkSqlValidationResult.lineStart())
               .put("end", flinkSqlValidationResult.lineEnd());
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkClusterWatcher.java
Patch:
@@ -99,7 +99,7 @@ private void init() {
     List<FlinkCluster> flinkClusters =
         flinkClusterService.list(
             new LambdaQueryWrapper<FlinkCluster>()
-                .eq(FlinkCluster::getClusterState, ClusterState.RUNNING.getValue())
+                .eq(FlinkCluster::getClusterState, ClusterState.RUNNING.getState())
                 // excluding flink clusters on kubernetes
                 .notIn(FlinkCluster::getExecutionMode, ExecutionMode.getKubernetesMode()));
     flinkClusters.forEach(cluster -> WATCHER_CLUSTERS.put(cluster.getId(), cluster));
@@ -138,7 +138,7 @@ private void alert(FlinkCluster cluster, ClusterState state) {
       cluster.setAffectedJobs(
           applicationInfoService.countAffectedByClusterId(
               cluster.getId(), InternalConfigHolder.get(CommonConfig.SPRING_PROFILES_ACTIVE())));
-      cluster.setClusterState(state.getValue());
+      cluster.setClusterState(state.getState());
       cluster.setEndTime(new Date());
       alertService.alert(cluster.getAlertId(), AlertTemplate.of(cluster, state));
     }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/SavePointServiceTest.java
Patch:
@@ -97,14 +97,14 @@ void testGetSavepointFromAppCfgIfStreamParkOrSQLJob() {
     app.setAppType(ApplicationType.APACHE_FLINK.getType());
     assertThat(savePointServiceImpl.getSavepointFromAppCfgIfStreamParkOrSQLJob(app)).isNull();
     app.setAppType(ApplicationType.STREAMPARK_FLINK.getType());
-    app.setJobType(DevelopmentMode.CUSTOM_CODE.getValue());
+    app.setJobType(DevelopmentMode.CUSTOM_CODE.getMode());
     assertThat(savePointServiceImpl.getSavepointFromAppCfgIfStreamParkOrSQLJob(app)).isNull();
 
     // Test for (StreamPark job Or FlinkSQL job) without application config.
     app.setAppType(ApplicationType.STREAMPARK_FLINK.getType());
     assertThat(savePointServiceImpl.getSavepointFromAppCfgIfStreamParkOrSQLJob(app)).isNull();
     app.setAppType(ApplicationType.STREAMPARK_FLINK.getType());
-    app.setJobType(DevelopmentMode.CUSTOM_CODE.getValue());
+    app.setJobType(DevelopmentMode.CUSTOM_CODE.getMode());
     assertThat(savePointServiceImpl.getSavepointFromAppCfgIfStreamParkOrSQLJob(app)).isNull();
 
     // Test for (StreamPark job Or FlinkSQL job) with application config just disabled checkpoint.

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/exception/AlertException.java
Patch:
@@ -17,15 +17,15 @@
 
 package org.apache.streampark.console.base.exception;
 
-import org.apache.streampark.common.util.Utils;
+import org.apache.streampark.common.util.ExceptionUtils;
 
 public class AlertException extends ApiAlertException {
   public AlertException(String message) {
     super(message);
   }
 
   public AlertException(Throwable cause) {
-    super(Utils.stringifyException(cause));
+    super(ExceptionUtils.stringifyException(cause));
   }
 
   public AlertException(String message, Throwable cause) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/exception/ApiDetailException.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.base.exception;
 
-import org.apache.streampark.common.util.Utils;
+import org.apache.streampark.common.util.ExceptionUtils;
 import org.apache.streampark.console.base.domain.ResponseCode;
 
 /**
@@ -37,11 +37,11 @@ public ApiDetailException(String message) {
   }
 
   public ApiDetailException(Throwable cause) {
-    super(Utils.stringifyException(cause), ResponseCode.CODE_FAIL_DETAIL);
+    super(ExceptionUtils.stringifyException(cause), ResponseCode.CODE_FAIL_DETAIL);
   }
 
   public ApiDetailException(String message, Throwable cause) {
-    super(message + Utils.stringifyException(cause), ResponseCode.CODE_FAIL_DETAIL);
+    super(message + ExceptionUtils.stringifyException(cause), ResponseCode.CODE_FAIL_DETAIL);
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationActionServiceImpl.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.streampark.common.fs.FsOperator;
 import org.apache.streampark.common.util.CompletableFutureUtils;
 import org.apache.streampark.common.util.DeflaterUtils;
+import org.apache.streampark.common.util.ExceptionUtils;
 import org.apache.streampark.common.util.HadoopUtils;
 import org.apache.streampark.common.util.PropertiesUtils;
 import org.apache.streampark.common.util.ThreadUtils;
@@ -360,7 +361,7 @@ public void cancel(Application appParam) throws Exception {
                   FlinkAppHttpWatcher.unWatching(application.getId());
                 }
 
-                String exception = Utils.stringifyException(e);
+                String exception = ExceptionUtils.stringifyException(e);
                 applicationLog.setException(exception);
                 applicationLog.setSuccess(false);
               }
@@ -520,7 +521,7 @@ public void start(Application appParam, boolean auto) throws Exception {
               if (e.getCause() instanceof CancellationException) {
                 updateToStopped(application);
               } else {
-                String exception = Utils.stringifyException(e);
+                String exception = ExceptionUtils.stringifyException(e);
                 applicationLog.setException(exception);
                 applicationLog.setSuccess(false);
                 Application app = getById(appParam.getId());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationInfoServiceImpl.java
Patch:
@@ -21,6 +21,7 @@
 import org.apache.streampark.common.conf.Workspace;
 import org.apache.streampark.common.enums.ExecutionMode;
 import org.apache.streampark.common.fs.LfsOperator;
+import org.apache.streampark.common.util.ExceptionUtils;
 import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.common.util.YarnUtils;
 import org.apache.streampark.console.base.exception.ApiAlertException;
@@ -212,7 +213,7 @@ public boolean checkEnv(Application appParam) throws ApplicationException {
       }
       return true;
     } catch (Exception e) {
-      log.error(Utils.stringifyException(e));
+      log.error(ExceptionUtils.stringifyException(e));
       throw new ApiDetailException(e);
     }
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.streampark.console.core.service.impl;
 
 import org.apache.streampark.common.util.DeflaterUtils;
+import org.apache.streampark.common.util.ExceptionUtils;
 import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.domain.Constant;
 import org.apache.streampark.console.base.domain.RestRequest;
@@ -202,7 +203,8 @@ public FlinkSqlValidationResult verifySql(String sql, Long versionId) {
             }
             return FlinkShimsProxy.getObject(this.getClass().getClassLoader(), result);
           } catch (Throwable e) {
-            log.error("verifySql invocationTargetException: {}", Utils.stringifyException(e));
+            log.error(
+                "verifySql invocationTargetException: {}", ExceptionUtils.stringifyException(e));
           }
           return null;
         });

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SavePointServiceImpl.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.streampark.common.enums.ExecutionMode;
 import org.apache.streampark.common.util.CompletableFutureUtils;
+import org.apache.streampark.common.util.ExceptionUtils;
 import org.apache.streampark.common.util.ThreadUtils;
 import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.domain.Constant;
@@ -254,7 +255,7 @@ private void handleSavepointResponseFuture(
             },
             e -> {
               log.error("Trigger savepoint for flink job failed.", e);
-              String exception = Utils.stringifyException(e);
+              String exception = ExceptionUtils.stringifyException(e);
               applicationLog.setException(exception);
               if (!(e instanceof TimeoutException)) {
                 applicationLog.setSuccess(false);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -569,7 +569,7 @@ public void updateHotParams(Application appParam) {
   }
 
   private boolean needFillYarnQueueLabel(ExecutionMode mode) {
-    return ExecutionMode.YARN_PER_JOB.equals(mode) || ExecutionMode.YARN_APPLICATION.equals(mode);
+    return ExecutionMode.YARN_PER_JOB == mode || ExecutionMode.YARN_APPLICATION == mode;
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/FlinkCluster.java
Patch:
@@ -136,7 +136,7 @@ public Map<String, Object> getOptionMap() {
       return Collections.emptyMap();
     }
     Map<String, Object> map = JacksonUtils.read(this.options, Map.class);
-    if (ExecutionMode.YARN_SESSION.equals(getExecutionModeEnum())) {
+    if (ExecutionMode.YARN_SESSION == getExecutionModeEnum()) {
       map.put(ConfigConst.KEY_YARN_APP_NAME(), this.clusterName);
       map.putAll(YarnQueueLabelExpression.getQueueLabelMap(yarnQueue));
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/FlinkAppState.java
Patch:
@@ -153,7 +153,7 @@ public static boolean isLost(Integer appState) {
   public static class Bridge {
     /** covert from org.apache.streampark.flink.k8s.enums.FlinkJobState */
     public static FlinkAppState fromK8sFlinkJobState(Enumeration.Value flinkJobState) {
-      if (FlinkJobState.K8S_INITIALIZING().equals(flinkJobState)) {
+      if (FlinkJobState.K8S_INITIALIZING() == flinkJobState) {
         return INITIALIZING;
       } else {
         return of(flinkJobState.toString());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/GitCredential.java
Patch:
@@ -34,7 +34,7 @@ public static GitCredential of(Integer value) {
   }
 
   public static boolean isSSH(Integer gitCredential) {
-    return GitCredential.SSH.equals(GitCredential.of(gitCredential));
+    return GitCredential.SSH == GitCredential.of(gitCredential);
   }
 
   public Integer getValue() {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/runner/EnvInitializer.java
Patch:
@@ -136,7 +136,7 @@ public synchronized void storageInitialize(StorageType storageType) {
     Workspace workspace = Workspace.of(storageType);
 
     // 1. prepare workspace dir
-    if (storageType.equals(LFS)) {
+    if (LFS == storageType) {
       fsOperator.mkdirsIfNotExists(Workspace.APP_LOCAL_DIST());
     }
     Arrays.asList(

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationInfoServiceImpl.java
Patch:
@@ -202,8 +202,8 @@ public boolean checkEnv(Application appParam) throws ApplicationException {
       envInitializer.checkFlinkEnv(application.getStorageType(), flinkEnv);
       envInitializer.storageInitialize(application.getStorageType());
 
-      if (ExecutionMode.YARN_SESSION.equals(application.getExecutionModeEnum())
-          || ExecutionMode.REMOTE.equals(application.getExecutionModeEnum())) {
+      if (ExecutionMode.YARN_SESSION == application.getExecutionModeEnum()
+          || ExecutionMode.REMOTE == application.getExecutionModeEnum()) {
         FlinkCluster flinkCluster = flinkClusterService.getById(application.getFlinkClusterId());
         boolean conned = flinkClusterWatcher.verifyClusterConnection(flinkCluster);
         if (!conned) {
@@ -247,7 +247,7 @@ public boolean existsRunningByClusterId(Long clusterId) {
             .anyMatch(
                 application ->
                     clusterId.equals(application.getFlinkClusterId())
-                        && FlinkAppState.RUNNING.equals(application.getStateEnum()));
+                        && FlinkAppState.RUNNING == application.getStateEnum());
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationManageServiceImpl.java
Patch:
@@ -497,8 +497,8 @@ public boolean update(Application appParam) {
     // 4) yarn application mode change
     if (!application.getBuild()) {
       if (!application.getExecutionMode().equals(appParam.getExecutionMode())) {
-        if (appParam.getExecutionModeEnum().equals(ExecutionMode.YARN_APPLICATION)
-            || application.getExecutionModeEnum().equals(ExecutionMode.YARN_APPLICATION)) {
+        if (ExecutionMode.YARN_APPLICATION == appParam.getExecutionModeEnum()
+            || ExecutionMode.YARN_APPLICATION == application.getExecutionModeEnum()) {
           application.setBuild(true);
         }
       }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -443,8 +443,8 @@ private BuildPipeline createPipelineInstance(@Nonnull Application app) {
       case YARN_APPLICATION:
         String yarnProvidedPath = app.getAppLib();
         String localWorkspace = app.getLocalAppHome().concat("/lib");
-        if (app.getDevelopmentMode().equals(DevelopmentMode.CUSTOM_CODE)
-            && app.getApplicationType().equals(ApplicationType.APACHE_FLINK)) {
+        if (DevelopmentMode.CUSTOM_CODE == app.getDevelopmentMode()
+            && ApplicationType.APACHE_FLINK == app.getApplicationType()) {
           yarnProvidedPath = app.getAppHome();
           localWorkspace = app.getLocalAppHome();
         }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationConfigServiceImpl.java
Patch:
@@ -74,7 +74,7 @@ public synchronized void create(Application application, Boolean latest) {
 
     if (application.getFormat() != null) {
       ConfigFileType fileType = ConfigFileType.of(application.getFormat());
-      if (fileType == null || ConfigFileType.UNKNOWN.equals(fileType)) {
+      if (fileType == null || ConfigFileType.UNKNOWN == fileType) {
         throw new ApiAlertException(
             "application' config error. must be (.properties|.yaml|.yml |.conf)");
       }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -141,7 +141,7 @@ public boolean update(Project projectParam) {
     }
     if (projectParam.getBuildState() != null) {
       project.setBuildState(projectParam.getBuildState());
-      if (BuildState.of(projectParam.getBuildState()).equals(BuildState.NEED_REBUILD)) {
+      if (BuildState.NEED_REBUILD == BuildState.of(projectParam.getBuildState())) {
         List<Application> applications = getApplications(project);
         // Update deployment status
         applications.forEach(
@@ -235,7 +235,7 @@ public List<String> modules(Long id) {
     Project project = getById(id);
     Utils.notNull(project);
 
-    if (!BuildState.SUCCESSFUL.equals(BuildState.of(project.getBuildState()))
+    if (BuildState.SUCCESSFUL != BuildState.of(project.getBuildState())
         || !project.getDistHome().exists()) {
       return Collections.emptyList();
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ResourceServiceImpl.java
Patch:
@@ -304,7 +304,7 @@ public RestResponse checkResource(Resource resourceParam) throws JsonProcessingE
         FlinkConnector connectorResource;
 
         ApiAlertException.throwIfFalse(
-            ResourceType.CONNECTOR.equals(resourceParam.getResourceType()),
+            ResourceType.CONNECTOR == resourceParam.getResourceType(),
             "getConnectorId method error, resource not flink connector.");
 
         List<File> jars;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SavePointServiceImpl.java
Patch:
@@ -306,7 +306,7 @@ private String getClusterId(Application application, FlinkCluster cluster) {
     if (ExecutionMode.isKubernetesMode(application.getExecutionMode())) {
       return application.getClusterId();
     } else if (ExecutionMode.isYarnMode(application.getExecutionMode())) {
-      if (ExecutionMode.YARN_SESSION.equals(application.getExecutionModeEnum())) {
+      if (ExecutionMode.YARN_SESSION == application.getExecutionModeEnum()) {
         Utils.notNull(
             cluster,
             String.format(
@@ -445,8 +445,7 @@ private void expire(SavePoint entity) {
     int cpThreshold =
         tryGetChkNumRetainedFromDynamicProps(application.getDynamicProperties())
             .orElse(getChkNumRetainedFromFlinkEnv(flinkEnv, application));
-    cpThreshold =
-        CHECKPOINT.equals(CheckPointType.of(entity.getType())) ? cpThreshold - 1 : cpThreshold;
+    cpThreshold = CHECKPOINT == CheckPointType.of(entity.getType()) ? cpThreshold - 1 : cpThreshold;
 
     if (cpThreshold == 0) {
       LambdaQueryWrapper<SavePoint> queryWrapper =

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkK8sWatcherWrapper.java
Patch:
@@ -127,14 +127,14 @@ public static class Bridge {
     // covert Application to TrackId
     public static TrackId toTrackId(@Nonnull Application app) {
       Enumeration.Value mode = FlinkK8sExecuteMode.of(app.getExecutionModeEnum());
-      if (FlinkK8sExecuteMode.APPLICATION().equals(mode)) {
+      if (FlinkK8sExecuteMode.APPLICATION() == mode) {
         return TrackId.onApplication(
             app.getK8sNamespace(),
             app.getClusterId(),
             app.getId(),
             app.getJobId(),
             app.getTeamId().toString());
-      } else if (FlinkK8sExecuteMode.SESSION().equals(mode)) {
+      } else if (FlinkK8sExecuteMode.SESSION() == mode) {
         return TrackId.onSession(
             app.getK8sNamespace(),
             app.getClusterId(),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/MenuServiceImpl.java
Patch:
@@ -66,7 +66,7 @@ public List<String> findUserPermissions(Long userId, Long teamId) {
                     new IllegalArgumentException(
                         String.format("The userId [%s] not found", userId)));
     // Admin has the permission for all menus.
-    if (UserType.ADMIN.equals(user.getUserType())) {
+    if (UserType.ADMIN == user.getUserType()) {
       return this.list().stream().map(Menu::getPerms).collect(Collectors.toList());
     }
     return this.baseMapper.findUserPermissions(userId, teamId);
@@ -81,7 +81,7 @@ public List<Menu> findUserMenus(Long userId, Long teamId) {
                     new IllegalArgumentException(
                         String.format("The userId:[%s] not found", userId)));
     // Admin has the permission for all menus.
-    if (UserType.ADMIN.equals(user.getUserType())) {
+    if (UserType.ADMIN == user.getUserType()) {
       LambdaQueryWrapper<Menu> queryWrapper =
           new LambdaQueryWrapper<Menu>().eq(Menu::getType, "0").orderByAsc(Menu::getOrderNum);
       return this.list(queryWrapper);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/TeamServiceImpl.java
Patch:
@@ -143,7 +143,7 @@ public List<Team> findUserTeams(Long userId) {
             .orElseThrow(
                 () -> new ApiAlertException(String.format("The userId [%s] not found.", userId)));
     // Admin has the permission for all teams.
-    if (UserType.ADMIN.equals(user.getUserType())) {
+    if (UserType.ADMIN == user.getUserType()) {
       return this.list();
     }
     return baseMapper.findUserTeams(userId);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/runner/EnvInitializer.java
Patch:
@@ -55,7 +55,7 @@
 
 import static org.apache.streampark.common.enums.StorageType.LFS;
 
-@Order
+@Order(1)
 @Slf4j
 @Component
 public class EnvInitializer implements ApplicationRunner {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/bean/AlertTemplate.java
Patch:
@@ -89,7 +89,7 @@ public static AlertTemplate of(FlinkCluster cluster, ClusterState clusterState)
     return new AlertTemplateBuilder()
         .setDuration(cluster.getStartTime(), cluster.getEndTime())
         .setJobName(cluster.getClusterName())
-        .setLink(ExecutionMode.YARN_SESSION, cluster.getClusterId())
+        .setLink(cluster.getExecutionModeEnum(), cluster.getClusterId())
         .setStartTime(cluster.getStartTime())
         .setEndTime(cluster.getEndTime())
         .setType(3)

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/FlinkAppState.java
Patch:
@@ -139,7 +139,7 @@ public static boolean isEndState(Integer appState) {
 
   /**
    * Type conversion bridging Deprecated, see {@link
-   * org.apache.streampark.console.core.utils.FlinkAppStateConverter}
+   * org.apache.streampark.console.core.utils.FlinkK8sDataTypeConverter}
    */
   @Deprecated
   public static class Bridge {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/application/impl/ApplicationActionServiceImpl.java
Patch:
@@ -419,6 +419,7 @@ public void start(Application appParam, boolean auto) throws Exception {
     KubernetesSubmitParam kubernetesSubmitParam =
         KubernetesSubmitParam.apply(
             application.getClusterId(),
+            application.getK8sName(),
             application.getK8sNamespace(),
             application.getFlinkImage(),
             application.getK8sRestExposedTypeEnum());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkClusterWatcher.java
Patch:
@@ -100,6 +100,7 @@ private void init() {
         flinkClusterService.list(
             new LambdaQueryWrapper<FlinkCluster>()
                 .eq(FlinkCluster::getClusterState, ClusterState.RUNNING.getValue())
+                // excluding flink clusters on kubernetes
                 .notIn(FlinkCluster::getExecutionMode, ExecutionMode.getKubernetesMode()));
     flinkClusters.forEach(cluster -> WATCHER_CLUSTERS.put(cluster.getId(), cluster));
   }
@@ -264,7 +265,8 @@ private ClusterState getStateFromYarnRestApi(FlinkCluster flinkCluster) {
    * @param flinkCluster
    */
   public static void addWatching(FlinkCluster flinkCluster) {
-    if (!WATCHER_CLUSTERS.containsKey(flinkCluster.getId())) {
+    if (!ExecutionMode.isKubernetesMode(flinkCluster.getExecutionModeEnum())
+        && !WATCHER_CLUSTERS.containsKey(flinkCluster.getId())) {
       log.info("add the cluster with id:{} to watcher cluster cache", flinkCluster.getId());
       WATCHER_CLUSTERS.put(flinkCluster.getId(), flinkCluster);
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkK8sWatcherWrapper.java
Patch:
@@ -89,8 +89,6 @@ private void initFlinkK8sWatcher(@Nonnull FlinkK8sWatcher trackMonitor) {
       // recovery tracking list
       List<TrackId> k8sApp = getK8sWatchingApps();
       k8sApp.forEach(trackMonitor::doWatching);
-    } else {
-      // TODO [flink-k8s-v2] Recovery tracking list and invoke FlinkK8sObserver.track()
     }
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/runner/EnvInitializer.java
Patch:
@@ -32,6 +32,7 @@
 import org.apache.streampark.console.core.service.SettingService;
 import org.apache.streampark.flink.kubernetes.v2.fs.EmbeddedFileServer;
 
+import lombok.SneakyThrows;
 import lombok.extern.slf4j.Slf4j;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.boot.ApplicationArguments;
@@ -72,6 +73,7 @@ public class EnvInitializer implements ApplicationRunner {
           "^streampark-flink-shims_flink-(1.1[2-7])_(2.12)-(.*).jar$",
           Pattern.CASE_INSENSITIVE | Pattern.DOTALL);
 
+  @SneakyThrows
   @Override
   public void run(ApplicationArguments args) throws Exception {
     Optional<String> profile =

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/OpenapiConfig.java
Patch:
@@ -83,5 +83,4 @@ public GroupedOpenApi publicApiV1() {
   public GroupedOpenApi publicApiV2() {
     return GroupedOpenApi.builder().group("v2").pathsToMatch("/v2/**").build();
   }
-
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/WebMvcConfig.java
Patch:
@@ -81,5 +81,4 @@ public Module jacksonModule() {
   public void addInterceptors(InterceptorRegistry registry) {
     registry.addInterceptor(uploadFileTypeInterceptor).addPathPatterns("/flink/app/upload");
   }
-
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/AccessTokenState.java
Patch:
@@ -17,9 +17,7 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
-
-public enum AccessTokenState implements Serializable {
+public enum AccessTokenState {
 
   /** not added token */
   NULL(0),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/AppExistsState.java
Patch:
@@ -17,9 +17,7 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
-
-public enum AppExistsState implements Serializable {
+public enum AppExistsState {
 
   /** no exists */
   NO(0),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/BuildState.java
Patch:
@@ -17,10 +17,9 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
-public enum BuildState implements Serializable {
+public enum BuildState {
 
   /** has changed, need rebuild */
   NEED_REBUILD(-2),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/CandidateType.java
Patch:
@@ -17,10 +17,9 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
-public enum CandidateType implements Serializable {
+public enum CandidateType {
 
   /** non candidate */
   NONE(0),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/ChangeTypeEnum.java
Patch:
@@ -19,12 +19,11 @@
 
 import lombok.Getter;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
 /** This is an enumeration representing the types of changes that can occur. */
 @Getter
-public enum ChangeTypeEnum implements Serializable {
+public enum ChangeTypeEnum {
 
   /** Represents no change. */
   NONE(0, "[NONE], nothing to changed"),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/CheckPointStatus.java
Patch:
@@ -17,10 +17,9 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
-public enum CheckPointStatus implements Serializable {
+public enum CheckPointStatus {
   /** IN_PROGRESS */
   IN_PROGRESS(1),
   /** COMPLETED */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/CheckPointType.java
Patch:
@@ -17,10 +17,9 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
-public enum CheckPointType implements Serializable {
+public enum CheckPointType {
   /** CHECKPOINT */
   CHECKPOINT(1),
   /** SAVEPOINT */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/ConfigFileType.java
Patch:
@@ -19,12 +19,11 @@
 
 import lombok.Getter;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
 /** configFile Type enum */
 @Getter
-public enum ConfigFileType implements Serializable {
+public enum ConfigFileType {
   YAML(1, "yaml"),
 
   PROPERTIES(2, "prop"),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/EffectiveType.java
Patch:
@@ -19,10 +19,8 @@
 
 import lombok.Getter;
 
-import java.io.Serializable;
-
 @Getter
-public enum EffectiveType implements Serializable {
+public enum EffectiveType {
   /** config */
   CONFIG(1),
   /** FLINKSQL */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/FlinkAppState.java
Patch:
@@ -21,12 +21,10 @@
 
 import lombok.Getter;
 
-import java.io.Serializable;
-
 import scala.Enumeration;
 
 @Getter
-public enum FlinkAppState implements Serializable {
+public enum FlinkAppState {
 
   /** Added new job to database. */
   ADDED(0),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/GitAuthorizedError.java
Patch:
@@ -17,9 +17,7 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
-
-public enum GitAuthorizedError implements Serializable {
+public enum GitAuthorizedError {
 
   /** Success. */
   SUCCESS(0),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/NoticeType.java
Patch:
@@ -17,10 +17,9 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
-public enum NoticeType implements Serializable {
+public enum NoticeType {
   /** exception */
   EXCEPTION(1),
   /** message */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/Operation.java
Patch:
@@ -19,11 +19,10 @@
 
 import lombok.Getter;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
 @Getter
-public enum Operation implements Serializable {
+public enum Operation {
   RELEASE(0),
   START(1),
   SAVEPOINT(2),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/OptionState.java
Patch:
@@ -19,11 +19,10 @@
 
 import lombok.Getter;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
 @Getter
-public enum OptionState implements Serializable {
+public enum OptionState {
 
   /** Application which is currently action: none. */
   NONE(0),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/PlaceholderType.java
Patch:
@@ -17,10 +17,8 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
-
 /** configFile Type enum */
-public enum PlaceholderType implements Serializable {
+public enum PlaceholderType {
   JOB_ID("job_id"),
 
   JOB_NAME("job_name"),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/ReleaseState.java
Patch:
@@ -17,10 +17,9 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
-public enum ReleaseState implements Serializable {
+public enum ReleaseState {
 
   /** release failed */
   FAILED(-1),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/ResourceFrom.java
Patch:
@@ -19,11 +19,10 @@
 
 import lombok.Getter;
 
-import java.io.Serializable;
 import java.util.Arrays;
 
 @Getter
-public enum ResourceFrom implements Serializable {
+public enum ResourceFrom {
 
   /** cicd(build from cvs) */
   CICD(1),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/StopFrom.java
Patch:
@@ -17,9 +17,7 @@
 
 package org.apache.streampark.console.core.enums;
 
-import java.io.Serializable;
-
-public enum StopFrom implements Serializable {
+public enum StopFrom {
   /** None */
   NONE,
   /** StreamPark */

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/base/util/DependencyUtilsTest.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.flink.table.factories.Factory;
 
 import lombok.extern.slf4j.Slf4j;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 
 import java.io.File;
@@ -49,6 +50,7 @@
 @Slf4j
 class DependencyUtilsTest {
 
+  @Disabled("Disabled due to unstable performance.")
   @Test
   public void resolveFlinkConnector() throws Exception {
 

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/ApplicationManageServiceITest.java
Patch:
@@ -36,6 +36,7 @@
 import org.junit.jupiter.api.AfterAll;
 import org.junit.jupiter.api.AfterEach;
 import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.Timeout;
 import org.springframework.beans.factory.annotation.Autowired;
@@ -51,6 +52,7 @@
  * Integration test for {@link
  * org.apache.streampark.console.core.service.application.ApplicationManageService}.
  */
+@Disabled("Disabled due to unstable performance.")
 class ApplicationManageServiceITest extends SpringIntegrationTestBase {
 
   static FlinkStandaloneSessionCluster cluster =

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -424,7 +424,7 @@ private BuildPipeline createPipelineInstance(@Nonnull Application app) {
     FlinkEnv flinkEnv = flinkEnvService.getByIdOrDefault(app.getVersionId());
     String flinkUserJar = retrieveFlinkUserJar(flinkEnv, app);
 
-    if (!new File(flinkUserJar).exists()) {
+    if (!FileUtils.exists(flinkUserJar)) {
       Resource resource = resourceService.findByResourceName(app.getTeamId(), app.getJar());
       if (resource != null && StringUtils.isNotBlank(resource.getFilePath())) {
         flinkUserJar = resource.getFilePath();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -21,14 +21,14 @@
 import org.apache.streampark.common.conf.InternalConfigHolder;
 import org.apache.streampark.common.conf.Workspace;
 import org.apache.streampark.common.util.CompletableFutureUtils;
+import org.apache.streampark.common.util.FileUtils;
 import org.apache.streampark.common.util.ThreadUtils;
 import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.domain.ResponseCode;
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.domain.RestResponse;
 import org.apache.streampark.console.base.exception.ApiAlertException;
 import org.apache.streampark.console.base.mybatis.pager.MybatisPager;
-import org.apache.streampark.console.base.util.FileUtils;
 import org.apache.streampark.console.base.util.GZipUtils;
 import org.apache.streampark.console.core.entity.Application;
 import org.apache.streampark.console.core.entity.Project;

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/base/util/FileUtilsTest.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.streampark.console.base.util;
 
+import org.apache.streampark.common.util.FileUtils;
+
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
 import org.junit.jupiter.api.io.TempDir;

File: streampark-flink/streampark-flink-shims/streampark-flink-shims-base/src/main/java/org/apache/streampark/flink/core/StreamEnvConfigFunction.java
Patch:
@@ -23,7 +23,8 @@
 @FunctionalInterface
 public interface StreamEnvConfigFunction {
   /**
-   * 用于初始化StreamExecutionEnvironment的时候,用于可以实现该函数,自定义要设置的参数...
+   * When used to initialize StreamExecutionEnvironment, it can be used to implement this function
+   * and customize the parameters to be set...
    *
    * @param environment
    * @param parameterTool

File: streampark-flink/streampark-flink-shims/streampark-flink-shims-base/src/main/java/org/apache/streampark/flink/core/TableEnvConfigFunction.java
Patch:
@@ -23,7 +23,8 @@
 @FunctionalInterface
 public interface TableEnvConfigFunction {
   /**
-   * 用于初始化TableEnvironment的时候,用于可以实现该函数,自定义要设置的参数...
+   * When used to initialize the TableEnvironment, it can be used to implement this function and
+   * customize the parameters to be set...
    *
    * @param tableConfig
    * @param parameterTool

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/ApplicationServiceITest.java
Patch:
@@ -147,7 +147,7 @@ void testStartAppOnRemoteSessionMode() throws Exception {
               return true;
             });
 
-    assertThat(completableFuture.get(WATCHING_INTERVAL.toMillis() * 4, TimeUnit.MILLISECONDS))
+    assertThat(completableFuture.get(WATCHING_INTERVAL.toMillis() * 24, TimeUnit.MILLISECONDS))
         .isEqualTo(true);
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/util/FileUtils.java
Patch:
@@ -24,6 +24,8 @@
 /** The file utils. */
 public class FileUtils {
 
+  private FileUtils() {}
+
   /**
    * Read the end of the file.
    *

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/util/FreemarkerUtils.java
Patch:
@@ -40,6 +40,8 @@ public class FreemarkerUtils {
     CONFIGURATION.setDefaultEncoding("UTF-8");
   }
 
+  private FreemarkerUtils() {}
+
   public static Template loadTemplateFile(String fileName) throws ExceptionInInitializerError {
     try {
       return CONFIGURATION.getTemplate(fileName);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/util/GitUtils.java
Patch:
@@ -46,6 +46,8 @@
 /** */
 public class GitUtils {
 
+  private GitUtils() {}
+
   public static Git clone(Project project) throws GitAPIException {
     CloneCommand cloneCommand =
         Git.cloneRepository().setURI(project.getUrl()).setDirectory(project.getAppSource());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -230,6 +230,8 @@ public class Application implements Serializable {
   private transient String savePoint;
   private transient Boolean savePointed = false;
   private transient Boolean drain = false;
+  private transient Boolean nativeFormat = false;
+  private transient Long savePointTimeout = 60L;
   private transient Boolean allowNonRestored = false;
   private transient Integer restoreMode;
   private transient String socketId;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/SavePointService.java
Patch:
@@ -33,7 +33,7 @@ public interface SavePointService extends IService<SavePoint> {
 
   SavePoint getLatest(Long id);
 
-  void trigger(Long appId, @Nullable String savepointPath);
+  void trigger(Long appId, @Nullable String savepointPath, @Nullable Boolean nativeFormat);
 
   Boolean delete(Long id, Application application) throws InternalException;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1299,6 +1299,7 @@ public void cancel(Application appParam) throws Exception {
             appParam.getSavePointed(),
             appParam.getDrain(),
             customSavepoint,
+            appParam.getNativeFormat(),
             application.getK8sNamespace());
 
     final Date triggerTime = new Date();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/AccessTokenController.java
Patch:
@@ -186,6 +186,7 @@ public RestResponse copyRestApiCurl(
               .addFormData("id", appId)
               .addFormData("savePointed", "false")
               .addFormData("drain", "false")
+              .addFormData("nativeFormat", "false")
               .addFormData("savePoint", "")
               .build();
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/bean/AlertTemplate.java
Patch:
@@ -103,7 +103,7 @@ public static AlertTemplate of(FlinkCluster cluster, ClusterState clusterState)
   }
 
   private static class AlertTemplateBuilder {
-    private AlertTemplate alertTemplate = new AlertTemplate();
+    private final AlertTemplate alertTemplate = new AlertTemplate();
 
     public AlertTemplateBuilder setTitle(String title) {
       alertTemplate.setTitle(title);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/alert/impl/DingTalkAlertNotifyServiceImpl.java
Patch:
@@ -107,7 +107,7 @@ public boolean doAlert(AlertConfigWithParams alertConfig, AlertTemplate alertTem
     } catch (AlertException alertException) {
       throw alertException;
     } catch (Exception e) {
-      throw new AlertException("Failed send dingTalk alert", e);
+      throw new AlertException("Failed send DingTalk alert", e);
     }
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/alert/impl/WeComAlertNotifyServiceImpl.java
Patch:
@@ -93,7 +93,7 @@ private void sendMessage(AlertWeComParams params, Map<String, Object> body)
     try {
       robotResponse = alertRestTemplate.postForObject(url, entity, RobotResponse.class);
     } catch (Exception e) {
-      log.error("Failed to request DingTalk robot alarm,\nurl:{}", url, e);
+      log.error("Failed to request WeCom robot alarm,\nurl:{}", url, e);
       throw new AlertException(
           String.format("Failed to request WeCom robot alert,\nurl:%s", url), e);
     }
@@ -104,7 +104,7 @@ private void sendMessage(AlertWeComParams params, Map<String, Object> body)
     if (robotResponse.getErrcode() != 0) {
       throw new AlertException(
           String.format(
-              "Failed to request DingTalk robot alert,\nurl:%s,\nerrorCode:%d,\nerrorMsg:%s",
+              "Failed to request WeCom robot alert,\nurl:%s,\nerrorCode:%d,\nerrorMsg:%s",
               url, robotResponse.getErrcode(), robotResponse.getErrmsg()));
     }
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkClusterWatcher.java
Patch:
@@ -296,6 +296,6 @@ private ClusterState yarnStateConvertClusterState(YarnApplicationState state) {
    */
   public Boolean verifyClusterConnection(FlinkCluster flinkCluster) {
     ClusterState clusterState = httpClusterState(flinkCluster);
-    return ClusterState.isRunning(clusterState) ? true : false;
+    return ClusterState.isRunning(clusterState);
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/runner/EnvInitializer.java
Patch:
@@ -87,7 +87,7 @@ public void run(ApplicationArguments args) throws Exception {
               "[StreamPark] System initialization check failed,"
                   + " The system initialization check failed. If started local for development and debugging,"
                   + " please ensure the -D%s parameter is clearly specified,"
-                  + " more detail: https://streampark.apache.org/docs/user-guide/development",
+                  + " more detail: https://streampark.apache.org/docs/user-guide/deployment",
               ConfigConst.KEY_APP_HOME()));
     }
 

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-doris/src/main/java/org/apache/streampark/flink/connector/doris/internal/DorisSinkFunction.java
Patch:
@@ -83,15 +83,15 @@ public void invoke(T value, SinkFunction.Context context) throws Exception {
           || null == data.getDataRows()) {
         LOGGER.warn(
             String.format(
-                " row data not fullfilled. {database: %s, table: %s, dataRows: %s}",
+                " row data not fulfilled. {database: %s, table: %s, dataRows: %s}",
                 data.getDatabase(), data.getTable(), data.getDataRows()));
         return;
       }
       dorisSinkWriter.writeRecords(data.getDatabase(), data.getTable(), data.getDataRows());
     } else {
       if (StringUtils.isEmpty(dorisConfig.database()) || StringUtils.isEmpty(dorisConfig.table())) {
         throw new RuntimeException(
-            " database|table  is empt ,please check your config or create DorisSinkRowDataWithMeta instance");
+            " database|table  is empty ,please check your config or create DorisSinkRowDataWithMeta instance");
       }
       dorisSinkWriter.writeRecords(dorisConfig.database(), dorisConfig.table(), (String) value);
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ApplicationMapper.java
Patch:
@@ -65,4 +65,6 @@ List<String> getRecentK8sClusterId(
   boolean existsRunningJobByClusterId(@Param("clusterId") Long clusterId);
 
   boolean existsJobByClusterId(@Param("clusterId") Long clusterId);
+
+  Integer getAffectedJobsByClusterId(@Param("clusterId") Long clusterId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -32,7 +32,6 @@
 import org.apache.streampark.console.core.service.FlinkEnvService;
 import org.apache.streampark.console.core.service.YarnQueueService;
 import org.apache.streampark.console.core.task.FlinkClusterWatcher;
-import org.apache.streampark.console.core.task.FlinkRESTAPIWatcher;
 import org.apache.streampark.flink.client.FlinkClient;
 import org.apache.streampark.flink.client.bean.DeployRequest;
 import org.apache.streampark.flink.client.bean.DeployResponse;
@@ -175,7 +174,6 @@ public void start(FlinkCluster cluster) {
       flinkCluster.setException(null);
       FlinkClusterWatcher.addFlinkCluster(flinkCluster);
       updateById(flinkCluster);
-      FlinkRESTAPIWatcher.removeFlinkCluster(flinkCluster);
     } catch (Exception e) {
       log.error(e.getMessage(), e);
       flinkCluster.setAddress(null);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/bean/AlertTemplate.java
Patch:
@@ -60,7 +60,7 @@ private static AlertTemplate of(Application application) {
 
     if (ExecutionMode.isYarnMode(application.getExecutionMode())) {
       String format = "%s/proxy/%s/";
-      String url = String.format(format, YarnUtils.getRMWebAppURL(), application.getAppId());
+      String url = String.format(format, YarnUtils.getRMWebAppURL(false), application.getAppId());
       template.setLink(url);
     } else {
       template.setLink(null);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/FlinkCluster.java
Patch:
@@ -178,7 +178,7 @@ public boolean verifyClusterConnection() {
     }
     if (ExecutionMode.YARN_SESSION.equals(this.getExecutionModeEnum())) {
       try {
-        String restUrl = YarnUtils.getRMWebAppURL() + "/proxy/" + this.clusterId + "/overview";
+        String restUrl = YarnUtils.getRMWebAppURL(true) + "/proxy/" + this.clusterId + "/overview";
         String result =
             HttpClientUtils.httpGetRequest(
                 restUrl,

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -163,7 +163,8 @@ public void start(FlinkCluster cluster) {
           deployResponse,
           "Deploy cluster failed, unknown reason，please check you params or StreamPark error log");
       if (ExecutionMode.isYarnSessionMode(flinkCluster.getExecutionModeEnum())) {
-        String address = YarnUtils.getRMWebAppURL() + "/proxy/" + deployResponse.clusterId() + "/";
+        String address =
+            YarnUtils.getRMWebAppURL(true) + "/proxy/" + deployResponse.clusterId() + "/";
         flinkCluster.setAddress(address);
         flinkCluster.setJobManagerUrl(deployResponse.address());
       } else {

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/alert/AlertServiceTest.java
Patch:
@@ -205,7 +205,7 @@ private AlertTemplate getAlertBaseInfo(Application application) {
       duration = application.getEndTime().getTime() - application.getStartTime().getTime();
     }
     String format = "%s/proxy/%s/";
-    String url = String.format(format, YarnUtils.getRMWebAppURL(), application.getAppId());
+    String url = String.format(format, YarnUtils.getRMWebAppURL(false), application.getAppId());
 
     AlertTemplate template = new AlertTemplate();
     template.setJobName(application.getJobName());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -231,8 +231,8 @@ public class Application implements Serializable {
   private transient String savePoint;
   private transient Boolean savePointed = false;
   private transient Boolean drain = false;
-  private transient Long savePointTimeout = 60L;
   private transient Boolean allowNonRestored = false;
+  private transient Integer restoreMode;
   private transient String socketId;
   private transient String projectName;
   private transient String createTimeFrom;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.streampark.common.enums.DevelopmentMode;
 import org.apache.streampark.common.enums.ExecutionMode;
 import org.apache.streampark.common.enums.ResolveOrder;
+import org.apache.streampark.common.enums.RestoreMode;
 import org.apache.streampark.common.enums.StorageType;
 import org.apache.streampark.common.fs.HdfsOperator;
 import org.apache.streampark.common.fs.LfsOperator;
@@ -1551,6 +1552,7 @@ public void start(Application appParam, boolean auto) throws Exception {
             appConf,
             application.getApplicationType(),
             getSavePointed(appParam),
+            appParam.getRestoreMode() == null ? null : RestoreMode.of(appParam.getRestoreMode()),
             applicationArgs,
             buildResult,
             kubernetesSubmitParam,

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/FlinkCluster.java
Patch:
@@ -64,6 +64,9 @@ public class FlinkCluster implements Serializable {
   @TableField(updateStrategy = FieldStrategy.IGNORED)
   private String address;
 
+  @TableField(updateStrategy = FieldStrategy.IGNORED)
+  private String jobManagerUrl;
+
   private String clusterId;
 
   private String clusterName;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/security/impl/LdapService.java
Patch:
@@ -82,11 +82,12 @@ public String ldapLogin(String userId, String userPwd) {
       ldapEnv = new Properties();
       ldapEnv.put(Context.INITIAL_CONTEXT_FACTORY, "com.sun.jndi.ldap.LdapCtxFactory");
       ldapEnv.put(Context.SECURITY_AUTHENTICATION, "simple");
-      ldapEnv.put(Context.SECURITY_PRINCIPAL, ldapSecurityPrincipal);
-      ldapEnv.put(Context.SECURITY_CREDENTIALS, ldapPrincipalPassword);
       ldapEnv.put(Context.PROVIDER_URL, ldapUrls);
     }
 
+    ldapEnv.put(Context.SECURITY_PRINCIPAL, ldapSecurityPrincipal);
+    ldapEnv.put(Context.SECURITY_CREDENTIALS, ldapPrincipalPassword);
+
     try {
       LdapContext ctx = new InitialLdapContext(ldapEnv, null);
       SearchControls sc = new SearchControls();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Resource.java
Patch:
@@ -42,6 +42,8 @@ public class Resource implements Serializable {
 
   private String resourceName;
 
+  private String resource;
+
   @Size(max = 100, message = "{noMoreThan}")
   private String description;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ApplicationMapper.java
Patch:
@@ -58,6 +58,8 @@ List<String> getRecentK8sClusterId(
 
   Boolean existsByJobName(@Param("jobName") String jobName);
 
+  Boolean existsByUserId(@Param("userId") Long userId);
+
   List<Application> getByProjectId(@Param("projectId") Long id);
 
   boolean existsRunningJobByClusterId(@Param("clusterId") Long clusterId);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ResourceMapper.java
Patch:
@@ -28,4 +28,6 @@
 public interface ResourceMapper extends BaseMapper<Resource> {
 
   IPage<Resource> page(Page<Resource> page, @Param("resource") Resource resource);
+
+  boolean existsByUserId(@Param("userId") Long userId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Resource.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.console.core.entity;
 
+import org.apache.streampark.console.core.enums.EngineType;
 import org.apache.streampark.console.core.enums.ResourceType;
 
 import com.baomidou.mybatisplus.annotation.IdType;
@@ -49,6 +50,8 @@ public class Resource implements Serializable {
 
   private ResourceType resourceType;
 
+  private EngineType engineType;
+
   private String mainClass;
 
   /** user name of creator */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -220,6 +220,7 @@ public class Application implements Serializable {
   /** running job */
   private transient JobsOverview.Task overview;
 
+  private transient String teamResource;
   private transient String dependency;
   private transient Long sqlId;
   private transient String flinkSql;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -718,7 +718,8 @@ public boolean create(Application appParam) {
     appParam.doSetHotParams();
     if (appParam.isUploadJob()) {
       String jarPath =
-          WebUtils.getAppTempDir().getAbsolutePath().concat("/").concat(appParam.getJar());
+          String.format(
+              "%s/%d/%s", Workspace.local().APP_UPLOADS(), appParam.getTeamId(), appParam.getJar());
       appParam.setJarCheckSum(FileUtils.checksumCRC32(new File(jarPath)));
     }
 
@@ -803,6 +804,7 @@ public Long copy(Application appParam) {
       if (newApp.isFlinkSqlJob()) {
         FlinkSql copyFlinkSql = flinkSqlService.getLatestFlinkSql(appParam.getId(), true);
         newApp.setFlinkSql(copyFlinkSql.getSql());
+        newApp.setTeamResource(copyFlinkSql.getTeamResource());
         newApp.setDependency(copyFlinkSql.getDependency());
         FlinkSql flinkSql = new FlinkSql(newApp);
         flinkSqlService.create(flinkSql);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -86,8 +86,8 @@
 import org.apache.streampark.flink.client.bean.SubmitResponse;
 import org.apache.streampark.flink.core.conf.ParameterCli;
 import org.apache.streampark.flink.kubernetes.FlinkK8sWatcher;
-import org.apache.streampark.flink.kubernetes.IngressController;
 import org.apache.streampark.flink.kubernetes.helper.KubernetesDeploymentHelper;
+import org.apache.streampark.flink.kubernetes.ingress.IngressController;
 import org.apache.streampark.flink.kubernetes.model.FlinkMetricCV;
 import org.apache.streampark.flink.kubernetes.model.TrackId;
 import org.apache.streampark.flink.packer.pipeline.BuildResult;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/UserServiceImpl.java
Patch:
@@ -96,7 +96,6 @@ public void updateLoginTime(String username) {
   @Transactional(rollbackFor = Exception.class)
   public void createUser(User user) {
     user.setCreateTime(new Date());
-    user.setAvatar(User.DEFAULT_AVATAR);
     String salt = ShaHashUtils.getRandomSalt();
     String password = ShaHashUtils.encrypt(salt, user.getPassword());
     user.setSalt(salt);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1272,7 +1272,6 @@ public void cancel(Application appParam) throws Exception {
             appParam.getSavePointed(),
             appParam.getDrain(),
             customSavepoint,
-            appParam.getSavePointTimeout(),
             application.getK8sNamespace());
 
     final Date triggerTime = new Date();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/security/impl/AuthenticatorImpl.java
Patch:
@@ -23,7 +23,6 @@
 import org.apache.streampark.console.core.enums.UserType;
 import org.apache.streampark.console.system.entity.User;
 import org.apache.streampark.console.system.security.Authenticator;
-import org.apache.streampark.console.system.security.impl.ldap.LdapService;
 import org.apache.streampark.console.system.service.UserService;
 
 import org.apache.commons.lang3.StringUtils;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/security/impl/LdapService.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-package org.apache.streampark.console.system.security.impl.ldap;
+package org.apache.streampark.console.system.security.impl;
 
 import lombok.extern.slf4j.Slf4j;
 import org.springframework.beans.factory.annotation.Value;

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-doris/src/main/java/org/apache/streampark/flink/connector/doris/bean/RespContent.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.flink.connector.doris.bean;
 
-import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.annotation.JsonProperty;
+import org.apache.streampark.shaded.com.fasterxml.jackson.annotation.JsonProperty;
 
 import java.io.Serializable;
 

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-doris/src/main/java/org/apache/streampark/flink/connector/doris/internal/DorisStreamLoader.java
Patch:
@@ -23,8 +23,9 @@
 import org.apache.streampark.flink.connector.doris.bean.RespContent;
 import org.apache.streampark.flink.connector.doris.util.DorisDelimiterParser;
 
+import org.apache.streampark.shaded.com.fasterxml.jackson.databind.ObjectMapper;
+
 import org.apache.commons.codec.binary.Base64;
-import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;
 import org.apache.http.HttpHeaders;
 import org.apache.http.client.methods.CloseableHttpResponse;
 import org.apache.http.client.methods.HttpGet;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkK8sChangeEventListener.java
Patch:
@@ -25,7 +25,6 @@
 import org.apache.streampark.console.core.metrics.flink.CheckPoints;
 import org.apache.streampark.console.core.service.ApplicationService;
 import org.apache.streampark.console.core.service.alert.AlertService;
-import org.apache.streampark.flink.kubernetes.IngressController;
 import org.apache.streampark.flink.kubernetes.enums.FlinkJobState;
 import org.apache.streampark.flink.kubernetes.enums.FlinkK8sExecuteMode;
 import org.apache.streampark.flink.kubernetes.event.FlinkClusterMetricChangeEvent;
@@ -96,7 +95,6 @@ public void subscribeJobStatusChange(FlinkJobStatusChangeEvent event) {
         || FlinkAppState.LOST.equals(state)
         || FlinkAppState.RESTARTING.equals(state)
         || FlinkAppState.FINISHED.equals(state)) {
-      IngressController.deleteIngress(app.getClusterId(), app.getK8sNamespace());
       executor.execute(() -> alertService.alert(app, state));
     }
   }
@@ -163,7 +161,6 @@ private void setByJobStatusCV(Application app, JobStatusCV jobStatus) {
     long duration = jobStatus.duration();
 
     if (FlinkJobState.isEndState(state)) {
-      IngressController.deleteIngress(app.getJobName(), app.getK8sNamespace());
       if (endTime < startTime) {
         endTime = System.currentTimeMillis();
       }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -808,8 +808,8 @@ public Long copy(Application appParam) {
         FlinkSql flinkSql = new FlinkSql(newApp);
         flinkSqlService.create(flinkSql);
       }
-      if (newApp.getConfig() != null) {
-        ApplicationConfig copyConfig = configService.getEffective(appParam.getId());
+      ApplicationConfig copyConfig = configService.getEffective(appParam.getId());
+      if (copyConfig != null) {
         ApplicationConfig config = new ApplicationConfig();
         config.setAppId(newApp.getId());
         config.setFormat(copyConfig.getFormat());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -397,7 +397,7 @@ public Boolean delete(Application paramApp) {
     // 8) remove app
     removeApp(application);
 
-    if (isKubernetesApp(paramApp)) {
+    if (isKubernetesApp(application)) {
       k8SFlinkTrackMonitor.unWatching(toTrackId(application));
     } else {
       FlinkRESTAPIWatcher.unWatching(paramApp.getId());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationService.java
Patch:
@@ -103,6 +103,8 @@ List<Application> getByTeamIdAndExecutionModes(
 
   boolean existsJobByClusterId(Long id);
 
+  boolean existsJobByFlinkEnvId(Long id);
+
   List<String> getRecentK8sNamespace();
 
   List<String> getRecentK8sClusterId(Integer executionMode);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/FlinkClusterService.java
Patch:
@@ -44,5 +44,7 @@ public interface FlinkClusterService extends IService<FlinkCluster> {
 
   Boolean existsByClusterName(String clusterName, Long id);
 
+  Boolean existsByFlinkEnvId(Long id);
+
   List<FlinkCluster> getByExecutionModes(Collection<ExecutionMode> executionModes);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/YarnQueue.java
Patch:
@@ -34,7 +34,6 @@
 public class YarnQueue implements Serializable {
 
   @TableId(type = IdType.AUTO)
-  @TableField(fill = FieldFill.INSERT, updateStrategy = FieldStrategy.NEVER)
   private Long id;
 
   @TableField(fill = FieldFill.INSERT, updateStrategy = FieldStrategy.NEVER)

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1250,7 +1250,7 @@ public void cancel(Application appParam) throws Exception {
             appParam.getSavePointed(),
             appParam.getDrain(),
             customSavepoint,
-            application.getSavePointTimeout(),
+            appParam.getSavePointTimeout(),
             application.getK8sNamespace());
 
     final Date triggerTime = new Date();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/runner/EnvInitializer.java
Patch:
@@ -69,7 +69,7 @@ public class EnvInitializer implements ApplicationRunner {
 
   private static final Pattern PATTERN_FLINK_SHIMS_JAR =
       Pattern.compile(
-          "^streampark-flink-shims_flink-1.1[2-7]_(2.11|2.12)-(.*).jar$",
+          "^streampark-flink-shims_flink-(1.1[2-7])_(2.11|2.12)-(.*).jar$",
           Pattern.CASE_INSENSITIVE | Pattern.DOTALL);
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/UserController.java
Patch:
@@ -22,6 +22,7 @@
 import org.apache.streampark.console.base.domain.RestResponse;
 import org.apache.streampark.console.base.exception.ApiAlertException;
 import org.apache.streampark.console.base.util.ShaHashUtils;
+import org.apache.streampark.console.core.enums.LoginType;
 import org.apache.streampark.console.core.enums.UserType;
 import org.apache.streampark.console.core.service.CommonService;
 import org.apache.streampark.console.system.entity.Team;
@@ -80,6 +81,7 @@ public RestResponse userList(RestRequest restRequest, User user) {
   @PostMapping("post")
   @RequiresPermissions("user:add")
   public RestResponse addUser(@Valid User user) throws Exception {
+    user.setLoginType(LoginType.PASSWORD);
     this.userService.createUser(user);
     return RestResponse.success();
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/MessageController.java
Patch:
@@ -34,8 +34,8 @@
 @Slf4j
 @Validated
 @RestController
-@RequestMapping("metrics")
-public class MetricsController {
+@RequestMapping("message")
+public class MessageController {
 
   @Autowired private MessageService messageService;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/authentication/ShiroRealm.java
Patch:
@@ -91,7 +91,7 @@ protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authent
       throw new AuthenticationException("ERROR Incorrect username or password!");
     }
 
-    if (!JWTUtil.verify(token, username, user.getPassword())) {
+    if (!JWTUtil.verify(token, username)) {
       // Check whether the token belongs to the api and whether the permission is valid
       String tokenDb = WebUtils.encryptToken(token);
       boolean effective = accessTokenService.checkTokenEffective(user.getUserId(), tokenDb);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/AccessTokenServiceImpl.java
Patch:
@@ -66,9 +66,7 @@ public RestResponse generateToken(Long userId, String expireTime, String descrip
       expireTime = AccessToken.DEFAULT_EXPIRE_TIME;
     }
     Long ttl = DateUtils.getTime(expireTime, DateUtils.fullFormat(), TimeZone.getDefault());
-    String token =
-        WebUtils.encryptToken(
-            JWTUtil.sign(user.getUserId(), user.getUsername(), user.getPassword(), ttl));
+    String token = WebUtils.encryptToken(JWTUtil.sign(user.getUserId(), user.getUsername(), ttl));
     JWTToken jwtToken = new JWTToken(token, expireTime);
 
     AccessToken accessToken = new AccessToken();

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/AccessTokenServiceTest.java
Patch:
@@ -53,6 +53,6 @@ void testGenerateToken() throws Exception {
     Assertions.assertEquals("admin", username);
     User user = userService.findByName(username);
     Assertions.assertNotNull(user);
-    Assertions.assertTrue(JWTUtil.verify(jwtToken.getToken(), username, user.getPassword()));
+    Assertions.assertTrue(JWTUtil.verify(jwtToken.getToken(), username));
   }
 }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/system/authentication/JWTTest.java
Patch:
@@ -27,20 +27,17 @@
 
 import java.util.Date;
 import java.util.TimeZone;
-import java.util.UUID;
 
 class JWTTest extends SpringTestBase {
 
   @Test
   void testExpireTime() {
     String userName = "black";
-    String secret = UUID.randomUUID().toString();
     String expireTime = AccessToken.DEFAULT_EXPIRE_TIME;
     String token =
         JWTUtil.sign(
             10000L,
             userName,
-            secret,
             DateUtils.getTime(expireTime, DateUtils.fullFormat(), TimeZone.getDefault()));
 
     assert token != null;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -696,7 +696,6 @@ public boolean create(Application appParam) {
     appParam.setRelease(ReleaseState.NEED_RELEASE.get());
     appParam.setOptionState(OptionState.NONE.getValue());
     appParam.setCreateTime(new Date());
-    appParam.setDefaultModeIngress(settingService.getIngressModeDefault());
     checkQueueLabelIfNeed(appParam.getExecutionMode(), appParam.getYarnQueue());
     appParam.doSetHotParams();
     if (appParam.isUploadJob()) {
@@ -769,7 +768,6 @@ public Long copy(Application appParam) {
     newApp.setResourceFrom(oldApp.getResourceFrom());
     newApp.setProjectId(oldApp.getProjectId());
     newApp.setModule(oldApp.getModule());
-    newApp.setDefaultModeIngress(oldApp.getDefaultModeIngress());
     newApp.setUserId(commonService.getUserId());
     newApp.setState(FlinkAppState.ADDED.getValue());
     newApp.setRelease(ReleaseState.NEED_RELEASE.get());
@@ -1499,7 +1497,7 @@ public void start(Application appParam, boolean auto) throws Exception {
         Utils.notNull(buildResult);
         DockerImageBuildResponse result = buildResult.as(DockerImageBuildResponse.class);
         String ingressTemplates = application.getIngressTemplate();
-        String domainName = application.getDefaultModeIngress();
+        String domainName = settingService.getIngressModeDefault();
         if (StringUtils.isNotBlank(ingressTemplates)) {
           String ingressOutput = result.workspacePath() + "/ingress.yaml";
           IngressController.configureIngress(ingressOutput);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1070,7 +1070,7 @@ public void forcedStop(Application app) {
           application.getK8sNamespace(), application.getJobName());
       KubernetesDeploymentHelper.deleteTaskConfigMap(
           application.getK8sNamespace(), application.getJobName());
-      IngressController.deleteIngress(application.getK8sNamespace(), application.getJobName());
+      IngressController.deleteIngress(application.getJobName(), application.getK8sNamespace());
     }
     if (startFuture != null) {
       startFuture.cancel(true);
@@ -1307,7 +1307,7 @@ public void cancel(Application appParam) throws Exception {
             (t, e) -> {
               if (isKubernetesApp(application)) {
                 IngressController.deleteIngress(
-                    application.getK8sNamespace(), application.getJobName());
+                    application.getJobName(), application.getK8sNamespace());
               }
               cancelFutureMap.remove(application.getId());
               applicationLogService.save(applicationLog);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/util/CommonUtils.java
Patch:
@@ -512,7 +512,7 @@ public static String uuid(int len) {
     while (sb.length() < len) {
       sb.append(uuid());
     }
-    return sb.toString().substring(0, len);
+    return sb.substring(0, len);
   }
 
   public static Double fixedNum(Number number) {
@@ -559,7 +559,7 @@ public static <T> Map<String, Object> beanToMap(T bean) {
     if (bean != null) {
       BeanMap beanMap = BeanMap.create(bean);
       for (Object key : beanMap.keySet()) {
-        map.put(key + "", beanMap.get(key));
+        map.put(String.valueOf(key), beanMap.get(key));
       }
     }
     return map;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationController.java
Patch:
@@ -398,7 +398,7 @@ public RestResponse verifySchema(String path) {
     } else if (pathPart == null) {
       error =
           "The path to store the checkpoint data in is null. Please specify a directory path for the checkpoint data.";
-    } else if (pathPart.length() == 0 || pathPart.equals("/")) {
+    } else if (pathPart.length() == 0 || "/".equals(pathPart)) {
       error = "Cannot use the root directory for checkpoints.";
     }
     if (error != null) {

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-doris/src/main/java/org/apache/streampark/flink/connector/doris/internal/DorisStreamLoader.java
Patch:
@@ -204,7 +204,7 @@ protected boolean isRedirectable(String method) {
       final Properties properties = dorisConfig.loadProperties();
       properties.forEach((k, v) -> put.setHeader(k.toString(), v.toString()));
       if (properties.containsKey("columns")) {
-        put.setHeader("timeout", dorisConfig.timeout() + "");
+        put.setHeader("timeout", String.valueOf(dorisConfig.timeout()));
       }
       put.setHeader(HttpHeaders.EXPECT, "100-continue");
       put.setHeader(

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/StreamParkConsoleBootstrap.java
Patch:
@@ -49,5 +49,4 @@ public class StreamParkConsoleBootstrap {
   public static void main(String[] args) {
     SpringApplication.run(StreamParkConsoleBootstrap.class, args);
   }
-  
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1374,9 +1374,6 @@ public void start(Application appParam, boolean auto) throws Exception {
       throw new ApiAlertException("[StreamPark] The application cannot be started repeatedly.");
     }
 
-    starting(application);
-    application.setAllowNonRestored(appParam.getAllowNonRestored());
-
     FlinkEnv flinkEnv = flinkEnvService.getByIdOrDefault(application.getVersionId());
     if (flinkEnv == null) {
       throw new ApiAlertException("[StreamPark] can no found flink version");
@@ -1393,6 +1390,9 @@ public void start(Application appParam, boolean auto) throws Exception {
       application.setRestartCount(application.getRestartCount() + 1);
     }
 
+    starting(application);
+    application.setAllowNonRestored(appParam.getAllowNonRestored());
+
     String appConf;
     String flinkUserJar = null;
     String jobId = new JobID().toHexString();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/security/Authenticator.java
Patch:
@@ -27,7 +27,5 @@ public interface Authenticator {
    * @param password user password
    * @return result object
    */
-  User authenticate(String username, String password) throws Exception;
-
-  User ldapAuthenticate(String username, String password) throws Exception;
+  User authenticate(String username, String password, String loginType) throws Exception;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationController.java
Patch:
@@ -235,7 +235,6 @@ public RestResponse revoke(Application app) {
   public RestResponse start(@ApiIgnore Application app) {
     try {
       applicationService.checkEnv(app);
-      applicationService.starting(app);
       applicationService.start(app, false);
       return RestResponse.success(true);
     } catch (Exception e) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -131,6 +131,7 @@ public class Application implements Serializable {
   private Integer optionState;
 
   /** alert id */
+  @TableField(updateStrategy = FieldStrategy.IGNORED)
   private Integer alertId;
 
   private String args;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/ApplicationLog.java
Patch:
@@ -40,7 +40,8 @@ public class ApplicationLog {
   private String jobManagerUrl;
   /** start status */
   private Boolean success;
-
+  /** option name */
+  private Integer optionName;
   /** option time */
   private Date optionTime;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/AppBuildPipeService.java
Patch:
@@ -19,6 +19,7 @@
 
 import org.apache.streampark.console.core.entity.AppBuildPipeline;
 import org.apache.streampark.console.core.entity.Application;
+import org.apache.streampark.console.core.entity.ApplicationLog;
 import org.apache.streampark.flink.packer.pipeline.DockerResolvedSnapshot;
 import org.apache.streampark.flink.packer.pipeline.PipelineStatus;
 
@@ -33,7 +34,8 @@
 public interface AppBuildPipeService extends IService<AppBuildPipeline> {
 
   /** Build application. This is an async call method. */
-  boolean buildApplication(@Nonnull Application app) throws Exception;
+  boolean buildApplication(@Nonnull Application app, ApplicationLog applicationLog)
+      throws Exception;
 
   /**
    * Get current build pipeline instance of specified application

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationLogService.java
Patch:
@@ -28,4 +28,6 @@ public interface ApplicationLogService extends IService<ApplicationLog> {
   IPage<ApplicationLog> page(ApplicationLog applicationLog, RestRequest request);
 
   void removeApp(Long appId);
+
+  Boolean delete(ApplicationLog applicationLog);
 }

File: streampark-common/src/main/java/org/apache/streampark/common/enums/ClusterState.java
Patch:
@@ -26,7 +26,7 @@ public enum ClusterState implements Serializable {
   /** cluster started */
   STARTED(1),
   /** cluster stopped */
-  STOPED(2),
+  STOPPED(2),
 
   /** cluster lost */
   LOST(3);

File: streampark-common/src/main/java/org/apache/streampark/common/enums/DevelopmentMode.java
Patch:
@@ -22,10 +22,10 @@
 public enum DevelopmentMode implements Serializable {
 
   /** custom code */
-  CUSTOMCODE("Custom Code", 1),
+  CUSTOM_CODE("Custom Code", 1),
 
   /** Flink SQL */
-  FLINKSQL("Flink SQL", 2);
+  FLINK_SQL("Flink SQL", 2);
 
   private final String mode;
 

File: streampark-common/src/main/java/org/apache/streampark/common/enums/FlinkK8sRestExposedType.java
Patch:
@@ -23,13 +23,13 @@
 public enum FlinkK8sRestExposedType implements Serializable {
 
   /** LoadBalancer */
-  LoadBalancer("LoadBalancer", 0),
+  LOAD_BALANCER("LoadBalancer", 0),
 
   /** ClusterIP */
-  ClusterIP("ClusterIP", 1),
+  CLUSTER_IP("ClusterIP", 1),
 
   /** NodePort */
-  NodePort("NodePort", 2);
+  NODE_PORT("NodePort", 2);
 
   private final String name;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/IndexController.java
Patch:
@@ -18,14 +18,15 @@
 package org.apache.streampark.console.core.controller;
 
 import org.springframework.stereotype.Controller;
+import org.springframework.web.bind.annotation.GetMapping;
 import org.springframework.web.bind.annotation.RequestMapping;
 import org.springframework.web.servlet.ModelAndView;
 
 @RequestMapping
 @Controller
 public class IndexController {
 
-  @RequestMapping("/")
+  @GetMapping("/")
   public ModelAndView index() {
     return new ModelAndView("/index.html");
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -445,12 +445,12 @@ public Map<String, Object> getOptionMap() {
 
   @JsonIgnore
   public boolean isFlinkSqlJob() {
-    return DevelopmentMode.FLINKSQL.getValue().equals(this.getJobType());
+    return DevelopmentMode.FLINK_SQL.getValue().equals(this.getJobType());
   }
 
   @JsonIgnore
   public boolean isCustomCodeJob() {
-    return DevelopmentMode.CUSTOMCODE.getValue().equals(this.getJobType());
+    return DevelopmentMode.CUSTOM_CODE.getValue().equals(this.getJobType());
   }
 
   @JsonIgnore

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/alert/impl/EmailAlertNotifyServiceImpl.java
Patch:
@@ -84,6 +84,7 @@ private boolean sendEmail(SenderEmail senderEmail, AlertTemplate mail, String...
       htmlEmail.setAuthentication(senderEmail.getUserName(), senderEmail.getPassword());
       htmlEmail.setFrom(senderEmail.getFrom());
       if (senderEmail.isSsl()) {
+        htmlEmail.setSSLCheckServerIdentity(true);
         htmlEmail.setSSLOnConnect(true);
         htmlEmail.setSslSmtpPort(senderEmail.getSmtpPort().toString());
       } else {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -328,7 +328,7 @@ private BuildPipeline createPipelineInstance(@Nonnull Application app) {
       case YARN_APPLICATION:
         String yarnProvidedPath = app.getAppLib();
         String localWorkspace = app.getLocalAppHome().concat("/lib");
-        if (app.getDevelopmentMode().equals(DevelopmentMode.CUSTOMCODE)
+        if (app.getDevelopmentMode().equals(DevelopmentMode.CUSTOM_CODE)
             && app.getApplicationType().equals(ApplicationType.APACHE_FLINK)) {
           yarnProvidedPath = app.getAppHome();
           localWorkspace = app.getLocalAppHome();
@@ -407,7 +407,7 @@ private BuildPipeline createPipelineInstance(@Nonnull Application app) {
   /** copy from {@link ApplicationServiceImpl#start(Application, boolean)} */
   private String retrieveFlinkUserJar(FlinkEnv flinkEnv, Application app) {
     switch (app.getDevelopmentMode()) {
-      case CUSTOMCODE:
+      case CUSTOM_CODE:
         switch (app.getApplicationType()) {
           case STREAMPARK_FLINK:
             return String.format("%s/%s", app.getAppLib(), app.getModule().concat(".jar"));
@@ -418,7 +418,7 @@ private String retrieveFlinkUserJar(FlinkEnv flinkEnv, Application app) {
                 "[StreamPark] unsupported ApplicationType of custom code: "
                     + app.getApplicationType());
         }
-      case FLINKSQL:
+      case FLINK_SQL:
         String sqlDistJar = commonService.getSqlClientJar(flinkEnv);
         if (app.getExecutionModeEnum() == ExecutionMode.YARN_APPLICATION) {
           String clientPath = Workspace.remote().APP_CLIENT();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -196,7 +196,7 @@ public void start(FlinkCluster cluster) {
       }
     } catch (Exception e) {
       log.error(e.getMessage(), e);
-      flinkCluster.setClusterState(ClusterState.STOPED.getValue());
+      flinkCluster.setClusterState(ClusterState.STOPPED.getValue());
       flinkCluster.setException(e.toString());
       updateById(flinkCluster);
       throw new ApiDetailException(e);
@@ -299,7 +299,7 @@ public void shutdown(FlinkCluster cluster) {
       ShutDownResponse shutDownResponse = future.get(60, TimeUnit.SECONDS);
       if (shutDownResponse != null) {
         flinkCluster.setAddress(null);
-        flinkCluster.setClusterState(ClusterState.STOPED.getValue());
+        flinkCluster.setClusterState(ClusterState.STOPPED.getValue());
         updateById(flinkCluster);
       } else {
         throw new ApiAlertException("get shutdown response failed");

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/CheckpointProcessor.java
Patch:
@@ -119,6 +119,9 @@ private void process(Application application, @Nonnull CheckPoints.CheckPoint ch
                 throw new RuntimeException(e);
               }
               break;
+            default:
+              // do nothing
+              break;
           }
         } else {
           counter.increment();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -122,6 +122,7 @@ public class Application implements Serializable {
   private Boolean build;
 
   /** max restart retries after job failed */
+  @TableField(updateStrategy = FieldStrategy.IGNORED)
   private Integer restartSize;
 
   /** has restart count */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/UserService.java
Patch:
@@ -100,6 +100,8 @@ public interface UserService extends IService<User> {
    */
   void updatePassword(User user) throws Exception;
 
+  void updateSaltPassword(User user) throws Exception;
+
   /**
    * reset password
    *

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/YarnQueueMapper.java
Patch:
@@ -28,4 +28,6 @@
 /** Yarn queue mapper definition. */
 public interface YarnQueueMapper extends BaseMapper<YarnQueue> {
   IPage<YarnQueue> findQueues(Page<YarnQueue> page, @Param("yarnQueue") YarnQueue yarnQueue);
+
+  boolean existsByQueueLabel(@Param("yarnQueue") YarnQueue yarnQueue);
 }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/utils/YarnQueueLabelExpressionTest.java
Patch:
@@ -21,7 +21,7 @@
 
 import org.junit.jupiter.api.Test;
 
-import static org.apache.streampark.console.core.utils.YarnQueueLabelExpression.ERR_HINTS;
+import static org.apache.streampark.console.core.utils.YarnQueueLabelExpression.ERR_FORMAT_HINTS;
 import static org.apache.streampark.console.core.utils.YarnQueueLabelExpression.isValid;
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.assertThatThrownBy;
@@ -63,6 +63,6 @@ void testOf() {
     assertThat(YarnQueueLabelExpression.of("a").getQueue()).isEqualTo("a");
     assertThatThrownBy(() -> YarnQueueLabelExpression.of("a@"))
         .isInstanceOf(ApiAlertException.class)
-        .hasMessageContaining(ERR_HINTS);
+        .hasMessageContaining(ERR_FORMAT_HINTS);
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/AccessTokenServiceImpl.java
Patch:
@@ -46,7 +46,6 @@
 import java.util.List;
 import java.util.Objects;
 import java.util.TimeZone;
-import java.util.UUID;
 
 @Slf4j
 @Service
@@ -66,11 +65,10 @@ public RestResponse generateToken(Long userId, String expireTime, String descrip
     if (StringUtils.isEmpty(expireTime)) {
       expireTime = AccessToken.DEFAULT_EXPIRE_TIME;
     }
-
     Long ttl = DateUtils.getTime(expireTime, DateUtils.fullFormat(), TimeZone.getDefault());
     String token =
         WebUtils.encryptToken(
-            JWTUtil.sign(user.getUserId(), user.getUsername(), UUID.randomUUID().toString(), ttl));
+            JWTUtil.sign(user.getUserId(), user.getUsername(), user.getPassword(), ttl));
     JWTToken jwtToken = new JWTToken(token, expireTime);
 
     AccessToken accessToken = new AccessToken();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/CheckpointProcessor.java
Patch:
@@ -69,6 +69,8 @@ public class CheckpointProcessor {
 
   @Autowired private SavePointService savePointService;
 
+  @Autowired private FlinkRESTAPIWatcher flinkRESTAPIWatcher;
+
   public void process(Application application, @Nonnull CheckPoints checkPoints) {
     checkPoints.getLatestCheckpoint().forEach(checkPoint -> process(application, checkPoint));
   }
@@ -83,6 +85,7 @@ private void process(Application application, @Nonnull CheckPoints.CheckPoint ch
       if (shouldStoreAsSavepoint(checkPointKey, checkPoint)) {
         savepointedCache.put(checkPointKey.getSavePointId(), DEFAULT_FLAG_BYTE);
         saveSavepoint(checkPoint, application.getId());
+        flinkRESTAPIWatcher.cleanSavepoint(application);
         return;
       }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkRESTAPIWatcher.java
Patch:
@@ -568,7 +568,7 @@ private void cleanOptioning(OptionState optionState, Long key) {
     }
   }
 
-  private void cleanSavepoint(Application application) {
+  public void cleanSavepoint(Application application) {
     SAVEPOINT_CACHE.invalidate(application.getId());
     application.setOptionState(OptionState.NONE.getValue());
   }

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-influx/src/main/java/org/apache/streampark/flink/connector/influx/function/InfluxFieldFunction.java
Patch:
@@ -21,5 +21,5 @@
 import java.util.Map;
 
 public interface InfluxFieldFunction<T> extends Serializable {
-    Map<String, Object> transform(T value);
+  Map<String, Object> transform(T value);
 }

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-influx/src/main/java/org/apache/streampark/flink/connector/influx/function/InfluxTagFunction.java
Patch:
@@ -21,5 +21,5 @@
 import java.util.Map;
 
 public interface InfluxTagFunction<T> extends Serializable {
-    Map<String, String> transform(T value);
+  Map<String, String> transform(T value);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -178,6 +178,8 @@ public void start(FlinkCluster cluster) {
           String address =
               YarnUtils.getRMWebAppURL() + "/proxy/" + deployResponse.clusterId() + "/";
           flinkCluster.setAddress(address);
+        } else {
+          flinkCluster.setAddress(deployResponse.address());
         }
         flinkCluster.setClusterId(deployResponse.clusterId());
         flinkCluster.setClusterState(ClusterState.STARTED.getValue());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1386,8 +1386,8 @@ public void start(Application appParam, boolean auto) throws Exception {
       if (!application.isNeedRestartOnFailed()) {
         return;
       }
+      appParam.setSavePointed(true);
       application.setRestartCount(application.getRestartCount() + 1);
-      application.setSavePointed(true);
     }
 
     String appConf;

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/system/authentication/JWTTest.java
Patch:
@@ -32,7 +32,7 @@
 class JWTTest extends SpringTestBase {
 
   @Test
-  void getExpireTime() {
+  void testExpireTime() {
     String userName = "black";
     String secret = UUID.randomUUID().toString();
     String expireTime = AccessToken.DEFAULT_EXPIRE_TIME;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ConfigController.java
Patch:
@@ -71,6 +71,7 @@ public RestResponse history(Application application) {
   }
 
   @PostMapping("delete")
+  @RequiresPermissions("conf:delete")
   public RestResponse delete(Long id) {
     Boolean deleted = applicationConfigService.removeById(id);
     return RestResponse.success(deleted);

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/common/util/RegexTest.java
Patch:
@@ -17,6 +17,7 @@
 
 package org.apache.streampark.common.util;
 
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 
 import java.io.File;
@@ -44,6 +45,7 @@ void regex() {
     }
   }
 
+  @Disabled("This test case can't be runnable due to the depended jar is not available.")
   @Test
   void classLoader() throws MalformedURLException {
     List<URL> libCache = new ArrayList<>(0);
@@ -82,6 +84,7 @@ void classLoader() throws MalformedURLException {
     System.out.println(urlClassLoader);
   }
 
+  @Disabled("This test case can't be runnable due to the environment is not available.")
   @Test
   void flinkVersion() {
     final Pattern flinkVersionPattern = Pattern.compile("^Version: (.*), Commit ID: (.*)$");

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/base/util/EncryptUtilsTest.java
Patch:
@@ -20,10 +20,10 @@
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
 
-public class EncryptUtilsTest {
+class EncryptUtilsTest {
 
   @Test
-  public void testEncrypt() throws Exception {
+  void testEncrypt() throws Exception {
     String value = "apache streampark";
     String encrypt = EncryptUtils.encrypt(value, "streampark");
     String decrypt = EncryptUtils.decrypt(encrypt, "streampark");

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/bean/SenderEmailTest.java
Patch:
@@ -28,6 +28,7 @@
 
 import freemarker.template.Template;
 import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 
 import java.io.StringWriter;
@@ -55,6 +56,7 @@ void initConfig() {
   }
 
   @Test
+  @Disabled("This test case can't be runnable due to the email service is not available.")
   void alert() {
     Application application = new Application();
     application.setStartTime(new Date());

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/entity/GitTest.java
Patch:
@@ -21,6 +21,7 @@
 import org.apache.streampark.console.core.enums.GitCredential;
 
 import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 
 import java.util.List;
@@ -35,12 +36,14 @@ void before() {
     project.setGitCredential(GitCredential.HTTPS.getValue());
   }
 
+  @Disabled("This test case can't be runnable due to external service is not available.")
   @Test
   void getBranchs() {
     List<String> branches = project.getAllBranches();
     branches.forEach(System.out::println);
   }
 
+  @Disabled("This test case can't be runnable due to external service is not available.")
   @Test
   void auth() {
     GitAuthorizedError error = project.gitCheck();

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/alert/AlertServiceTest.java
Patch:
@@ -29,12 +29,14 @@
 
 import com.fasterxml.jackson.databind.ObjectMapper;
 import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.Disabled;
 import org.junit.jupiter.api.Test;
 import org.springframework.web.client.RestTemplate;
 
 import java.util.Date;
 import java.util.TimeZone;
 
+@Disabled("These test cases can't be runnable due to external service is not available.")
 class AlertServiceTest {
   AlertTemplate alertTemplate;
   AlertConfigWithParams params = new AlertConfigWithParams();

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/utils/YarnQueueLabelExpressionTest.java
Patch:
@@ -17,6 +17,8 @@
 
 package org.apache.streampark.console.core.utils;
 
+import org.apache.streampark.console.base.exception.ApiAlertException;
+
 import org.junit.jupiter.api.Test;
 
 import static org.apache.streampark.console.core.utils.YarnQueueLabelExpression.ERR_HINTS;
@@ -60,7 +62,7 @@ void testOf() {
     assertThat(YarnQueueLabelExpression.of("a").getLabelExpression()).isEmpty();
     assertThat(YarnQueueLabelExpression.of("a").getQueue()).isEqualTo("a");
     assertThatThrownBy(() -> YarnQueueLabelExpression.of("a@"))
-        .isInstanceOf(IllegalArgumentException.class)
+        .isInstanceOf(ApiAlertException.class)
         .hasMessageContaining(ERR_HINTS);
   }
 }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/system/authentication/JWTTest.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.streampark.console.system.authentication;
 
 import org.apache.streampark.common.util.DateUtils;
+import org.apache.streampark.console.SpringTestBase;
 import org.apache.streampark.console.system.entity.AccessToken;
 
 import com.auth0.jwt.JWT;
@@ -28,7 +29,7 @@
 import java.util.TimeZone;
 import java.util.UUID;
 
-class JWTTest {
+class JWTTest extends SpringTestBase {
 
   @Test
   void getExpireTime() {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationService.java
Patch:
@@ -71,8 +71,6 @@ public interface ApplicationService extends IService<Application> {
 
   Map<String, Serializable> dashboard(Long teamId);
 
-  void tailMvnDownloading(Long id);
-
   String upload(MultipartFile file) throws Exception;
 
   /** set the latest to Effective, it will really become the current effective */

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ProjectController.java
Patch:
@@ -17,9 +17,9 @@
 
 package org.apache.streampark.console.core.controller;
 
-import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.domain.RestResponse;
+import org.apache.streampark.console.base.exception.ApiAlertException;
 import org.apache.streampark.console.core.annotation.AppUpdated;
 import org.apache.streampark.console.core.entity.Project;
 import org.apache.streampark.console.core.enums.GitAuthorizedError;
@@ -50,7 +50,8 @@ public class ProjectController {
   @PostMapping("create")
   @RequiresPermissions("project:create")
   public RestResponse create(Project project) {
-    Utils.notNull(project.getTeamId(), "The teamId cannot be null");
+    ApiAlertException.throwIfNull(
+        project.getTeamId(), "The teamId can't be null. Create team failed.");
     return projectService.create(project);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/authentication/JWTFilter.java
Patch:
@@ -80,7 +80,7 @@ protected boolean executeLogin(ServletRequest request, ServletResponse response)
       getSubject(request, response).login(jwtToken);
       return true;
     } catch (Exception e) {
-      log.info(e.getMessage());
+      log.error("Error in executeLogin, token {}, jwtToken {}", token, jwtToken, e);
       return false;
     }
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/MemberServiceImpl.java
Patch:
@@ -75,7 +75,7 @@ public void deleteByTeamId(Long teamId) {
 
   @Override
   public IPage<Member> findUsers(Member member, RestRequest request) {
-    Utils.notNull(member.getTeamId(), "The team id is required.");
+    ApiAlertException.throwIfNull(member.getTeamId(), "The team id is required.");
     Page<Member> page = new Page<>();
     page.setCurrent(request.getPageNum());
     page.setSize(request.getPageSize());
@@ -102,7 +102,7 @@ public Member findByUserName(Long teamId, String userName) {
   }
 
   private Member findByUserId(Long teamId, Long userId) {
-    Utils.notNull(teamId, "The team id is required.");
+    ApiAlertException.throwIfNull(teamId, "The team id is required.");
     LambdaQueryWrapper<Member> queryWrapper =
         new LambdaQueryWrapper<Member>()
             .eq(Member::getTeamId, teamId)
@@ -137,7 +137,7 @@ public void createMember(Member member) {
                 () ->
                     new ApiAlertException(
                         String.format("The teamId [%s] not found", member.getTeamId())));
-    Utils.required(
+    ApiAlertException.throwIfFalse(
         findByUserId(member.getTeamId(), user.getUserId()) == null,
         String.format(
             "The user [%s] has been added the team [%s], please don't add it again.",

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationBuildPipelineController.java
Patch:
@@ -60,16 +60,16 @@ public class ApplicationBuildPipelineController {
   @Autowired private FlinkSqlService flinkSqlService;
 
   /**
-   * Launch application building pipeline.
+   * Release application building pipeline.
    *
    * @param appId application id
    * @param forceBuild forced start pipeline or not
    * @return Whether the pipeline was successfully started
    */
   @ApiAccess
   @ApiOperation(
-      value = "Launch application",
-      notes = "Launch application",
+      value = "Release application",
+      notes = "Release application",
       tags = ApiDocConstant.FLINK_APP_OP_TAG,
       consumes = "application/x-www-form-urlencoded")
   @ApiImplicitParams({

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationController.java
Patch:
@@ -189,7 +189,7 @@ public RestResponse mapping(Application app) {
 
   @AppUpdated
   @PostMapping("revoke")
-  @RequiresPermissions("app:launch")
+  @RequiresPermissions("app:release")
   public RestResponse revoke(Application app) {
     applicationService.revoke(app);
     return RestResponse.success();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/OptionState.java
Patch:
@@ -27,8 +27,8 @@ public enum OptionState implements Serializable {
 
   /** Application which is currently action: none. */
   NONE(0),
-  /** Application which is currently action: deploying. */
-  LAUNCHING(1),
+  /** Application which is currently action: releasing. */
+  RELEASING(1),
   /** Application which is currently action: cancelling. */
   CANCELLING(2),
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationService.java
Patch:
@@ -86,7 +86,7 @@ public interface ApplicationService extends IService<Application> {
 
   boolean checkAlter(Application application);
 
-  void updateLaunch(Application application);
+  void updateRelease(Application application);
 
   List<Application> getByProjectId(Long id);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationBackUpServiceImpl.java
Patch:
@@ -28,7 +28,7 @@
 import org.apache.streampark.console.core.entity.ApplicationConfig;
 import org.apache.streampark.console.core.entity.FlinkSql;
 import org.apache.streampark.console.core.enums.EffectiveType;
-import org.apache.streampark.console.core.enums.LaunchState;
+import org.apache.streampark.console.core.enums.ReleaseState;
 import org.apache.streampark.console.core.mapper.ApplicationBackUpMapper;
 import org.apache.streampark.console.core.service.ApplicationBackUpService;
 import org.apache.streampark.console.core.service.ApplicationConfigService;
@@ -144,7 +144,7 @@ public void rollback(ApplicationBackUp backParam) {
           new UpdateWrapper<Application>()
               .lambda()
               .eq(Application::getId, application.getId())
-              .set(Application::getLaunch, LaunchState.NEED_RESTART.get()));
+              .set(Application::getRelease, ReleaseState.NEED_RESTART.get()));
     } catch (Exception e) {
       throw e;
     }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/ApplicationServiceTest.java
Patch:
@@ -54,7 +54,7 @@ void revokeTest() {
     app.setVersionId(1L);
     app.setK8sNamespace("default");
     app.setState(0);
-    app.setLaunch(2);
+    app.setRelease(2);
     app.setBuild(true);
     app.setRestartSize(0);
     app.setOptionState(0);
@@ -77,7 +77,7 @@ void revokeTest() {
     app.setDrain(false);
     app.setAllowNonRestored(false);
 
-    Assertions.assertDoesNotThrow(() -> applicationService.updateLaunch(app));
+    Assertions.assertDoesNotThrow(() -> applicationService.updateRelease(app));
   }
 
   @Test

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkK8sChangeEventListener.java
Patch:
@@ -146,7 +146,7 @@ public void subscribeCheckpointChange(FlinkJobCheckpointChangeEvent event) {
     CheckPoints checkPoint = new CheckPoints();
     checkPoint.setLatest(latest);
 
-    checkpointProcessor.process(event.trackId().appId(), checkPoint);
+    checkpointProcessor.process(applicationService.getById(event.trackId().appId()), checkPoint);
   }
 
   private void setByJobStatusCV(Application app, JobStatusCV jobStatus) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkRESTAPIWatcher.java
Patch:
@@ -354,7 +354,7 @@ private void handleCheckPoints(Application application) throws Exception {
     FlinkCluster flinkCluster = getFlinkCluster(application);
     CheckPoints checkPoints = httpCheckpoints(application, flinkCluster);
     if (checkPoints != null) {
-      checkpointProcessor.process(application.getId(), checkPoints);
+      checkpointProcessor.process(application, checkPoints);
     }
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Project.java
Patch:
@@ -17,7 +17,6 @@
 
 package org.apache.streampark.console.core.entity;
 
-import org.apache.streampark.common.conf.CommonConfig;
 import org.apache.streampark.common.conf.Workspace;
 import org.apache.streampark.common.util.CommandUtils;
 import org.apache.streampark.console.base.exception.ApiDetailException;
@@ -204,7 +203,7 @@ public String getMavenArgs() {
       cmdBuffer.append(this.buildArgs.trim());
     }
 
-    Setting setting = SettingService.SETTINGS.get(CommonConfig.MAVEN_SETTINGS_PATH());
+    Setting setting = SettingService.SETTINGS.get(SettingService.KEY_MAVEN_SETTINGS);
     if (setting != null) {
       cmdBuffer.append(" --settings ").append(setting.getSettingValue());
     }

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/common/util/RegexTest.java
Patch:
@@ -15,9 +15,7 @@
  * limitations under the License.
  */
 
-package java.util.regex;
-
-import org.apache.streampark.common.util.CommandUtils;
+package org.apache.streampark.common.util;
 
 import org.junit.jupiter.api.Test;
 
@@ -28,6 +26,8 @@
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
 import java.util.stream.Collectors;
 
 class RegexTest {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/SwaggerConfig.java
Patch:
@@ -94,7 +94,7 @@ private ApiInfo apiInfo() {
         .contact(
             new Contact(
                 "Apache StreamPark", "https://streampark.apache.org/", "dev@streampark.apache.org"))
-        .version("2.1.0")
+        .version("2.1.0-SNAPSHOT")
         .license("Apache-2.0 license")
         .build();
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/FlinkCluster.java
Patch:
@@ -27,6 +27,7 @@
 import org.apache.streampark.console.base.util.CommonUtils;
 import org.apache.streampark.console.base.util.JacksonUtils;
 import org.apache.streampark.console.core.metrics.flink.Overview;
+import org.apache.streampark.console.core.utils.YarnQueueLabelExpression;
 import org.apache.streampark.flink.client.FlinkClient;
 
 import com.baomidou.mybatisplus.annotation.FieldStrategy;
@@ -125,9 +126,7 @@ public Map<String, Object> getOptionMap() {
     Map<String, Object> map = JacksonUtils.read(this.options, Map.class);
     if (ExecutionMode.YARN_SESSION.equals(getExecutionModeEnum())) {
       map.put(ConfigConst.KEY_YARN_APP_NAME(), this.clusterName);
-      if (StringUtils.isNotEmpty(this.yarnQueue)) {
-        map.put(ConfigConst.KEY_YARN_APP_QUEUE(), this.yarnQueue);
-      }
+      map.putAll(YarnQueueLabelExpression.getQueueLabelMap(yarnQueue));
     }
     map.entrySet().removeIf(entry -> entry.getValue() == null);
     return map;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/exception/AlertException.java
Patch:
@@ -17,15 +17,15 @@
 
 package org.apache.streampark.console.base.exception;
 
-import org.apache.streampark.common.util.ExceptionUtils;
+import org.apache.streampark.common.util.Utils;
 
 public class AlertException extends ApiAlertException {
   public AlertException(String message) {
     super(message);
   }
 
   public AlertException(Throwable cause) {
-    super(ExceptionUtils.stringifyException(cause));
+    super(Utils.stringifyException(cause));
   }
 
   public AlertException(String message, Throwable cause) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/exception/ApiDetailException.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.base.exception;
 
-import org.apache.streampark.common.util.ExceptionUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.domain.ResponseCode;
 
 /**
@@ -37,11 +37,11 @@ public ApiDetailException(String message) {
   }
 
   public ApiDetailException(Throwable cause) {
-    super(ExceptionUtils.stringifyException(cause), ResponseCode.CODE_FAIL_DETAIL);
+    super(Utils.stringifyException(cause), ResponseCode.CODE_FAIL_DETAIL);
   }
 
   public ApiDetailException(String message, Throwable cause) {
-    super(message + ExceptionUtils.stringifyException(cause), ResponseCode.CODE_FAIL_DETAIL);
+    super(message + Utils.stringifyException(cause), ResponseCode.CODE_FAIL_DETAIL);
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/interceptor/UploadFileTypeInterceptor.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.streampark.console.base.interceptor;
 
-import org.apache.streampark.common.util.AssertUtils;
 import org.apache.streampark.common.util.FileUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.exception.ApiAlertException;
 
 import org.springframework.stereotype.Component;
@@ -43,7 +43,7 @@ public boolean preHandle(HttpServletRequest request, HttpServletResponse respons
       Map<String, MultipartFile> files = multipartRequest.getFileMap();
       for (String file : files.keySet()) {
         MultipartFile multipartFile = multipartRequest.getFile(file);
-        AssertUtils.state(multipartFile != null);
+        Utils.required(multipartFile != null);
         boolean fileType = FileUtils.isJarFileType(multipartFile.getInputStream());
         if (!fileType) {
           throw new ApiAlertException("illegal file type, Only standard jar files supported");

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ProjectController.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.core.controller;
 
-import org.apache.streampark.common.util.AssertUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.domain.RestResponse;
 import org.apache.streampark.console.core.annotation.AppUpdated;
@@ -50,7 +50,7 @@ public class ProjectController {
   @PostMapping("create")
   @RequiresPermissions("project:create")
   public RestResponse create(Project project) {
-    AssertUtils.checkArgument(project.getTeamId() != null, "The teamId cannot be null");
+    Utils.required(project.getTeamId() != null, "The teamId cannot be null");
     return projectService.create(project);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/alert/impl/AlertServiceImpl.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.core.service.alert.impl;
 
-import org.apache.streampark.common.util.AssertUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.exception.AlertException;
 import org.apache.streampark.console.base.util.SpringContextUtils;
 import org.apache.streampark.console.core.bean.AlertConfigWithParams;
@@ -84,7 +84,7 @@ public boolean alert(AlertConfigWithParams params, AlertTemplate alertTemplate)
                   try {
                     Class<? extends AlertNotifyService> notifyServiceClass =
                         getAlertServiceImpl(alertType);
-                    AssertUtils.state(notifyServiceClass != null);
+                    Utils.required(notifyServiceClass != null);
                     boolean alertRes =
                         SpringContextUtils.getBean(notifyServiceClass)
                             .doAlert(params, alertTemplate);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationBackUpServiceImpl.java
Patch:
@@ -18,8 +18,8 @@
 package org.apache.streampark.console.core.service.impl;
 
 import org.apache.streampark.common.fs.FsOperator;
-import org.apache.streampark.common.util.AssertUtils;
 import org.apache.streampark.common.util.ThreadUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.exception.InternalException;
 import org.apache.streampark.console.base.mybatis.pager.MybatisPager;
@@ -190,7 +190,7 @@ public void removeApp(Application application) {
   @Override
   public void rollbackFlinkSql(Application application, FlinkSql sql) {
     ApplicationBackUp backUp = getFlinkSqlBackup(application.getId(), sql.getId());
-    AssertUtils.state(backUp != null);
+    Utils.required(backUp != null);
     // rollback config and sql
     effectiveService.saveOrUpdate(backUp.getAppId(), EffectiveType.CONFIG, backUp.getId());
     effectiveService.saveOrUpdate(backUp.getAppId(), EffectiveType.FLINKSQL, backUp.getSqlId());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SavePointServiceImpl.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.core.service.impl;
 
-import org.apache.streampark.common.util.AssertUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.domain.Constant;
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.exception.InternalException;
@@ -67,7 +67,7 @@ public boolean save(SavePoint entity) {
 
   private void expire(SavePoint entity) {
     FlinkEnv flinkEnv = flinkEnvService.getByAppId(entity.getAppId());
-    AssertUtils.state(flinkEnv != null);
+    Utils.required(flinkEnv != null);
     int cpThreshold =
         Integer.parseInt(
             flinkEnv.convertFlinkYamlAsMap().getOrDefault("state.checkpoints.num-retained", "5"));

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SqlCompleteServiceImpl.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.core.service.impl;
 
-import org.apache.streampark.common.util.AssertUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.core.service.SqlCompleteService;
 
 import com.google.common.collect.Sets;
@@ -185,7 +185,7 @@ public void buildTree(String word, int count, TreeNode buildWay) {
         nowStep = nowStep.get(nowChar).getNext();
         loc += 1;
       }
-      AssertUtils.state(preNode != null);
+      Utils.required(preNode != null);
       preNode.setStop();
       preNode.setCount(count);
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkRESTAPIWatcher.java
Patch:
@@ -18,9 +18,9 @@
 package org.apache.streampark.console.core.task;
 
 import org.apache.streampark.common.enums.ExecutionMode;
-import org.apache.streampark.common.util.AssertUtils;
 import org.apache.streampark.common.util.HttpClientUtils;
 import org.apache.streampark.common.util.ThreadUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.common.util.YarnUtils;
 import org.apache.streampark.console.base.util.JacksonUtils;
 import org.apache.streampark.console.core.entity.Application;
@@ -207,7 +207,7 @@ private void doWatch() {
             final OptionState optionState = OPTIONING.get(key);
             try {
               // query status from flink rest api
-              AssertUtils.state(application.getId() != null);
+              Utils.required(application.getId() != null);
               getFromFlinkRestApi(application, stopFrom);
             } catch (Exception flinkException) {
               // query status from yarn rest api

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/RoleServiceImpl.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.system.service.impl;
 
-import org.apache.streampark.common.util.AssertUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.domain.Constant;
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.system.entity.Role;
@@ -86,7 +86,7 @@ public void deleteRole(Long roleId) {
                 () ->
                     new IllegalArgumentException(String.format("Role id [%s] not found", roleId)));
     List<Long> userIdsByRoleId = memberService.findUserIdsByRoleId(roleId);
-    AssertUtils.isTrue(
+    Utils.required(
         userIdsByRoleId == null || userIdsByRoleId.isEmpty(),
         String.format(
             "There are some users are bound to role %s , please unbind it first.",

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/TeamServiceImpl.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.system.service.impl;
 
-import org.apache.streampark.common.util.AssertUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.exception.ApiAlertException;
 import org.apache.streampark.console.core.enums.UserType;
@@ -129,7 +129,7 @@ public void updateTeam(Team team) {
                 () ->
                     new IllegalArgumentException(
                         String.format("Team id [id=%s] not found", team.getId())));
-    AssertUtils.isTrue(
+    Utils.required(
         oldTeam.getTeamName().equals(team.getTeamName()), "Team name cannot be changed.");
     oldTeam.setDescription(team.getDescription());
     oldTeam.setModifyTime(new Date());

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-hbase/src/main/scala/org/apache/streampark/flink/connector/hbase/source/HBaseJavaSource.java
Patch:
@@ -41,8 +41,8 @@ public DataStreamSource<T> getDataStream(HBaseQueryFunction<T> queryFunction,
                                              HBaseResultFunction<T> resultFunction,
                                              RunningFunction runningFunc) {
 
-        Utils.require(queryFunction != null, "queryFunction must not be null");
-        Utils.require(resultFunction != null, "resultFunction must not be null");
+        Utils.required(queryFunction != null, "queryFunction must not be null");
+        Utils.required(resultFunction != null, "resultFunction must not be null");
         HBaseSourceFunction<T> sourceFunction = new HBaseSourceFunction<>(
             property,
             queryFunction,

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-jdbc/src/main/scala/org/apache/streampark/flink/connector/jdbc/sink/JdbcJavaSink.java
Patch:
@@ -17,8 +17,8 @@
 
 package org.apache.streampark.flink.connector.jdbc.sink;
 
-import org.apache.streampark.common.util.AssertUtils;
 import org.apache.streampark.common.util.ConfigUtils;
+import org.apache.streampark.common.util.Utils;
 import org.apache.streampark.flink.connector.function.TransformFunction;
 import org.apache.streampark.flink.connector.jdbc.internal.JdbcSinkFunction;
 import org.apache.streampark.flink.core.scala.StreamingContext;
@@ -55,7 +55,7 @@ public JdbcJavaSink<T> sql(TransformFunction<T, String> func) {
     }
 
     public DataStreamSink<T> sink(DataStream<T> dataStream) {
-        AssertUtils.notNull(sqlFunc);
+        Utils.required(sqlFunc != null, "transformFunction can not be null");
         this.jdbc = this.jdbc == null ? ConfigUtils.getJdbcConf(context.parameter().toMap(), alias) : this.jdbc;
         JdbcSinkFunction<T> sinkFun = new JdbcSinkFunction<>(this.jdbc, this.sqlFunc);
         return dataStream.addSink(sinkFun);

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-jdbc/src/main/scala/org/apache/streampark/flink/connector/jdbc/source/JdbcJavaSource.java
Patch:
@@ -53,8 +53,8 @@ public DataStreamSource<T> getDataStream(SQLQueryFunction<T> queryFunction,
                                              SQLResultFunction<T> resultFunction,
                                              RunningFunction runningFunc) {
 
-        Utils.require(queryFunction != null, "queryFunction must not be null");
-        Utils.require(resultFunction != null, "resultFunction must not be null");
+        Utils.required(queryFunction != null, "queryFunction must not be null");
+        Utils.required(resultFunction != null, "resultFunction must not be null");
         this.jdbc = this.jdbc == null ? ConfigUtils.getJdbcConf(context.parameter().toMap(), alias) : this.jdbc;
         JdbcSourceFunction<T> sourceFunction = new JdbcSourceFunction<>(jdbc, queryFunction, resultFunction, runningFunc, null);
         return context.getJavaEnv().addSource(sourceFunction);

File: streampark-flink/streampark-flink-connector/streampark-flink-connector-mongo/src/main/scala/org/apache/streampark/flink/connector/mongo/source/MongoJavaSource.java
Patch:
@@ -42,9 +42,9 @@ public DataStreamSource<T> getDataStream(String collectionName,
                                              MongoResultFunction<T> resultFunction,
                                              RunningFunction runningFunc) {
 
-        Utils.require(collectionName != null, "collectionName must not be null");
-        Utils.require(queryFunction != null, "queryFunction must not be null");
-        Utils.require(resultFunction != null, "resultFunction must not be null");
+        Utils.required(collectionName != null, "collectionName must not be null");
+        Utils.required(queryFunction != null, "queryFunction must not be null");
+        Utils.required(resultFunction != null, "resultFunction must not be null");
         MongoSourceFunction<T> sourceFunction = new MongoSourceFunction<>(collectionName, property, queryFunction, resultFunction, runningFunc, null);
         return context.getJavaEnv().addSource(sourceFunction);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ProjectController.java
Patch:
@@ -20,6 +20,7 @@
 import org.apache.streampark.common.util.AssertUtils;
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.domain.RestResponse;
+import org.apache.streampark.console.core.annotation.AppUpdated;
 import org.apache.streampark.console.core.entity.Project;
 import org.apache.streampark.console.core.enums.GitAuthorizedError;
 import org.apache.streampark.console.core.service.ProjectService;
@@ -53,6 +54,7 @@ public RestResponse create(Project project) {
     return projectService.create(project);
   }
 
+  @AppUpdated
   @PostMapping("update")
   @RequiresPermissions("project:update")
   public RestResponse update(Project project) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1361,6 +1361,7 @@ public void start(Application appParam, boolean auto) throws Exception {
     final Application application = getById(appParam.getId());
 
     AssertUtils.state(application != null);
+    application.setAllowNonRestored(appParam.getAllowNonRestored());
 
     FlinkEnv flinkEnv = flinkEnvService.getByIdOrDefault(application.getVersionId());
     if (flinkEnv == null) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ProjectController.java
Patch:
@@ -133,7 +133,8 @@ public RestResponse listConf(Project project) {
   }
 
   @PostMapping("select")
-  public RestResponse select() {
-    return RestResponse.success().data(projectService.list());
+  public RestResponse select(@RequestParam Long teamId) {
+    List<Project> list = projectService.findByTeamId(teamId);
+    return RestResponse.success().data(list);
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ProjectService.java
Patch:
@@ -40,6 +40,8 @@ public interface ProjectService extends IService<Project> {
 
   Boolean existsByTeamId(Long teamId);
 
+  List<Project> findByTeamId(Long teamId);
+
   void build(Long id) throws Exception;
 
   RestResponse getBuildLog(Long id, Long startOffset);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkRESTAPIWatcher.java
Patch:
@@ -266,9 +266,6 @@ private void doWatch() {
   private void getFromFlinkRestApi(Application application, StopFrom stopFrom) throws Exception {
     FlinkCluster flinkCluster = getFlinkCluster(application);
     JobsOverview jobsOverview = httpJobsOverview(application, flinkCluster);
-    if (jobsOverview == null) {
-      return;
-    }
     Optional<JobsOverview.Job> optional;
     ExecutionMode execMode = application.getExecutionModeEnum();
     if (ExecutionMode.YARN_APPLICATION.equals(execMode)

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/domain/Constant.java
Patch:
@@ -30,4 +30,5 @@ public class Constant {
   public static final String TYPE_MENU = "0";
   public static final String APP_MENU_ID = "100015";
   public static final String APP_DETAIL_MENU_ID = "100018";
+  public static final Long FLINK_SAMPLE_APP_ID = 100000L;
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/LogClientService.java
Patch:
@@ -23,7 +23,6 @@
 import org.springframework.stereotype.Component;
 
 import java.io.File;
-import java.io.FileNotFoundException;
 import java.nio.file.Files;
 import java.nio.file.Paths;
 import java.util.List;
@@ -44,9 +43,8 @@ public String rollViewLog(String path, int offset, int limit) {
           lines.forEach(line -> builder.append(line).append("\r\n"));
           return builder.toString();
         }
-      } else {
-        throw new FileNotFoundException("file path: " + path + " not exists ");
       }
+      return null;
     } catch (Exception e) {
       throw new ApiDetailException("roll view log error: " + e);
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/WebMvcConfig.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.base.config;
 
-import org.apache.streampark.console.base.interceptor.FileHeaderCheckInterceptor;
+import org.apache.streampark.console.base.interceptor.UploadFileTypeInterceptor;
 
 import com.fasterxml.jackson.databind.DeserializationFeature;
 import com.fasterxml.jackson.databind.ObjectMapper;
@@ -42,7 +42,7 @@
 @Configuration
 public class WebMvcConfig implements WebMvcConfigurer {
 
-  @Autowired private FileHeaderCheckInterceptor fileHeaderCheckInterceptor;
+  @Autowired private UploadFileTypeInterceptor uploadFileTypeInterceptor;
 
   @Override
   public void extendMessageConverters(List<HttpMessageConverter<?>> converters) {
@@ -82,6 +82,6 @@ public MappingJackson2HttpMessageConverter jackson2HttpMessageConverter() {
 
   @Override
   public void addInterceptors(InterceptorRegistry registry) {
-    registry.addInterceptor(fileHeaderCheckInterceptor).addPathPatterns("/flink/app/upload");
+    registry.addInterceptor(uploadFileTypeInterceptor).addPathPatterns("/flink/app/upload");
   }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationController.java
Patch:
@@ -22,7 +22,6 @@
 import org.apache.streampark.console.base.domain.ApiDocConstant;
 import org.apache.streampark.console.base.domain.RestRequest;
 import org.apache.streampark.console.base.domain.RestResponse;
-import org.apache.streampark.console.base.exception.ApplicationException;
 import org.apache.streampark.console.base.exception.InternalException;
 import org.apache.streampark.console.base.util.MoreFutures;
 import org.apache.streampark.console.core.annotation.ApiAccess;
@@ -373,7 +372,7 @@ public RestResponse checkjar(String jar) {
 
   @PostMapping("upload")
   @RequiresPermissions("app:create")
-  public RestResponse upload(MultipartFile file) throws ApplicationException {
+  public RestResponse upload(MultipartFile file) throws Exception {
     String uploadPath = applicationService.upload(file);
     return RestResponse.success(uploadPath);
   }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationService.java
Patch:
@@ -73,7 +73,7 @@ public interface ApplicationService extends IService<Application> {
 
   void tailMvnDownloading(Long id);
 
-  String upload(MultipartFile file) throws ApplicationException;
+  String upload(MultipartFile file) throws Exception;
 
   /** set the latest to Effective, it will really become the current effective */
   void toEffective(Application application);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/FlinkEnv.java
Patch:
@@ -17,7 +17,7 @@
 
 package org.apache.streampark.console.core.entity;
 
-import org.apache.streampark.common.domain.FlinkVersion;
+import org.apache.streampark.common.conf.FlinkVersion;
 import org.apache.streampark.common.util.DeflaterUtils;
 import org.apache.streampark.common.util.PropertiesUtils;
 import org.apache.streampark.console.base.exception.ApiDetailException;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ApplicationMapper.java
Patch:
@@ -32,7 +32,7 @@ public interface ApplicationMapper extends BaseMapper<Application> {
 
   Application getApp(@Param("application") Application application);
 
-  void updateTracking(@Param("application") Application application);
+  void persistMetrics(@Param("application") Application application);
 
   List<Application> getByTeamId(@Param("teamId") Long teamId);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/metrics/yarn/YarnAppInfo.java
Patch:
@@ -21,7 +21,7 @@
 import lombok.Data;
 
 @Data
-public class AppInfo {
+public class YarnAppInfo {
 
   private App app;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationService.java
Patch:
@@ -57,7 +57,7 @@ public interface ApplicationService extends IService<Application> {
 
   void cancel(Application app) throws Exception;
 
-  void updateTracking(Application application);
+  void persistMetrics(Application application);
 
   void clean(Application app);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/SavePointService.java
Patch:
@@ -27,7 +27,7 @@
 
 public interface SavePointService extends IService<SavePoint> {
 
-  void obsolete(Long appId);
+  void expire(Long appId);
 
   SavePoint getLatest(Long id);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -454,7 +454,7 @@ public Map<Long, PipelineStatus> listPipelineStatus(List<Long> appIds) {
       return Collections.emptyMap();
     }
     return appBuildPipelines.stream()
-        .collect(Collectors.toMap(e -> e.getAppId(), e -> e.getPipelineStatus()));
+        .collect(Collectors.toMap(AppBuildPipeline::getAppId, AppBuildPipeline::getPipelineStatus));
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -31,7 +31,7 @@
 import org.apache.streampark.console.core.service.CommonService;
 import org.apache.streampark.console.core.service.FlinkClusterService;
 import org.apache.streampark.console.core.service.FlinkEnvService;
-import org.apache.streampark.console.core.task.FlinkTrackingTask;
+import org.apache.streampark.console.core.task.FlinkRESTAPIWatcher;
 import org.apache.streampark.flink.submit.FlinkSubmitter;
 import org.apache.streampark.flink.submit.bean.DeployRequest;
 import org.apache.streampark.flink.submit.bean.DeployResponse;
@@ -183,7 +183,7 @@ public void start(FlinkCluster cluster) {
         updateWrapper.set(FlinkCluster::getClusterState, ClusterState.STARTED.getValue());
         updateWrapper.set(FlinkCluster::getException, null);
         update(updateWrapper);
-        FlinkTrackingTask.removeFlinkCluster(flinkCluster);
+        FlinkRESTAPIWatcher.removeFlinkCluster(flinkCluster);
       } else {
         throw new ApiAlertException(
             "deploy cluster failed, unknown reason，please check you params or StreamPark error log");

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -20,7 +20,6 @@
 import org.apache.streampark.console.core.entity.FlinkEnv;
 import org.apache.streampark.console.core.mapper.FlinkEnvMapper;
 import org.apache.streampark.console.core.service.FlinkEnvService;
-import org.apache.streampark.console.core.task.FlinkTrackingTask;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
 import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;
@@ -74,7 +73,6 @@ public void update(FlinkEnv version) throws IOException {
       flinkEnv.doSetVersion();
     }
     updateById(flinkEnv);
-    FlinkTrackingTask.getFlinkEnvMap().put(flinkEnv.getId(), flinkEnv);
   }
 
   @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -106,7 +106,7 @@ public void setCandidate(CandidateType candidateType, Long appId, Long sqlId) {
     this.update(
         new LambdaUpdateWrapper<FlinkSql>()
             .eq(FlinkSql::getAppId, appId)
-            .set(FlinkSql::getCandidate, 0));
+            .set(FlinkSql::getCandidate, CandidateType.NONE.get()));
 
     this.update(
         new LambdaUpdateWrapper<FlinkSql>()

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/SavePointServiceImpl.java
Patch:
@@ -50,7 +50,7 @@ public class SavePointServiceImpl extends ServiceImpl<SavePointMapper, SavePoint
   @Autowired private FlinkEnvService flinkEnvService;
 
   @Override
-  public void obsolete(Long appId) {
+  public void expire(Long appId) {
     SavePoint savePoint = new SavePoint();
     savePoint.setLatest(false);
     LambdaQueryWrapper<SavePoint> queryWrapper =
@@ -61,7 +61,7 @@ public void obsolete(Long appId) {
   @Override
   public boolean save(SavePoint entity) {
     this.expire(entity);
-    this.obsolete(entity.getAppId());
+    this.expire(entity.getAppId());
     return super.save(entity);
   }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkK8sChangeEventListener.java
Patch:
@@ -54,7 +54,7 @@
 
 /** Event Listener for K8sFlinkTrackMonitor */
 @Component
-public class K8sFlinkChangeEventListener {
+public class FlinkK8sChangeEventListener {
 
   @Lazy @Autowired private ApplicationService applicationService;
 
@@ -88,7 +88,7 @@ public void subscribeJobStatusChange(FlinkJobStatusChangeEvent event) {
     }
     // update application record
     Application newApp = getUpdateAppWithJobStatusCV(app, jobStatus);
-    applicationService.updateTracking(newApp);
+    applicationService.persistMetrics(newApp);
 
     // email alerts when necessary
     FlinkAppState state = FlinkAppState.of(newApp.getState());
@@ -129,7 +129,7 @@ public void subscribeMetricsChange(FlinkClusterMetricChangeEvent event) {
     newApp.setTotalSlot(metrics.totalSlot());
     newApp.setAvailableSlot(metrics.availableSlot());
 
-    applicationService.updateTracking(newApp);
+    applicationService.persistMetrics(newApp);
   }
 
   @SuppressWarnings("UnstableApiUsage")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationController.java
Patch:
@@ -174,7 +174,6 @@ public RestResponse revoke(Application app) {
         @ApiImplicitParam(name = "id", value = "app Id", required = true, paramType = "query", dataTypeClass = Long.class),
         @ApiImplicitParam(name = "savePointed", value = "restored app from the savepoint or latest checkpoint", required = true, paramType = "query", dataTypeClass = Boolean.class, defaultValue = "false"),
         @ApiImplicitParam(name = "savePoint", value = "savepoint or checkpoint path", required = true, paramType = "query", dataTypeClass = String.class, defaultValue = ""),
-        @ApiImplicitParam(name = "flameGraph", value = "whether the flame graph support", required = true, paramType = "query", dataTypeClass = Boolean.class, defaultValue = "false"),
         @ApiImplicitParam(name = "allowNonRestored", value = "ignore savepoint then cannot be restored", required = true, paramType = "query", dataTypeClass = Boolean.class, defaultValue = "false")})
     @PostMapping(value = "start", consumes = "application/x-www-form-urlencoded")
     @RequiresPermissions("app:start")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -168,7 +168,6 @@ public class Application implements Serializable {
     private Integer executionMode;
     private String dynamicProperties;
     private Integer appType;
-    private Boolean flameGraph;
 
     /**
      * determine if tracking status

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/AccessTokenController.java
Patch:
@@ -123,7 +123,6 @@ public RestResponse copyRestApiCurl(@NotBlank(message = "{required}") String app
         if ("/flink/app/start".equalsIgnoreCase(path)) {
             resultCURL = curlBuilder
                 .addFormData("allowNonRestored", "false")
-                .addFormData("flameGraph", "false")
                 .addFormData("savePoint", "")
                 .addFormData("savePointed", "false")
                 .addFormData("id", appId)

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/ApplicationServiceTest.java
Patch:
@@ -64,7 +64,6 @@ void revokeTest() {
         app.setResolveOrder(0);
         app.setExecutionMode(4);
         app.setAppType(2);
-        app.setFlameGraph(false);
         app.setTracking(0);
         app.setJar("SocketWindowWordCount.jar");
         app.setJarCheckSum(1553115525L);
@@ -86,7 +85,6 @@ void revokeTest() {
     void start() throws Exception {
         Application application = new Application();
         application.setId(1304056220683497473L);
-        application.setFlameGraph(false);
         application.setRestart(false);
         application.setSavePointed(false);
         application.setAllowNonRestored(false);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/enums/ResourceFrom.java
Patch:
@@ -39,7 +39,7 @@ public enum ResourceFrom implements Serializable {
     }
 
     public static ResourceFrom of(Integer value) {
-        return Arrays.stream(values()).filter((x) -> x.value == value).findFirst().orElse(null);
+        return Arrays.stream(values()).filter((x) -> x.value.equals(value)).findFirst().orElse(null);
     }
 
     public Integer getValue() {

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/VariableServiceTest.java
Patch:
@@ -54,7 +54,7 @@ void testNormalReplace() {
         variable.setTeamId(teamId);
         variableService.save(variable);
         Variable findVariable = variableService.findByVariableCode(teamId, variableCode);
-        Assertions.assertTrue(findVariable != null);
+        Assertions.assertNotNull(findVariable);
         String paramWithPlaceholders = "--kafka.brokers ${" + variableCode + "}";
         String realParam = variableService.replaceVariable(teamId, paramWithPlaceholders);
         Assertions.assertEquals(realParam, "--kafka.brokers " + variableVariable);
@@ -78,7 +78,7 @@ void testAbnormalReplace() {
         variable.setTeamId(teamId);
         variableService.save(variable);
         Variable findVariable = variableService.findByVariableCode(teamId, variableCode);
-        Assertions.assertTrue(findVariable != null);
+        Assertions.assertNotNull(findVariable);
         String paramWithPlaceholders = "--kafka.brokers ${" + variableCode + "}";
         String realParam = variableService.replaceVariable(teamId, paramWithPlaceholders);
         Assertions.assertNotEquals("--kafka.brokers " + variableVariable, realParam);

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/entity/GitTest.java
Patch:
@@ -18,6 +18,7 @@
 package org.apache.streampark.console.core.entity;
 
 import org.apache.streampark.console.core.enums.GitAuthorizedError;
+import org.apache.streampark.console.core.enums.GitProtocol;
 
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
@@ -30,7 +31,8 @@ class GitTest {
 
     @BeforeEach
     void before() {
-        project.setUrl("https://github.com/apache/incubator-streampark-quickstart");
+        project.setUrl("https://github.com/apache/incubator-streampark.git");
+        project.setGitProtocol(GitProtocol.HTTPS.getValue());
     }
 
     @Test

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -163,7 +163,7 @@ public boolean buildApplication(@Nonnull Application app) {
         // save snapshot of pipeline to db when status of pipeline was changed.
         pipeline.registerWatcher(new PipeWatcher() {
             @Override
-            public void onStart(PipeSnapshot snapshot) throws Exception {
+            public void onStart(PipeSnapshot snapshot) {
                 AppBuildPipeline buildPipeline = AppBuildPipeline.fromPipeSnapshot(snapshot).setAppId(app.getId());
                 saveEntity(buildPipeline);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1177,7 +1177,7 @@ public void cancel(Application appParam) throws Exception {
                 String.format("The clusterId=%s cannot be find, maybe the clusterId is wrong or " +
                         "the cluster has been deleted. Please contact the Admin.",
                     application.getFlinkClusterId()));
-            URI activeAddress = cluster.getActiveAddress();
+            URI activeAddress = cluster.getRemoteURI();
             properties.put(RestOptions.ADDRESS.key(), activeAddress.getHost());
             properties.put(RestOptions.PORT.key(), activeAddress.getPort());
         }
@@ -1550,7 +1550,7 @@ private Map<String, Object> getProperties(Application application) {
             AssertUtils.state(cluster != null,
                 String.format("The clusterId=%s cannot be find, maybe the clusterId is wrong or " +
                     "the cluster has been deleted. Please contact the Admin.", application.getFlinkClusterId()));
-            URI activeAddress = cluster.getActiveAddress();
+            URI activeAddress = cluster.getRemoteURI();
             properties.put(RestOptions.ADDRESS.key(), activeAddress.getHost());
             properties.put(RestOptions.PORT.key(), activeAddress.getPort());
         } else if (ExecutionMode.isYarnMode(application.getExecutionModeEnum())) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkTrackingTask.java
Patch:
@@ -749,7 +749,7 @@ private JobsOverview httpJobsOverview(Application application, FlinkCluster flin
             return jobsOverview;
         } else if (ExecutionMode.REMOTE.equals(execMode) || ExecutionMode.YARN_SESSION.equals(execMode)) {
             if (application.getJobId() != null) {
-                String remoteUrl = flinkCluster.getActiveAddress().toURL() + "/" + flinkUrl;
+                String remoteUrl = flinkCluster.getAddress() + "/" + flinkUrl;
                 JobsOverview jobsOverview = httpRestRequest(remoteUrl, JobsOverview.class);
                 if (jobsOverview != null) {
                     List<JobsOverview.Job> jobs = jobsOverview.getJobs().stream().filter(x -> x.getId().equals(application.getJobId())).collect(Collectors.toList());
@@ -776,7 +776,7 @@ private CheckPoints httpCheckpoints(Application application, FlinkCluster flinkC
             return yarnRestRequest(reqURL, CheckPoints.class);
         } else if (ExecutionMode.REMOTE.equals(execMode) || ExecutionMode.YARN_SESSION.equals(execMode)) {
             if (application.getJobId() != null) {
-                String remoteUrl = flinkCluster.getActiveAddress().toURL() + "/" + String.format(flinkUrl, application.getJobId());
+                String remoteUrl = flinkCluster.getAddress() + "/" + String.format(flinkUrl, application.getJobId());
                 return httpRestRequest(remoteUrl, CheckPoints.class);
             }
         }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1254,6 +1254,9 @@ public void cancel(Application appParam) throws Exception {
                 }
             }
         ).whenComplete((t, e) -> {
+            if (isKubernetesApp(application)) {
+                IngressController.deleteIngress(application.getK8sNamespace(), application.getJobName());
+            }
             cancelFuture.cancel(true);
             cancelFutureMap.remove(application.getId());
         });

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/entity/User.java
Patch:
@@ -85,6 +85,8 @@ public class User implements Serializable {
 
     private String avatar;
 
+    private transient String oldPassword;
+
     private transient String sortField;
 
     private transient String sortOrder;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/K8sFlinkChangeEventListener.java
Patch:
@@ -100,7 +100,7 @@ public void subscribeJobStatusChange(FlinkJobStatusChangeEvent event) {
         applicationService.updateTracking(newApp);
 
         // email alerts when necessary
-        FlinkAppState state = FlinkAppState.of(app.getState());
+        FlinkAppState state = FlinkAppState.of(newApp.getState());
         if (FlinkAppState.FAILED.equals(state) || FlinkAppState.LOST.equals(state)
             || FlinkAppState.RESTARTING.equals(state) || FlinkAppState.FINISHED.equals(state)) {
             IngressController.deleteIngress(app.getClusterId(), app.getK8sNamespace());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -717,7 +717,7 @@ public Long copy(Application appParam) {
 
         newApp.setJobName(jobName);
         newApp.setClusterId(ExecutionMode.isSessionMode(oldApp.getExecutionModeEnum()) ? oldApp.getClusterId() : jobName);
-        newApp.setArgs(oldApp.getArgs());
+        newApp.setArgs(appParam.getArgs() != null ? appParam.getArgs() : oldApp.getArgs());
         newApp.setVersionId(oldApp.getVersionId());
 
         newApp.setFlinkClusterId(oldApp.getFlinkClusterId());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/FlinkClusterMapper.java
Patch:
@@ -24,7 +24,7 @@
 
 public interface FlinkClusterMapper extends BaseMapper<FlinkCluster> {
 
-    Boolean existsByClusterId(@Param("clusterId") String clusterId);
+    Boolean existsByClusterId(@Param("clusterId") String clusterId, @Param("id") Long id);
 
     Boolean existsByClusterName(@Param("clusterName") String clusterName, @Param("id") Long id);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/ApplicationService.java
Patch:
@@ -98,4 +98,7 @@ public interface ApplicationService extends IService<Application> {
 
     void forcedStop(Application app);
 
+    boolean existsRunningJobByClusterId(Long clusterId);
+
+    boolean existsJobByClusterId(Long id);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -73,7 +73,6 @@
 import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;
 import com.github.benmanes.caffeine.cache.Cache;
 import com.github.benmanes.caffeine.cache.Caffeine;
-import com.google.common.collect.Maps;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.collections.CollectionUtils;
 import org.springframework.beans.factory.annotation.Autowired;
@@ -84,6 +83,7 @@
 import javax.annotation.Nonnull;
 
 import java.io.File;
+import java.util.Collections;
 import java.util.List;
 import java.util.Map;
 import java.util.Optional;
@@ -442,14 +442,14 @@ public boolean allowToBuildNow(@Nonnull Long appId) {
     @Override
     public Map<Long, PipelineStatus> listPipelineStatus(List<Long> appIds) {
         if (CollectionUtils.isEmpty(appIds)) {
-            return Maps.newHashMap();
+            return Collections.emptyMap();
         }
         LambdaQueryWrapper<AppBuildPipeline> queryWrapper = new LambdaQueryWrapper<AppBuildPipeline>()
             .in(AppBuildPipeline::getAppId, appIds);
 
         List<AppBuildPipeline> appBuildPipelines = baseMapper.selectList(queryWrapper);
         if (CollectionUtils.isEmpty(appBuildPipelines)) {
-            return Maps.newHashMap();
+            return Collections.emptyMap();
         }
         return appBuildPipelines.stream().collect(Collectors.toMap(e -> e.getAppId(), e -> e.getPipelineStatus()));
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/config/MybatisConfig.java
Patch:
@@ -27,6 +27,7 @@
 import com.baomidou.mybatisplus.core.toolkit.GlobalConfigUtils;
 import com.baomidou.mybatisplus.extension.plugins.MybatisPlusInterceptor;
 import com.baomidou.mybatisplus.extension.plugins.inner.PaginationInnerInterceptor;
+import org.apache.ibatis.type.JdbcType;
 import org.mybatis.spring.annotation.MapperScan;
 import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
 import org.springframework.context.annotation.Bean;
@@ -79,7 +80,7 @@ public MybatisPlusPropertiesCustomizer mybatisPlusPropertiesCustomizer() {
             properties.setTypeAliasesPackage("org.apache.streampark.console.*.entity");
             properties.setMapperLocations(new String[]{"classpath:mapper/*/*.xml"});
             MybatisConfiguration mybatisConfiguration = new MybatisConfiguration();
-            mybatisConfiguration.setJdbcTypeForNull(null);
+            mybatisConfiguration.setJdbcTypeForNull(JdbcType.NULL);
             properties.setConfiguration(mybatisConfiguration);
             GlobalConfig globalConfig = GlobalConfigUtils.getGlobalConfig(mybatisConfiguration);
             GlobalConfig.DbConfig dbConfig = globalConfig.getDbConfig();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Setting.java
Patch:
@@ -17,7 +17,9 @@
 
 package org.apache.streampark.console.core.entity;
 
+import com.baomidou.mybatisplus.annotation.FieldStrategy;
 import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableField;
 import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import lombok.Data;
@@ -37,6 +39,7 @@ public class Setting implements Serializable {
     @TableId(type = IdType.INPUT)
     private String settingKey;
 
+    @TableField(updateStrategy = FieldStrategy.IGNORED)
     private String settingValue;
 
     private Integer type;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -639,7 +639,7 @@ public Long copy(Application appParam) {
 
         newApp.setJobName(jobName);
         newApp.setClusterId(ExecutionMode.isSessionMode(oldApp.getExecutionModeEnum()) ? oldApp.getClusterId() : jobName);
-        newApp.setArgs(appParam.getArgs());
+        newApp.setArgs(oldApp.getArgs());
         newApp.setVersionId(oldApp.getVersionId());
 
         newApp.setFlinkClusterId(oldApp.getFlinkClusterId());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1090,7 +1090,7 @@ public void cancel(Application appParam) throws Exception {
         CancelRequest cancelRequest = new CancelRequest(
             flinkEnv.getFlinkVersion(),
             ExecutionMode.of(application.getExecutionMode()),
-            application.getAppId(),
+            application.getClusterId(),
             application.getJobId(),
             appParam.getSavePointed(),
             appParam.getDrain(),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ProjectMapper.java
Patch:
@@ -28,6 +28,8 @@ public interface ProjectMapper extends BaseMapper<Project> {
 
     void updateBuildState(@Param("id") Long id, @Param("state") Integer buildState);
 
+    void updateBuildTime(@Param("id") Long id);
+
     IPage<Project> page(Page<Project> page, @Param("project") Project project);
 
     Boolean existsByTeamId(@Param("teamId") Long teamId);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/ProjectBuildTask.java
Patch:
@@ -75,6 +75,7 @@ protected void doRun() throws Throwable {
             return;
         }
         this.baseMapper.updateBuildState(project.getId(), BuildState.SUCCESSFUL.get());
+        this.baseMapper.updateBuildTime(project.getId());
         this.deploy(project);
         List<Application> applications = this.applicationService.getByProjectId(project.getId());
         // Update the deploy state

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/UserController.java
Patch:
@@ -166,7 +166,7 @@ public RestResponse initTeam(Long teamId, Long userId) {
         if (team == null) {
             return RestResponse.fail("teamId is invalid", ResponseCode.CODE_FAIL_ALERT);
         }
-        userService.setLatestTeam(teamId, userId);
+        userService.setLastTeam(teamId, userId);
         return RestResponse.success();
     }
 
@@ -180,7 +180,7 @@ public RestResponse setTeam(Long teamId) {
         User user = commonService.getCurrentUser();
 
         //1) set the latest team
-        userService.setLatestTeam(teamId, user.getUserId());
+        userService.setLastTeam(teamId, user.getUserId());
 
         //2) get latest userInfo
         user.dataMasking();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/mapper/UserMapper.java
Patch:
@@ -34,6 +34,8 @@ public interface UserMapper extends BaseMapper<User> {
 
     List<User> findByAppOwner(@Param("teamId") Long teamId);
 
-    void unbindTeam(@Param("userId") Long userId);
+    void clearLastTeamByUserId(@Param("userId") Long userId);
+
+    void clearLastTeamByTeamId(@Param("teamId") Long teamId);
 
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/MemberServiceImpl.java
Patch:
@@ -141,7 +141,7 @@ public void deleteMember(Member memberArg) {
         Member member = Optional.ofNullable(this.getById(memberArg.getId()))
             .orElseThrow(() -> new ApiAlertException(String.format("The member [id=%s] not found", memberArg.getId())));
         this.removeById(member);
-        userService.unbindTeam(member.getUserId(), member.getTeamId());
+        userService.clearLastTeam(member.getUserId(), member.getTeamId());
     }
 
     @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/TeamServiceImpl.java
Patch:
@@ -115,6 +115,7 @@ public void deleteTeam(Long teamId) {
         }
 
         memberService.deleteByTeamId(teamId);
+        userService.clearLastTeam(teamId);
         this.removeById(teamId);
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/PassportController.java
Patch:
@@ -97,7 +97,7 @@ private RestResponse login(String username, String password, User user) throws E
         userService.fillInTeam(user);
 
         //no team.
-        if (user.getTeamId() == null) {
+        if (user.getLastTeamId() == null) {
             return RestResponse.success().data(user.getUserId()).put("code", ResponseCode.CODE_FORBIDDEN);
         }
 
@@ -110,7 +110,7 @@ private RestResponse login(String username, String password, User user) throws E
         JWTToken jwtToken = new JWTToken(token, expireTimeStr);
         String userId = RandomStringUtils.randomAlphanumeric(20);
         user.setId(userId);
-        Map<String, Object> userInfo = userService.generateFrontendUserInfo(user, user.getTeamId(), jwtToken);
+        Map<String, Object> userInfo = userService.generateFrontendUserInfo(user, user.getLastTeamId(), jwtToken);
         return new RestResponse().data(userInfo);
     }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/entity/User.java
Patch:
@@ -101,7 +101,7 @@ public class User implements Serializable {
     /**
      * The last set teamId
      */
-    private Long teamId;
+    private Long lastTeamId;
 
     public void dataMasking() {
         String dataMask = ConfigConst.DEFAULT_DATAMASK_STRING();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/util/WebUtils.java
Patch:
@@ -76,7 +76,7 @@ public static String decryptToken(String encryptToken) {
      * @return underscore
      */
     public static String camelToUnderscore(String value) {
-        if (StringUtils.isBlank(value)) {
+        if (StringUtils.isBlank(value) || value.contains("_")) {
             return value;
         }
         String[] arr = StringUtils.splitByCharacterTypeCamelCase(value);

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/enums/AlertTypeTest.java
Patch:
@@ -31,7 +31,7 @@ void decodeTest() {
 
     @Test
     void encodeTest() {
-        int level = AlertType.encode(Arrays.asList(AlertType.dingTalk, AlertType.email));
+        int level = AlertType.encode(Arrays.asList(AlertType.DING_TALK, AlertType.EMAIL));
         System.out.println(level);
     }
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/authentication/ShiroConfig.java
Patch:
@@ -61,6 +61,7 @@ public ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityMan
 
         filterChainDefinitionMap.put("/index.html", "anon");
         filterChainDefinitionMap.put("/assets/**", "anon");
+        filterChainDefinitionMap.put("/resource/**/**", "anon");
         filterChainDefinitionMap.put("/css/**", "anon");
         filterChainDefinitionMap.put("/fonts/**", "anon");
         filterChainDefinitionMap.put("/img/**", "anon");
@@ -70,6 +71,7 @@ public ShiroFilterFactoryBean shiroFilterFactoryBean(SecurityManager securityMan
         filterChainDefinitionMap.put("/*.png", "anon");
         filterChainDefinitionMap.put("/*.jpg", "anon");
         filterChainDefinitionMap.put("/*.less", "anon");
+        filterChainDefinitionMap.put("/*.ico", "anon");
         filterChainDefinitionMap.put("/", "anon");
         filterChainDefinitionMap.put("/**", "jwt");
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/AppBuildPipeline.java
Patch:
@@ -108,7 +108,7 @@ public AppBuildPipeline setPipeType(@Nonnull PipelineType pipeType) {
 
     @Nonnull
     @JsonIgnore
-    public PipelineStatus getPipeStatus() {
+    public PipelineStatus getPipelineStatus() {
         return PipelineStatus.of(pipeStatusCode);
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -435,7 +435,7 @@ public DockerResolvedSnapshot getDockerProgressDetailSnapshot(@Nonnull Long appI
     @Override
     public boolean allowToBuildNow(@Nonnull Long appId) {
         return getCurrentBuildPipeline(appId)
-            .map(pipeline -> PipelineStatus.running != pipeline.getPipeStatus())
+            .map(pipeline -> PipelineStatus.running != pipeline.getPipelineStatus())
             .orElse(true);
     }
 
@@ -451,9 +451,10 @@ public Map<Long, PipelineStatus> listPipelineStatus(List<Long> appIds) {
         if (CollectionUtils.isEmpty(rMaps)) {
             return Maps.newHashMap();
         }
+
         return rMaps.stream().collect(Collectors.toMap(
             e -> (Long) e.get("app_id"),
-            e -> PipelineStatus.of((Integer) e.get("pipe_status"))));
+            e -> PipelineStatus.of((Integer) e.get("pipeStatusCode"))));
     }
 
     @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/StreamParkConsoleBootstrap.java
Patch:
@@ -39,7 +39,7 @@
  *                                     /_/
  *
  *   WebSite:  https://streampark.apache.org
- *   GitHub :  https://github.com/apache/streampark
+ *   GitHub :  https://github.com/apache/incubator-streampark
  *
  *   [StreamPark] Make stream processing easier ô~ô!
  *

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/entity/GitTest.java
Patch:
@@ -30,7 +30,7 @@ class GitTest {
 
     @BeforeEach
     void before() {
-        project.setUrl("https://github.com/streamxhub/streampark-quickstart");
+        project.setUrl("https://github.com/apache/incubator-streampark-quickstart");
     }
 
     @Test

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/UserController.java
Patch:
@@ -92,8 +92,8 @@ public RestResponse updateUser(@Valid User user) throws Exception {
 
     @DeleteMapping("delete")
     @RequiresPermissions("user:delete")
-    public RestResponse deleteUsers(Long userId) {
-        this.userService.removeById(userId);
+    public RestResponse deleteUser(Long userId) throws Exception {
+        this.userService.deleteUser(userId);
         return RestResponse.success();
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/mapper/UserMapper.java
Patch:
@@ -33,4 +33,7 @@ public interface UserMapper extends BaseMapper<User> {
     List<User> getNoTokenUser();
 
     List<User> findByAppOwner(@Param("teamId") Long teamId);
+
+    void unbindTeam(@Param("userId") Long userId);
+
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/MemberService.java
Patch:
@@ -30,7 +30,7 @@ public interface MemberService extends IService<Member> {
 
     void deleteByRoleIds(String[] roleIds);
 
-    void deleteByUserIds(String[] userIds);
+    void deleteByUserId(Long userId);
 
     void deleteByTeamId(Long teamId);
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkClusterController.java
Patch:
@@ -77,7 +77,7 @@ public RestResponse update(FlinkCluster cluster) {
         flinkCluster.setClusterName(cluster.getClusterName());
         flinkCluster.setAddress(cluster.getAddress());
         flinkCluster.setExecutionMode(cluster.getExecutionMode());
-        flinkCluster.setProperties(cluster.getProperties());
+        flinkCluster.setDynamicProperties(cluster.getDynamicProperties());
         flinkCluster.setFlameGraph(cluster.getFlameGraph());
         flinkCluster.setFlinkImage(cluster.getFlinkImage());
         flinkCluster.setOptions(cluster.getOptions());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/FlinkCluster.java
Patch:
@@ -79,7 +79,7 @@ public class FlinkCluster implements Serializable {
 
     private Boolean k8sHadoopIntegration;
 
-    private String properties;
+    private String dynamicProperties;
 
     private Integer k8sRestExposedType;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -166,7 +166,7 @@ public ResponseResult start(FlinkCluster flinkCluster) {
             FlinkEnv flinkEnv = flinkEnvService.getById(flinkCluster.getVersionId());
             Map<String, Object> extraParameter = flinkCluster.getOptionMap();
             ResolveOrder resolveOrder = ResolveOrder.of(flinkCluster.getResolveOrder());
-            Map<String, String> properties = FlinkSubmitter.extractPropertiesAsJava(flinkCluster.getProperties());
+            Map<String, String> properties = FlinkSubmitter.extractDynamicPropertiesAsJava(flinkCluster.getDynamicProperties());
             DeployRequest deployRequest = new DeployRequest(
                 flinkEnv.getFlinkVersion(),
                 flinkCluster.getClusterId(),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -449,8 +449,9 @@ public boolean checkAlter(Application application) {
         if (!FlinkAppState.CANCELED.equals(state)) {
             return false;
         }
-        Long useId = FlinkTrackingTask.getCanceledJobUserId(appId);
-        return useId == null || application.getUserId().longValue() != FlinkTrackingTask.getCanceledJobUserId(appId).longValue();
+        long cancelUserId = FlinkTrackingTask.getCanceledJobUserId(appId).longValue();
+        long appUserId = application.getUserId().longValue();
+        return cancelUserId != -1 && cancelUserId != appUserId;
     }
 
     private void removeApp(Application application) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/FlinkClusterController.java
Patch:
@@ -73,6 +73,7 @@ public RestResponse create(FlinkCluster cluster) {
     public RestResponse update(FlinkCluster cluster) {
         FlinkCluster flinkCluster = flinkClusterService.getById(cluster.getId());
         flinkCluster.setClusterId(cluster.getClusterId());
+        flinkCluster.setVersionId(cluster.getVersionId());
         flinkCluster.setClusterName(cluster.getClusterName());
         flinkCluster.setAddress(cluster.getAddress());
         flinkCluster.setExecutionMode(cluster.getExecutionMode());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/K8sFlinkChangeEventListener.java
Patch:
@@ -164,9 +164,6 @@ private void updateApplicationWithJobStatusCV(Application app, JobStatusCV jobSt
         // update relevant fields of Application from JobStatusCV
         app.setJobId(jobStatus.jobId());
         app.setTotalTask(jobStatus.taskTotal());
-        if (FlinkJobState.isEndState(state)) {
-            app.setOptionState(OptionState.NONE.getValue());
-        }
 
         // corrective start-time / end-time / duration
         long preStartTime = app.getStartTime() != null ? app.getStartTime().getTime() : 0;
@@ -178,6 +175,8 @@ private void updateApplicationWithJobStatusCV(Application app, JobStatusCV jobSt
         long duration = jobStatus.duration();
 
         if (FlinkJobState.isEndState(state)) {
+            IngressController.deleteIngress(app.getJobName(), app.getK8sNamespace());
+            app.setOptionState(OptionState.NONE.getValue());
             if (endTime < startTime) {
                 endTime = System.currentTimeMillis();
             }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/AlertController.java
Patch:
@@ -134,7 +134,7 @@ public RestResponse sendAlert(Long id) throws AlertException {
         Date date = new Date();
         alertTemplate.setStartTime(DateUtils.format(date, DateUtils.fullFormat(), TimeZone.getDefault()));
         alertTemplate.setEndTime(DateUtils.format(date, DateUtils.fullFormat(), TimeZone.getDefault()));
-        alertTemplate.setDuration(DateUtils.toRichTimeDuration(0));
+        alertTemplate.setDuration("");
         boolean alert = alertService.alert(AlertConfigWithParams.of(alertConfigService.getById(id)), alertTemplate);
         return RestResponse.success(alert);
     }

File: streampark-console/streampark-console-service/src/test/java/org/apache/commons/mail/SendEmailTest.java
Patch:
@@ -99,22 +99,21 @@ private AlertTemplate getAlertBaseInfo(Application application) {
         } else {
             duration = application.getEndTime().getTime() - application.getStartTime().getTime();
         }
-        duration = duration / 1000 / 60;
         String format = "%s/proxy/%s/";
         String url = String.format(format, YarnUtils.getRMWebAppURL(), application.getAppId());
 
         AlertTemplate template = new AlertTemplate();
         template.setJobName(application.getJobName());
         template.setStartTime(DateUtils.format(application.getStartTime(), DateUtils.fullFormat(), TimeZone.getDefault()));
-        template.setDuration(DateUtils.toRichTimeDuration(duration));
+        template.setDuration(DateUtils.toDuration(duration));
         template.setLink(url);
         template.setEndTime(
             DateUtils.format(application.getEndTime() == null ? new Date() : application.getEndTime(), DateUtils.fullFormat(),
                 TimeZone.getDefault()));
         template.setRestart(application.isNeedRestartOnFailed());
         template.setRestartIndex(application.getRestartCount());
         template.setTotalRestart(application.getRestartSize());
-        template.setCpFailureRateInterval(DateUtils.toRichTimeDuration(application.getCpFailureRateInterval()));
+        template.setCpFailureRateInterval(DateUtils.toDuration(application.getCpFailureRateInterval() * 1000 * 60));
         template.setCpMaxFailureInterval(application.getCpMaxFailureInterval());
 
         return template;

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/alert/AlertServiceTest.java
Patch:
@@ -56,7 +56,7 @@ void before1() {
         Date date = new Date();
         alertTemplate.setStartTime(DateUtils.format(date, DateUtils.fullFormat(), TimeZone.getDefault()));
         alertTemplate.setEndTime(DateUtils.format(date, DateUtils.fullFormat(), TimeZone.getDefault()));
-        alertTemplate.setDuration(DateUtils.toRichTimeDuration(0));
+        alertTemplate.setDuration("");
     }
 
     void before2() {
@@ -72,7 +72,7 @@ void before2() {
         Date date = new Date();
         alertTemplate.setStartTime(DateUtils.format(date, DateUtils.fullFormat(), TimeZone.getDefault()));
         alertTemplate.setEndTime(DateUtils.format(date, DateUtils.fullFormat(), TimeZone.getDefault()));
-        alertTemplate.setDuration(DateUtils.toRichTimeDuration(0));
+        alertTemplate.setDuration("");
     }
 
     @Test

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationController.java
Patch:
@@ -335,9 +335,10 @@ public RestResponse checkSavepointPath(Application app) throws Exception {
     @PostMapping(value = "/detail")
     public RestResponse detail(@ApiParam("K8s name spaces") @RequestParam(value = "namespace", required = false) String namespace,
                                @ApiParam("Job name") @RequestParam(value = "jobName", required = false) String jobName,
+                               @ApiParam("Job id") @RequestParam(value = "jobId", required = false) String jobId,
                                @ApiParam("Number of log lines skipped loading") @RequestParam(value = "skipLineNum", required = false) Integer skipLineNum,
                                @ApiParam("Number of log lines loaded at once") @RequestParam(value = "limit", required = false) Integer limit) {
-        return RestResponse.success(MoreFutures.derefUsingDefaultTimeout(logService.queryLog(namespace, jobName, skipLineNum, limit)));
+        return RestResponse.success(MoreFutures.derefUsingDefaultTimeout(logService.queryLog(namespace, jobName, jobId, skipLineNum, limit)));
     }
 
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/LoggerService.java
Patch:
@@ -20,5 +20,5 @@
 import java.util.concurrent.CompletionStage;
 
 public interface LoggerService {
-    CompletionStage<String> queryLog(String namespac, String jobName, int skipLineNum, int limit);
+    CompletionStage<String> queryLog(String namespac, String jobName, String jobId, int skipLineNum, int limit);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -928,7 +928,7 @@ public void forcedStop(Application app) {
         CompletableFuture<CancelResponse> cancelFuture = cancelFutureMap.remove(app.getId());
         Application application = this.baseMapper.getApp(app);
         if (isKubernetesApp(application)) {
-            KubernetesDeploymentHelper.watchPodTerminatedLog(application.getK8sNamespace(), application.getJobName());
+            KubernetesDeploymentHelper.watchPodTerminatedLog(application.getK8sNamespace(), application.getJobName(), application.getJobId());
             KubernetesDeploymentHelper.deleteTaskDeployment(application.getK8sNamespace(), application.getJobName());
             KubernetesDeploymentHelper.deleteTaskConfigMap(application.getK8sNamespace(), application.getJobName());
             IngressController.deleteIngress(application.getK8sNamespace(), application.getJobName());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/VariableController.java
Patch:
@@ -82,7 +82,7 @@ public RestResponse variableList(@RequestParam Long teamId, String keyword) {
     }
 
     @PostMapping("dependApps")
-    @RequiresPermissions("variable:dependApps")
+    @RequiresPermissions("variable:depend_apps")
     public RestResponse dependApps(RestRequest restRequest, Variable variable) {
         IPage<Application> dependApps = variableService.dependAppsPage(variable, restRequest);
         return RestResponse.success(dependApps);
@@ -113,7 +113,7 @@ public RestResponse updateVariable(@Valid Variable variable) {
     }
 
     @PostMapping("showOriginal")
-    @RequiresPermissions("variable:showOriginal")
+    @RequiresPermissions("variable:show_original")
     public RestResponse showOriginal(@RequestParam Long id) {
         Variable v = this.variableService.getById(id);
         return RestResponse.success(v);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/MenuService.java
Patch:
@@ -41,8 +41,6 @@ public interface MenuService extends IService<Menu> {
 
     Map<String, Object> findMenus(Menu menu);
 
-    List<Menu> findMenuList(Menu menu);
-
     void createMenu(Menu menu);
 
     void updateMenu(Menu menu) throws Exception;

File: streampark-console/streampark-console-service/src/test/java/com/github/benmanes/caffeine/cache/RefreshCacheTest.java
Patch:
@@ -22,12 +22,12 @@
 import java.util.UUID;
 import java.util.concurrent.TimeUnit;
 
-public class RefreshCacheTest {
+class RefreshCacheTest {
 
     Cache<String, String> caffeine = null;
 
     @Test
-    public void cache() throws Exception {
+    void cache() throws Exception {
         if (caffeine == null) {
             caffeine = Caffeine.newBuilder()
                 .refreshAfterWrite(50, TimeUnit.MILLISECONDS)

File: streampark-console/streampark-console-service/src/test/java/org/apache/commons/mail/SendEmailTest.java
Patch:
@@ -35,14 +35,14 @@
 import java.util.Map;
 import java.util.TimeZone;
 
-public class SendEmailTest {
+class SendEmailTest {
 
     private Template template;
 
     private SenderEmail senderEmail;
 
     @BeforeEach
-    public void initConfig() throws Exception {
+    void initConfig() throws Exception {
         this.template = FreemarkerUtils.loadTemplateFile("alert-email.ftl");
         senderEmail = new SenderEmail();
         senderEmail.setFrom("****@domain.com");
@@ -54,7 +54,7 @@ public void initConfig() throws Exception {
     }
 
     @Test
-    public void alert() {
+    void alert() {
         Application application = new Application();
         application.setStartTime(new Date());
         application.setJobName("Test My Job");

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/base/util/ShaHashUtilsTest.java
Patch:
@@ -23,10 +23,10 @@
 /**
  * Test for {@link ShaHashUtils}
  */
-public class ShaHashUtilsTest {
+class ShaHashUtilsTest {
 
     @Test
-    public void testEncrypt() {
+    void testEncrypt() {
         String randomSalt = "rh8b1ojwog777yrg0daesf04gk";
         String encryptPassword = ShaHashUtils.encrypt(randomSalt, "streampark");
         Assertions.assertEquals("2513f3748847298ea324dffbf67fe68681dd92315bda830065facd8efe08f54f", encryptPassword);

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/entity/DependencyTest.java
Patch:
@@ -31,10 +31,10 @@
 import scala.collection.JavaConversions;
 
 @Slf4j
-public class DependencyTest {
+class DependencyTest {
 
     @Test
-    public void resolveMavenDependencies() {
+    void resolveMavenDependencies() {
         /**
          * <dependency>
          *      <groupId>org.apache.flink</groupId>

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/enums/AlertTypeTest.java
Patch:
@@ -22,7 +22,7 @@
 import java.util.Arrays;
 import java.util.List;
 
-public class AlertTypeTest {
+class AlertTypeTest {
     @Test
     void decodeTest() {
         List<AlertType> notifyTypes = AlertType.decode(5);

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/service/VariableServiceTest.java
Patch:
@@ -32,7 +32,7 @@
  */
 @ExtendWith(SpringExtension.class)
 @SpringBootTest(classes = StreamParkConsoleBootstrap.class, webEnvironment = SpringBootTest.WebEnvironment.RANDOM_PORT)
-public class VariableServiceTest {
+class VariableServiceTest {
 
     @Autowired
     private VariableService variableService;
@@ -41,7 +41,7 @@ public class VariableServiceTest {
      * Test whether the variable will be replaced normally
      */
     @Test
-    public void testNormalReplace() {
+    void testNormalReplace() {
         Long teamId = 100000L;
         Long userId = 100000L;
         String variableCode = "collect_kafka.brokers-520room";
@@ -64,7 +64,7 @@ public void testNormalReplace() {
      * Test whether the variable cannot be replaced normally
      */
     @Test
-    public void testAbnormalReplace() {
+    void testAbnormalReplace() {
         Long teamId = 100000L;
         Long userId = 100000L;
         // It contains a non-normal character '#' which should not be matched

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/system/authentication/JWTTest.java
Patch:
@@ -28,10 +28,10 @@
 import java.util.TimeZone;
 import java.util.UUID;
 
-public class JWTTest {
+class JWTTest {
 
     @Test
-    public void getExpireTime() {
+    void getExpireTime() {
         String userName = "black";
         String secret = UUID.randomUUID().toString();
         String expireTime = AccessToken.DEFAULT_EXPIRE_TIME;

File: streampark-flink/streampark-flink-repl/src/test/java/org/apache/streampark/flink/repl/test/FlinkInterpreterTest.java
Patch:
@@ -28,7 +28,7 @@
 
 import java.util.Properties;
 
-public class FlinkInterpreterTest {
+class FlinkInterpreterTest {
 
     private static final Logger LOGGER = LoggerFactory.getLogger(FlinkInterpreterTest.class);
 
@@ -54,7 +54,7 @@ public void testDown() throws Exception {
     }
 
     @Test
-    public void testWordCount() {
+    void testWordCount() {
         try {
             InterpreterOutput out = new InterpreterOutput(line -> {
 
@@ -82,7 +82,7 @@ public void testWordCount() {
     }
 
     @Test
-    public void testStream() {
+    void testStream() {
         String code = "\n" +
             "%flink.execution.mode=yarn\n" +
             "// the host and the port to connect to\n" +

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/AgentThreadFactoryTest.java
Patch:
@@ -22,10 +22,10 @@
 
 import java.util.concurrent.atomic.AtomicInteger;
 
-public class AgentThreadFactoryTest {
+class AgentThreadFactoryTest {
 
     @Test
-    public void newThread() throws InterruptedException {
+    void newThread() throws InterruptedException {
         final AtomicInteger i = new AtomicInteger(10);
 
         AgentThreadFactory threadFactory = new AgentThreadFactory();

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/ProfilerRunnableTest.java
Patch:
@@ -22,10 +22,10 @@
 
 import java.util.concurrent.atomic.AtomicInteger;
 
-public class ProfilerRunnableTest {
+class ProfilerRunnableTest {
 
     @Test
-    public void invokeRunnable() {
+    void invokeRunnable() {
         final AtomicInteger i = new AtomicInteger(10);
 
         ProfilerRunner profilerRunnable =

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/profiler/CpuAndMemoryProfilerTest.java
Patch:
@@ -26,10 +26,10 @@
 import java.util.List;
 import java.util.Map;
 
-public class CpuAndMemoryProfilerTest {
+class CpuAndMemoryProfilerTest {
 
     @Test
-    public void profile() {
+    void profile() {
         final List<String> nameList = new ArrayList<>();
         final List<Map<String, Object>> metricList = new ArrayList<>();
 

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/profiler/MethodArgumentProfilerTest.java
Patch:
@@ -28,10 +28,10 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
-public class MethodArgumentProfilerTest {
+class MethodArgumentProfilerTest {
 
     @Test
-    public void profile() {
+    void profile() {
         final List<String> nameList = new ArrayList<>();
         final List<Map<String, Object>> metricList = new ArrayList<>();
 

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/profiler/MethodDurationProfilerTest.java
Patch:
@@ -28,10 +28,10 @@
 import java.util.Map;
 import java.util.stream.Collectors;
 
-public class MethodDurationProfilerTest {
+class MethodDurationProfilerTest {
 
     @Test
-    public void profile() {
+    void profile() {
         final List<String> nameList = new ArrayList<>();
         final List<Map<String, Object>> metricList = new ArrayList<>();
 

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/profiler/ProcessInfoProfilerTest.java
Patch:
@@ -28,10 +28,10 @@
 import java.util.List;
 import java.util.Map;
 
-public class ProcessInfoProfilerTest {
+class ProcessInfoProfilerTest {
 
     @Test
-    public void profile() {
+    void profile() {
         final List<String> nameList = new ArrayList<>();
         final List<Map<String, Object>> metricList = new ArrayList<>();
 

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/profiler/StacktraceReporterProfilerTest.java
Patch:
@@ -29,10 +29,10 @@
 import java.util.List;
 import java.util.Map;
 
-public class StacktraceReporterProfilerTest {
+class StacktraceReporterProfilerTest {
 
     @Test
-    public void profile() {
+    void profile() {
         final List<String> nameList = new ArrayList<>();
         final List<Map<String, Object>> metricList = new ArrayList<>();
 

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/profiler/ThreadInfoProfilerTest.java
Patch:
@@ -26,10 +26,10 @@
 import java.util.List;
 import java.util.Map;
 
-public class ThreadInfoProfilerTest {
+class ThreadInfoProfilerTest {
 
     @Test
-    public void profile() {
+    void profile() {
         final List<String> nameList = new ArrayList<>();
         final List<Map<String, Object>> metricList = new ArrayList<>();
 

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/reporter/ConsoleOutputReporterTest.java
Patch:
@@ -21,10 +21,10 @@
 
 import java.util.HashMap;
 
-public class ConsoleOutputReporterTest {
+class ConsoleOutputReporterTest {
 
     @Test
-    public void report() {
+    void report() {
         ConsoleOutputReporter reporter = new ConsoleOutputReporter();
         reporter.report("Test", new HashMap<String, Object>());
     }

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/util/ClassAndMethodMetricBufferTest.java
Patch:
@@ -22,10 +22,10 @@
 
 import java.util.Map;
 
-public class ClassAndMethodMetricBufferTest {
+class ClassAndMethodMetricBufferTest {
 
     @Test
-    public void appendValue() {
+    void appendValue() {
         ClassAndMethodLongMetricBuffer buffer = new ClassAndMethodLongMetricBuffer();
         buffer.appendValue("class1", "method1", "metric1", 11);
         buffer.appendValue("class1", "method2", "metric1", 22);
@@ -61,7 +61,7 @@ public void appendValue() {
     }
 
     @Test
-    public void appendValue_concurrent() throws InterruptedException {
+    void appendValue_concurrent() throws InterruptedException {
         ClassAndMethodLongMetricBuffer buffer = new ClassAndMethodLongMetricBuffer();
 
         String[] classNames = new String[] {"class1", "class2", "class1", "class2", "class101"};

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/util/ClassMethodArgmentMetricBufferTest.java
Patch:
@@ -23,10 +23,10 @@
 import java.util.Map;
 import java.util.concurrent.atomic.AtomicLong;
 
-public class ClassMethodArgmentMetricBufferTest {
+class ClassMethodArgmentMetricBufferTest {
 
     @Test
-    public void appendValue() {
+    void appendValue() {
         ClassMethodArgumentMetricBuffer buffer = new ClassMethodArgumentMetricBuffer();
         buffer.appendValue("class1", "method1", "arg1");
         buffer.appendValue("class1", "method2", "arg1");
@@ -53,7 +53,7 @@ public void appendValue() {
     }
 
     @Test
-    public void appendValue_concurrent() throws InterruptedException {
+    void appendValue_concurrent() throws InterruptedException {
         ClassMethodArgumentMetricBuffer buffer = new ClassMethodArgumentMetricBuffer();
 
         String[] classNames = new String[] {"class1", "class2", "class1", "class2", "class101"};

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/util/IOUtilsTest.java
Patch:
@@ -22,10 +22,10 @@
 
 import java.io.ByteArrayInputStream;
 
-public class IOUtilsTest {
+class IOUtilsTest {
 
     @Test
-    public void toByteArray() {
+    void toByteArray() {
         byte[] bytes = new byte[] {1, 2, 3};
         ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(bytes);
         byte[] result = Utils.toByteArray(byteArrayInputStream);

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/util/ReflectionUtilsTest.java
Patch:
@@ -22,10 +22,10 @@
 
 import java.lang.reflect.InvocationTargetException;
 
-public class ReflectionUtilsTest {
+class ReflectionUtilsTest {
 
     @Test
-    public void executeStaticMethods()
+    void executeStaticMethods()
         throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException,
         InvocationTargetException {
         Object result =

File: streampark-plugin/streampark-jvm-profiler/src/test/java/org/apache/streampark/plugin/profiling/util/StacktraceMetricBufferTest.java
Patch:
@@ -25,10 +25,10 @@
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicLong;
 
-public class StacktraceMetricBufferTest {
+class StacktraceMetricBufferTest {
 
     @Test
-    public void appendValue() {
+    void appendValue() {
         StacktraceMetricBuffer buffer = new StacktraceMetricBuffer();
 
         Set<Stacktrace> distinctStacktraces = new HashSet<>();

File: streampark-storage/src/main/java/org/apache/streampark/storage/oss/OssStorageService.java
Patch:
@@ -53,7 +53,7 @@ public void getData(String objectPath, String localFilePath) throws Exception {
         try {
             ossClient.getObject(new GetObjectRequest(bucket, objectPath), new File(localFilePath));
         } catch (Exception e) {
-            log.error("GetData failed. ObjectPath: %s, local path: %s.", objectPath, localFilePath, e);
+            log.error("GetData failed. ObjectPath: {}, local path: {}.", objectPath, localFilePath, e);
             throw handleOssException(e);
         }
     }
@@ -64,7 +64,7 @@ public void putData(String objectPath, String localFilePath) throws Exception {
             PutObjectRequest putObjectRequest = new PutObjectRequest(ossConfig.getBucket(), objectPath, new File(localFilePath));
             ossClient.putObject(putObjectRequest);
         } catch (Exception e) {
-            log.error("PutData failed. ObjectPath: %s, local path: %s.", objectPath, localFilePath, e);
+            log.error("PutData failed. ObjectPath: {}, local path: {}.", objectPath, localFilePath, e);
             throw handleOssException(e);
         }
     }

File: streampark-storage/src/test/java/org/apache/streampark/storage/oss/OssStorageServiceTest.java
Patch:
@@ -22,10 +22,10 @@
 import org.junit.jupiter.api.Assertions;
 import org.junit.jupiter.api.Test;
 
-public class OssStorageServiceTest {
+class OssStorageServiceTest {
 
     @Test
-    public void testHandleException() throws Exception {
+    void testHandleException() {
         OSSException ossException = new OSSException("mock error", "MOCK_CODE", "requestId", "hostId", "header", "resource", "GET");
         RuntimeException exp = OssStorageService.handleOssException(ossException);
         Assertions.assertEquals("Caught an OSSException. Error Message: mock error. Error Code: MOCK_CODE. Request ID: requestId", exp.getMessage());

File: streampark-common/src/main/scala/org/apache/streampark/common/enums/ApplicationType.java
Patch:
@@ -19,7 +19,6 @@
 
 import java.io.Serializable;
 
-
 public enum ApplicationType implements Serializable {
     /**
      * StreamPark Flink

File: streampark-common/src/main/scala/org/apache/streampark/common/enums/DevelopmentMode.java
Patch:
@@ -19,7 +19,6 @@
 
 import java.io.Serializable;
 
-
 public enum DevelopmentMode implements Serializable {
 
     /**

File: streampark-common/src/main/scala/org/apache/streampark/common/enums/ExecutionMode.java
Patch:
@@ -22,8 +22,6 @@
 import java.io.Serializable;
 import java.util.List;
 
-
-
 public enum ExecutionMode implements Serializable {
 
     /**

File: streampark-common/src/main/scala/org/apache/streampark/common/enums/Semantic.java
Patch:
@@ -19,8 +19,6 @@
 
 import java.io.Serializable;
 
-
-
 public enum Semantic implements Serializable {
 
     /**

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -106,6 +106,7 @@
 import org.apache.commons.io.FileUtils;
 import org.apache.commons.io.FilenameUtils;
 import org.apache.commons.lang3.StringUtils;
+import org.apache.flink.api.common.JobID;
 import org.apache.flink.configuration.CheckpointingOptions;
 import org.apache.flink.configuration.RestOptions;
 import org.apache.flink.runtime.jobgraph.SavepointConfigOptions;
@@ -1293,7 +1294,6 @@ public void start(Application appParam, boolean auto) throws Exception {
         Map<String, String> dynamicOption = FlinkSubmitter.extractDynamicOptionAsJava(application.getDynamicOptions());
 
         Map<String, Object> extraParameter = new HashMap<>(0);
-        extraParameter.put(ConfigConst.KEY_JOB_ID(), application.getId());
 
         if (appParam.getAllowNonRestored()) {
             extraParameter.put(SavepointConfigOptions.SAVEPOINT_IGNORE_UNCLAIMED_STATE.key(), true);
@@ -1386,6 +1386,8 @@ public void start(Application appParam, boolean auto) throws Exception {
             DevelopmentMode.of(application.getJobType()),
             ExecutionMode.of(application.getExecutionMode()),
             resolveOrder,
+            application.getId(),
+            new JobID().toHexString(),
             application.getJobName(),
             appConf,
             application.getApplicationType(),

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/K8sFlinkTrackMonitorWrapper.java
Patch:
@@ -131,7 +131,7 @@ public static class Bridge {
         public static TrackId toTrackId(@Nonnull Application app) {
             Enumeration.Value mode = FlinkK8sExecuteMode.of(app.getExecutionModeEnum());
             if (FlinkK8sExecuteMode.APPLICATION().equals(mode)) {
-                return TrackId.onApplication(app.getK8sNamespace(), app.getClusterId(), app.getId(), null);
+                return TrackId.onApplication(app.getK8sNamespace(), app.getClusterId(), app.getId(), app.getJobId());
             } else if (FlinkK8sExecuteMode.SESSION().equals(mode)) {
                 return TrackId.onSession(app.getK8sNamespace(), app.getClusterId(), app.getId(), app.getJobId());
             } else {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/UserController.java
Patch:
@@ -205,9 +205,9 @@ public RestResponse setTeam(Long teamId) {
     }
 
     @PostMapping("appOwners")
-    public RestResponse appOnwers(Long teamId) {
+    public RestResponse appOwners(Long teamId) {
         List<User> userList = userService.findByAppOwner(teamId);
-        userList.forEach((u) -> u.dataMasking());
+        userList.forEach(User::dataMasking);
         return RestResponse.success(userList);
     }
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/controller/PassportController.java
Patch:
@@ -126,8 +126,7 @@ private Map<String, Object> generateUserInfo(JWTToken token, User user) {
 
         Set<String> permissions = this.userService.getPermissions(username);
         userInfo.put("permissions", permissions);
-        user.setPassword("******");
-        user.setSalt("******");
+        user.dataMasking();
         userInfo.put("user", user);
         return userInfo;
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/mapper/UserMapper.java
Patch:
@@ -23,15 +23,14 @@
 import com.baomidou.mybatisplus.core.metadata.IPage;
 import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
 import org.apache.ibatis.annotations.Param;
-import org.apache.ibatis.annotations.Select;
 
 import java.util.List;
 
 public interface UserMapper extends BaseMapper<User> {
 
     IPage<User> findUserDetail(Page page, @Param("user") User user);
 
-    @Select("SELECT u.* FROM t_user u LEFT JOIN t_access_token t ON u.USER_ID = t.USER_ID WHERE t.USER_ID IS NULL")
     List<User> getNoTokenUser();
 
+    List<User> findByAppOwner(@Param("teamId") Long teamId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/UserService.java
Patch:
@@ -111,4 +111,5 @@ public interface UserService extends IService<User> {
 
     void fillInTeam(User user);
 
+    List<User> findByAppOwner(Long teamId);
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -656,6 +656,7 @@ public Long copy(Application appParam) {
         newApp.setJar(oldApp.getJar());
         newApp.setJarCheckSum(oldApp.getJarCheckSum());
         newApp.setTags(oldApp.getTags());
+        newApp.setTeamId(oldApp.getTeamId());
 
         boolean saved = save(newApp);
         if (saved) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/UserServiceImpl.java
Patch:
@@ -105,7 +105,7 @@ public void updateLoginTime(String username) throws Exception {
     public void createUser(User user) throws Exception {
         user.setCreateTime(new Date());
         user.setAvatar(User.DEFAULT_AVATAR);
-        String salt = ShaHashUtils.getRandomSalt(26);
+        String salt = ShaHashUtils.getRandomSalt();
         String password = ShaHashUtils.encrypt(salt, user.getPassword());
         user.setSalt(salt);
         user.setPassword(password);
@@ -151,7 +151,7 @@ public void updateAvatar(String username, String avatar) throws Exception {
     @Transactional(rollbackFor = Exception.class)
     public void updatePassword(String username, String password) throws Exception {
         User user = new User();
-        String salt = ShaHashUtils.getRandomSalt(26);
+        String salt = ShaHashUtils.getRandomSalt();
         password = ShaHashUtils.encrypt(salt, password);
         user.setSalt(salt);
         user.setPassword(password);
@@ -163,7 +163,7 @@ public void updatePassword(String username, String password) throws Exception {
     public void resetPassword(String[] usernames) throws Exception {
         for (String username : usernames) {
             User user = new User();
-            String salt = ShaHashUtils.getRandomSalt(26);
+            String salt = ShaHashUtils.getRandomSalt();
             String password = ShaHashUtils.encrypt(salt, User.DEFAULT_PASSWORD);
             user.setSalt(salt);
             user.setPassword(password);

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/entity/Application.java
Patch:
@@ -96,6 +96,7 @@ public class Application implements Serializable {
     @TableField(updateStrategy = FieldStrategy.IGNORED)
     private String appId;
 
+    @TableField(updateStrategy = FieldStrategy.IGNORED)
     private String jobId;
 
     /**

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -102,7 +102,6 @@
 import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.io.FileUtils;
 import org.apache.commons.lang3.StringUtils;
-import org.apache.flink.api.common.JobID;
 import org.apache.flink.configuration.RestOptions;
 import org.apache.flink.runtime.jobgraph.SavepointConfigOptions;
 import org.springframework.beans.factory.annotation.Autowired;
@@ -1192,7 +1191,6 @@ public void start(Application appParam, boolean auto) throws Exception {
 
         AssertUtils.state(application != null);
 
-        application.setJobId(new JobID().toHexString());
         // if manually started, clear the restart flag
         if (!auto) {
             application.setRestartCount(0);
@@ -1269,7 +1267,6 @@ public void start(Application appParam, boolean auto) throws Exception {
 
         Map<String, Object> extraParameter = new HashMap<>(0);
         extraParameter.put(ConfigConst.KEY_JOB_ID(), application.getId());
-        extraParameter.put(ConfigConst.KEY_FLINK_JOB_ID(), application.getJobId());
 
         if (appParam.getAllowNonRestored()) {
             extraParameter.put(SavepointConfigOptions.SAVEPOINT_IGNORE_UNCLAIMED_STATE.key(), true);
@@ -1388,6 +1385,9 @@ public void start(Application appParam, boolean auto) throws Exception {
                     }
                 }
                 application.setAppId(submitResponse.clusterId());
+                if (StringUtils.isNoneEmpty(submitResponse.jobId())) {
+                    application.setJobId(submitResponse.jobId());
+                }
 
                 if (StringUtils.isNoneEmpty(submitResponse.jobManagerUrl())) {
                     application.setJobManagerUrl(submitResponse.jobManagerUrl());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkTrackingTask.java
Patch:
@@ -323,6 +323,8 @@ private void handleJobOverview(Application application, JobsOverview.Job jobOver
                 application.setEndTime(new Date(endTime));
             }
         }
+
+        application.setJobId(jobOverview.getId());
         application.setDuration(jobOverview.getDuration());
         application.setTotalTask(jobOverview.getTasks().getTotal());
         application.setOverview(jobOverview.getTasks());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/K8sFlinkChangeEventListener.java
Patch:
@@ -162,6 +162,7 @@ private void updateApplicationWithJobStatusCV(Application app, JobStatusCV jobSt
         app.setState(fromK8sFlinkJobState(state).getValue());
 
         // update relevant fields of Application from JobStatusCV
+        app.setJobId(jobStatus.jobId());
         app.setTotalTask(jobStatus.taskTotal());
         if (FlinkJobState.isEndState(state)) {
             app.setOptionState(OptionState.NONE.getValue());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/task/FlinkTrackingTask.java
Patch:
@@ -324,12 +324,11 @@ private void handleJobOverview(Application application, JobsOverview.Job jobOver
             }
         }
         application.setDuration(jobOverview.getDuration());
+        application.setTotalTask(jobOverview.getTasks().getTotal());
+        application.setOverview(jobOverview.getTasks());
 
         // get overview info at the first start time
         if (STARTING_CACHE.getIfPresent(application.getId()) != null) {
-            application.setTotalTask(jobOverview.getTasks().getTotal());
-            application.setOverview(jobOverview.getTasks());
-
             FlinkCluster flinkCluster = getFlinkCluster(application);
             Overview override = httpOverview(application, flinkCluster);
             if (override != null && override.getSlotsTotal() > 0) {

File: streampark-console/streampark-console-service/src/test/java/java/util/regex/RegexTest.java
Patch:
@@ -15,6 +15,8 @@
  * limitations under the License.
  */
 
+package java.util.regex;
+
 import org.apache.streampark.common.util.CommandUtils;
 
 import org.junit.Test;
@@ -26,8 +28,6 @@
 import java.util.ArrayList;
 import java.util.Collections;
 import java.util.List;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
 import java.util.stream.Collectors;
 
 public class RegexTest {

File: streampark-console/streampark-console-service/src/test/java/org/apache/commons/mail/SendEmailTest.java
Patch:
@@ -15,6 +15,8 @@
  * limitations under the License.
  */
 
+package org.apache.commons.mail;
+
 import org.apache.streampark.common.util.DateUtils;
 import org.apache.streampark.common.util.YarnUtils;
 import org.apache.streampark.console.base.util.FreemarkerUtils;
@@ -24,8 +26,6 @@
 import org.apache.streampark.console.core.enums.FlinkAppState;
 
 import freemarker.template.Template;
-import org.apache.commons.mail.EmailException;
-import org.apache.commons.mail.HtmlEmail;
 import org.junit.Before;
 import org.junit.Test;
 

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/entity/DependencyTest.java
Patch:
@@ -15,8 +15,9 @@
  * limitations under the License.
  */
 
+package org.apache.streampark.console.core.entity;
+
 import org.apache.streampark.common.util.DependencyUtils;
-import org.apache.streampark.console.core.entity.Application;
 
 import lombok.extern.slf4j.Slf4j;
 import org.junit.Test;
@@ -33,7 +34,7 @@
 public class DependencyTest {
 
     @Test
-    public void resolveMavenDependencies() throws Throwable {
+    public void resolveMavenDependencies() {
         /**
          * <dependency>
          *      <groupId>org.apache.flink</groupId>

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/entity/GitTest.java
Patch:
@@ -15,7 +15,8 @@
  * limitations under the License.
  */
 
-import org.apache.streampark.console.core.entity.Project;
+package org.apache.streampark.console.core.entity;
+
 import org.apache.streampark.console.core.enums.GitAuthorizedError;
 
 import org.junit.Before;

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/core/enums/AlertTypeTest.java
Patch:
@@ -15,7 +15,7 @@
  * limitations under the License.
  */
 
-import org.apache.streampark.console.core.enums.AlertType;
+package org.apache.streampark.console.core.enums;
 
 import org.junit.jupiter.api.Test;
 

File: streampark-console/streampark-console-service/src/test/java/org/apache/streampark/console/system/authentication/JWTTest.java
Patch:
@@ -14,8 +14,10 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
+package org.apache.streampark.console.system.authentication;
+
 import org.apache.streampark.common.util.DateUtils;
-import org.apache.streampark.console.system.authentication.JWTUtil;
 import org.apache.streampark.console.system.entity.AccessToken;
 
 import com.auth0.jwt.JWT;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -31,6 +31,7 @@
 import org.apache.streampark.console.core.service.FlinkClusterService;
 import org.apache.streampark.console.core.service.FlinkEnvService;
 import org.apache.streampark.console.core.service.SettingService;
+import org.apache.streampark.console.core.task.FlinkTrackingTask;
 import org.apache.streampark.flink.submit.FlinkSubmitter;
 import org.apache.streampark.flink.submit.bean.DeployRequest;
 import org.apache.streampark.flink.submit.bean.DeployResponse;
@@ -188,6 +189,7 @@ public ResponseResult start(FlinkCluster flinkCluster) {
                     updateWrapper.set(FlinkCluster::getException, null);
                     update(updateWrapper);
                     result.setStatus(1);
+                    FlinkTrackingTask.removeFlinkCluster(flinkCluster);
                 } else {
                     result.setStatus(0);
                     result.setMsg("deploy cluster failed," + deployResponse.message());

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/controller/ApplicationBuildPipelineController.java
Patch:
@@ -67,12 +67,12 @@ public class ApplicationBuildPipelineController {
      * @return Whether the pipeline was successfully started
      */
     @ApiAccess
-    @ApiOperation(value = "Launch application", notes = "Launch application", tags = ApiDocConstant.FLINK_APP_OP_TAG, consumes = "x-www-form-urlencoded")
+    @ApiOperation(value = "Launch application", notes = "Launch application", tags = ApiDocConstant.FLINK_APP_OP_TAG, consumes = "application/x-www-form-urlencoded")
     @ApiImplicitParams({
         @ApiImplicitParam(name = "appId", value = "APP_ID", required = true, paramType = "form", dataType = "Long"),
         @ApiImplicitParam(name = "forceBuild", value = "FORCE_BUILD", required = true, paramType = "form", dataType = "Boolean", defaultValue = "false"),
     })
-    @PostMapping("/build")
+    @PostMapping(value = "build", consumes = "application/x-www-form-urlencoded")
     @RequiresPermissions("app:create")
     public RestResponse buildApplication(Long appId, boolean forceBuild) {
         try {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -485,6 +485,8 @@ public IPage<Application> page(Application appParam, RestRequest request) {
             if (app == null) {
                 return record;
             }
+            app.setNickName(record.getNickName());
+            app.setUserName(record.getUserName());
             app.setFlinkVersion(record.getFlinkVersion());
             app.setProjectName(record.getProjectName());
             return app;

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -74,10 +74,10 @@ public void update(FlinkEnv version) throws IOException {
         if (!version.getFlinkHome().equals(flinkEnv.getFlinkHome())) {
             flinkEnv.setFlinkHome(version.getFlinkHome());
             flinkEnv.doSetFlinkConf();
-            version.doSetVersion();
+            flinkEnv.doSetVersion();
         }
         updateById(flinkEnv);
-        FlinkTrackingTask.getFlinkEnvMap().put(flinkEnv.getId(), version);
+        FlinkTrackingTask.getFlinkEnvMap().put(flinkEnv.getId(), flinkEnv);
     }
 
     @Override

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -623,7 +623,7 @@ public Long copy(Application appParam) {
         newApp.setClusterId(oldApp.getExecutionModeEnum() == ExecutionMode.KUBERNETES_NATIVE_SESSION ? oldApp.getClusterId() : jobName);
         args = args != null && !"".equals(args) ? args : oldApp.getArgs();
         newApp.setArgs(args);
-        newApp.setVersionId(100000L);
+        newApp.setVersionId(oldApp.getVersionId());
 
         newApp.setFlinkClusterId(oldApp.getFlinkClusterId());
         newApp.setRestartSize(oldApp.getRestartSize());
@@ -660,6 +660,7 @@ public Long copy(Application appParam) {
 
         newApp.setJar(oldApp.getJar());
         newApp.setJarCheckSum(oldApp.getJarCheckSum());
+        newApp.setTags(oldApp.getTags());
 
         boolean saved = save(newApp);
         if (saved) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/base/domain/router/RouterTree.java
Patch:
@@ -44,7 +44,7 @@ public class RouterTree<T> {
 
     private String type;
 
-    private String display;
+    private boolean display;
 
     private Double order;
 

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/system/service/impl/MenuServiceImpl.java
Patch:
@@ -131,8 +131,7 @@ public ArrayList<VueRouter<Menu>> getUserRouters(User user) {
             route.setPath(menu.getPath());
             route.setComponent(menu.getComponent());
             route.setName(menu.getMenuName());
-            boolean hidden = menu.getDisplay().equals(Menu.DISPLAY_NONE);
-            route.setMeta(new RouterMeta(true, hidden, true, menu.getIcon()));
+            route.setMeta(new RouterMeta(true, !menu.isDisplay(), true, menu.getIcon()));
             routes.add(route);
         });
         return TreeUtils.buildVueRouter(routes);
@@ -155,7 +154,7 @@ private void buildTrees(List<RouterTree<Menu>> trees, List<Menu> menus, List<Str
             tree.setOrder(menu.getOrderNum());
             tree.setPermission(menu.getPerms());
             tree.setType(menu.getType());
-            tree.setDisplay(menu.getDisplay());
+            tree.setDisplay(menu.isDisplay());
             trees.add(tree);
         });
     }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/SavePointMapper.java
Patch:
@@ -31,7 +31,7 @@
 
 public interface SavePointMapper extends BaseMapper<SavePoint> {
 
-    @Update("update t_flink_savepoint set latest=0 where app_id=#{appId}")
+    @Update("update t_flink_savepoint set latest=false where app_id=#{appId}")
     void obsolete(@Param("appId") Long appId);
 
     @Select("select * from t_flink_savepoint where app_id=#{appId} and latest=true")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -69,6 +69,7 @@
 import org.apache.streampark.flink.packer.pipeline.impl.FlinkYarnApplicationBuildPipeline;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
+import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;
 import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;
 import com.github.benmanes.caffeine.cache.Cache;
 import com.github.benmanes.caffeine.cache.Caffeine;
@@ -442,9 +443,8 @@ public Map<Long, PipelineStatus> listPipelineStatus(List<Long> appIds) {
         if (CollectionUtils.isEmpty(appIds)) {
             return Maps.newHashMap();
         }
-        LambdaQueryWrapper<AppBuildPipeline> query = new LambdaQueryWrapper();
-        query.select(AppBuildPipeline::getAppId, AppBuildPipeline::getPipeStatusCode)
-            .in(AppBuildPipeline::getAppId, appIds);
+        QueryWrapper<AppBuildPipeline> query = new QueryWrapper<>();
+        query.select("app_id", "pipe_status").in("app_id", appIds);
         List<Map<String, Object>> rMaps = baseMapper.selectMaps(query);
         if (CollectionUtils.isEmpty(rMaps)) {
             return Maps.newHashMap();

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/ApplicationConfigMapper.java
Patch:
@@ -36,7 +36,7 @@ public interface ApplicationConfigMapper extends BaseMapper<ApplicationConfig> {
     @Select("select s.* from t_flink_config s inner join t_flink_effective e on s.id = e.target_id where e.app_id=#{appId} and e.target_type=1")
     ApplicationConfig getEffective(@Param("appId") Long appId);
 
-    @Select("select * from t_flink_config where app_id=#{appId} and latest=1")
+    @Select("select * from t_flink_config where app_id=#{appId} and latest=true")
     ApplicationConfig getLatest(@Param("appId") Long appId);
 
 }

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/mapper/SavePointMapper.java
Patch:
@@ -34,7 +34,7 @@ public interface SavePointMapper extends BaseMapper<SavePoint> {
     @Update("update t_flink_savepoint set latest=0 where app_id=#{appId}")
     void obsolete(@Param("appId") Long appId);
 
-    @Select("select * from t_flink_savepoint where app_id=#{appId} and latest=1")
+    @Select("select * from t_flink_savepoint where app_id=#{appId} and latest=true")
     SavePoint getLatest(@Param("appId") Long appId);
 
     @Select("select * from t_flink_savepoint where app_id=#{appId}")

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -95,7 +95,6 @@
 @Service
 @Slf4j
 @Transactional(propagation = Propagation.SUPPORTS, rollbackFor = Exception.class)
-@SuppressWarnings("SpringJavaAutowiredFieldsWarningInspection")
 public class AppBuildPipeServiceImpl
     extends ServiceImpl<ApplicationBuildPipelineMapper, AppBuildPipeline> implements AppBuildPipeService {
 
@@ -444,7 +443,7 @@ public Map<Long, PipelineStatus> listPipelineStatus(List<Long> appIds) {
             return Maps.newHashMap();
         }
         LambdaQueryWrapper<AppBuildPipeline> query = new LambdaQueryWrapper();
-        query.select(AppBuildPipeline::getAppId, AppBuildPipeline::getPipeStatus)
+        query.select(AppBuildPipeline::getAppId, AppBuildPipeline::getPipeStatusCode)
             .in(AppBuildPipeline::getAppId, appIds);
         List<Map<String, Object>> rMaps = baseMapper.selectMaps(query);
         if (CollectionUtils.isEmpty(rMaps)) {

File: streampark-console/streampark-console-service/src/main/java/org/apache/streampark/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -190,7 +190,7 @@ public void build(Long id, String socketId) throws Exception {
                         FlinkTrackingTask.refreshTracking(() -> applications.forEach((app) -> {
                             log.info("update deploy by project: {}, appName:{}", project.getName(), app.getJobName());
                             app.setLaunch(LaunchState.NEED_LAUNCH.get());
-                            app.setBuild(Boolean.TRUE);
+                            app.setBuild(true);
                             this.applicationService.updateLaunch(app);
                         }));
                     } catch (Exception e) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/AlertController.java
Patch:
@@ -57,9 +57,10 @@ public class AlertController {
 
     @Autowired
     private AlertService alertService;
+
     @PostMapping(value = "add")
-    public RestResponse addAlertConf(@RequestBody AlertConfigWithParams params) throws Exception {
-        log.info("接收到告警配置：{}", params);
+    public RestResponse addAlertConf(@RequestBody AlertConfigWithParams params) {
+        log.info("received alert config：{}", params);
         AlertConfig alertConfig = AlertConfig.of(params);
         boolean save = alertConfigService.save(alertConfig);
         return RestResponse.success(save);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -98,9 +98,6 @@ public RestResponse get(Application app) {
     @PostMapping("create")
     @RequiresPermissions("app:create")
     public RestResponse create(Application app) throws IOException {
-        if (app.getTeamId() == null || app.getTeamId() <= 0L) {
-            return RestResponse.success(false).message("请选择团队");
-        }
         boolean saved = applicationService.create(app);
         return RestResponse.success(saved);
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkEnvController.java
Patch:
@@ -17,7 +17,6 @@
 package com.streamxhub.streamx.console.core.controller;
 
 import com.streamxhub.streamx.console.base.domain.RestResponse;
-import com.streamxhub.streamx.console.base.exception.InternalException;
 import com.streamxhub.streamx.console.core.entity.FlinkEnv;
 import com.streamxhub.streamx.console.core.service.FlinkEnvService;
 
@@ -88,7 +87,7 @@ public RestResponse update(FlinkEnv version) throws Exception {
     }
 
     @PostMapping("default")
-    public RestResponse setDefault(Long id) throws InternalException {
+    public RestResponse setDefault(Long id) {
         flinkEnvService.setDefault(id);
         return RestResponse.success();
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/SettingController.java
Patch:
@@ -60,7 +60,7 @@ public RestResponse get(String key) {
     }
 
     @PostMapping("weburl")
-    public RestResponse weburl() {
+    public RestResponse webUrl() {
         String url = settingService.getStreamXAddress();
         return RestResponse.success(url == null ? null : url.trim());
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/mapper/ApplicationMapper.java
Patch:
@@ -85,5 +85,4 @@ public interface ApplicationMapper extends BaseMapper<Application> {
             "limit #{limitSize}")
     List<String> getRecentK8sTmPodTemplate(@Param("limitSize") int limit);
 
-    Long getCountByTeam(@Param("teamId") Long teamId);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationService.java
Patch:
@@ -96,5 +96,4 @@ public interface ApplicationService extends IService<Application> {
 
     void forcedStop(Application app);
 
-    Long getCountByTeam(Long teamId);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ProjectService.java
Patch:
@@ -58,7 +58,4 @@ public interface ProjectService extends IService<Project> {
 
     boolean checkExists(Project project);
 
-    Long getCountByTeam(Long teamId);
-
-    List<Project> listByTeam(Long teamId);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/Role.java
Patch:
@@ -26,7 +26,6 @@
 
 import java.io.Serializable;
 import java.util.Date;
-import java.util.List;
 
 @Data
 @TableName("t_role")
@@ -59,6 +58,4 @@ public class Role implements Serializable {
     private transient String createTimeFrom;
     private transient String createTimeTo;
     private transient String menuId;
-
-    private transient List<Long> roleIdList;
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/mapper/UserRoleMapper.java
Patch:
@@ -21,8 +21,6 @@
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;
 import org.apache.ibatis.annotations.Param;
 
-import java.util.List;
-
 public interface UserRoleMapper extends BaseMapper<UserRole> {
 
     /**
@@ -45,5 +43,4 @@ public interface UserRoleMapper extends BaseMapper<UserRole> {
      */
     Boolean deleteByRoleId(@Param("roleId") Long roleId);
 
-    List<Long> selectRoleIdList(@Param("userId") Long userId);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/RoleService.java
Patch:
@@ -31,8 +31,6 @@ public interface RoleService extends IService<Role> {
 
     IPage<Role> findRoles(Role role, RestRequest request);
 
-    IPage<Role> findRolesByUser();
-
     List<Role> findUserRole(String userName);
 
     Role findByName(String roleName);

File: streamx-console/streamx-console-service/src/test/java/ApplicationServiceTest.java
Patch:
@@ -44,7 +44,6 @@ public void revokeTest() {
         app.setId(100001L);
         app.setJobType(1);
         app.setUserId(100000L);
-        app.setTeamId(1L);
         app.setJobName("socket-test");
         app.setVersionId(1L);
         app.setK8sNamespace("default");

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationBuildPipelineController.java
Patch:
@@ -50,7 +50,6 @@
 @Validated
 @RestController
 @RequestMapping("flink/pipe")
-@SuppressWarnings("SpringJavaAutowiredFieldsWarningInspection")
 public class ApplicationBuildPipelineController {
 
     @Autowired

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -163,7 +163,7 @@ public RestResponse mapping(Application app) {
 
     @PostMapping("revoke")
     @RequiresPermissions("app:launch")
-    public RestResponse revoke(Application app) throws Exception {
+    public RestResponse revoke(Application app) {
         applicationService.revoke(app);
         return RestResponse.success();
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationHistoryController.java
Patch:
@@ -51,7 +51,6 @@ public class ApplicationHistoryController {
     @Autowired
     private ApplicationHistoryService applicationHistoryService;
 
-    @SuppressWarnings("SpringJavaInjectionPointsAutowiringInspection")
     @Autowired
     private ApplicationMapper applicationMapper;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Message.java
Patch:
@@ -46,7 +46,7 @@ public class Message {
 
     private String context;
 
-    private Boolean read;
+    private Boolean isRead;
 
     private Date createTime;
 
@@ -60,7 +60,7 @@ public Message(Long userId, Long appId, String title, String context, NoticeType
         this.context = context;
         this.type = noticeType.get();
         this.createTime = new Date();
-        this.read = false;
+        this.isRead = false;
     }
 
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/MessageServiceImpl.java
Patch:
@@ -51,7 +51,7 @@ public void push(Message message) {
     @Override
     public IPage<Message> getUnRead(NoticeType noticeType, RestRequest request) {
         LambdaQueryWrapper<Message> query = new QueryWrapper<Message>().lambda();
-        query.eq(Message::getRead, false).orderByDesc(Message::getCreateTime);
+        query.eq(Message::getIsRead, false).orderByDesc(Message::getCreateTime);
         query.eq(Message::getType, noticeType.get());
         return this.baseMapper.selectPage(new MybatisPager<Message>().getDefaultPage(request), query);
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Message.java
Patch:
@@ -46,7 +46,7 @@ public class Message {
 
     private String context;
 
-    private Integer readed;
+    private Boolean read;
 
     private Date createTime;
 
@@ -60,7 +60,7 @@ public Message(Long userId, Long appId, String title, String context, NoticeType
         this.context = context;
         this.type = noticeType.get();
         this.createTime = new Date();
-        this.readed = 0;
+        this.read = false;
     }
 
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/MessageServiceImpl.java
Patch:
@@ -51,7 +51,7 @@ public void push(Message message) {
     @Override
     public IPage<Message> getUnRead(NoticeType noticeType, RestRequest request) {
         LambdaQueryWrapper<Message> query = new QueryWrapper<Message>().lambda();
-        query.eq(Message::getReaded, 0).orderByDesc(Message::getCreateTime);
+        query.eq(Message::getRead, false).orderByDesc(Message::getCreateTime);
         query.eq(Message::getType, noticeType.get());
         return this.baseMapper.selectPage(new MybatisPager<Message>().getDefaultPage(request), query);
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -64,6 +64,7 @@ public boolean create(FlinkEnv version) throws Exception {
         if (count == 0) {
             version.setIsDefault(true);
         }
+        version.setId(null);
         version.setCreateTime(new Date());
         version.doSetFlinkConf();
         version.doSetVersion();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/security/Authenticator.java
Patch:
@@ -16,7 +16,7 @@
 
 package com.streamxhub.streamx.console.system.security;
 
-import java.util.Map;
+import com.streamxhub.streamx.console.system.entity.User;
 
 public interface Authenticator {
     /**
@@ -25,6 +25,6 @@ public interface Authenticator {
      * @param password user password
      * @return result object
      */
-    Map<String, Object> authenticate(String username, String password) throws Exception;
+    User authenticate(String username, String password) throws Exception;
 
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -661,6 +661,7 @@ public Long copy(Application appParam) {
         newApp.setResourceFrom(oldApp.getResourceFrom());
         newApp.setProjectId(oldApp.getProjectId());
         newApp.setModule(oldApp.getModule());
+        newApp.setDefaultModeIngress(oldApp.getDefaultModeIngress());
 
         newApp.setUserId(commonService.getCurrentUser().getUserId());
         newApp.setState(FlinkAppState.ADDED.getValue());

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/mybatis/interceptor/H2SQLPrepareInterceptor.java
Patch:
@@ -89,6 +89,9 @@ protected void processUpdate(Update update, int index, String sql, Object obj) {
             Object parameterObject = boundSql.getParameterObject();
             if (parameterObject instanceof MapperMethod.ParamMap<?>) {
                 MapperMethod.ParamMap<?> paramMap = (MapperMethod.ParamMap<?>) parameterObject;
+                if (!paramMap.containsKey(Constants.ENTITY)) {
+                    return;
+                }
                 Object entity = paramMap.get(Constants.ENTITY);
                 if (Objects.nonNull(entity) && paramMap.containsKey(Constants.WRAPPER)) {
                     TableInfo tableInfo = TableInfoHelper.getTableInfo(entity.getClass());
@@ -124,5 +127,4 @@ protected void processUpdate(Update update, int index, String sql, Object obj) {
             }
         }
     }
-
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -659,6 +659,8 @@ public Long copy(Application appParam) {
         newApp.setMainClass(oldApp.getMainClass());
         newApp.setAppType(oldApp.getAppType());
         newApp.setResourceFrom(oldApp.getResourceFrom());
+        newApp.setProjectId(oldApp.getProjectId());
+        newApp.setModule(oldApp.getModule());
 
         newApp.setUserId(commonService.getCurrentUser().getUserId());
         newApp.setState(FlinkAppState.ADDED.getValue());

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -631,7 +631,7 @@ public Long copy(Application appParam) {
         String args = appParam.getArgs();
 
         newApp.setJobName(jobName);
-        newApp.setClusterId(jobName);
+        newApp.setClusterId(oldApp.getExecutionModeEnum() == ExecutionMode.KUBERNETES_NATIVE_SESSION ? oldApp.getClusterId() : jobName);
         args = args != null && !"".equals(args) ? args : oldApp.getArgs();
         newApp.setArgs(args);
         newApp.setVersionId(100000L);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -354,7 +354,7 @@ public void revoke(Application appParma) throws ApplicationException {
         }
         try {
             FlinkTrackingTask.refreshTracking(application.getId(), () -> {
-                baseMapper.update(application, updateWrapper);
+                baseMapper.update(null, updateWrapper);
                 return null;
             });
         } catch (Exception e) {
@@ -868,7 +868,7 @@ public void updateLaunch(Application application) {
         if (application.getOptionState() != null) {
             updateWrapper.set(Application::getOptionState, application.getOptionState());
         }
-        baseMapper.update(application, updateWrapper);
+        this.update(updateWrapper);
     }
 
     @Override
@@ -889,7 +889,7 @@ public boolean checkBuildAndUpdate(Application application) {
                 updateWrapper.set(Application::getLaunch, LaunchState.DONE.get());
                 updateWrapper.set(Application::getOptionState, OptionState.NONE.getValue());
             }
-            baseMapper.update(application, updateWrapper);
+            this.update(updateWrapper);
 
             // backup.
             if (application.isFlinkSqlJob()) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -165,8 +165,7 @@ public void toEffective(Long appId, Long sqlId) {
 
     @Override
     public void cleanCandidate(Long id) {
-        this.baseMapper.update(
-            null,
+        this.update(
             new LambdaUpdateWrapper<FlinkSql>()
                 .eq(FlinkSql::getId, id)
                 .set(FlinkSql::getCandidate, CandidateType.NONE.get())

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/AppBuildPipeServiceImpl.java
Patch:
@@ -98,7 +98,7 @@
 @Slf4j
 @Transactional(propagation = Propagation.SUPPORTS, rollbackFor = Exception.class)
 @SuppressWarnings("SpringJavaAutowiredFieldsWarningInspection")
-public class ApplBuildPipeServiceImpl
+public class AppBuildPipeServiceImpl
     extends ServiceImpl<ApplicationBuildPipelineMapper, AppBuildPipeline> implements AppBuildPipeService {
 
     @Autowired

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/SavePoint.java
Patch:
@@ -37,6 +37,8 @@ public class SavePoint {
 
     private Long appId;
 
+    private Long chkId;
+
     private Boolean latest;
 
     /**

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/AlertDingTalkParams.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity.alert;
+package com.streamxhub.streamx.console.core.bean;
 
 import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
 import lombok.Data;
@@ -29,7 +29,7 @@
  */
 @Data
 @JsonIgnoreProperties(ignoreUnknown = true)
-public class DingTalkParams implements Serializable {
+public class AlertDingTalkParams implements Serializable {
     @NotBlank(message = "The access token of DingTalk must not be empty")
     private String token;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/AlertEmailParams.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity.alert;
+package com.streamxhub.streamx.console.core.bean;
 
 import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
 import lombok.Data;
@@ -29,7 +29,7 @@
  */
 @Data
 @JsonIgnoreProperties(ignoreUnknown = true)
-public class EmailParams implements Serializable {
+public class AlertEmailParams implements Serializable {
 
     @NotBlank(message = "The address of email must not be empty")
     private String contacts;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/AlertHttpCallbackParams.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity.alert;
+package com.streamxhub.streamx.console.core.bean;
 
 import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
 import lombok.Data;
@@ -29,7 +29,7 @@
  */
 @Data
 @JsonIgnoreProperties(ignoreUnknown = true)
-public class HttpCallbackParams implements Serializable {
+public class AlertHttpCallbackParams implements Serializable {
     @NotBlank(message = "The url of alert must not be empty")
     private String url;
     /**

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/AlertLarkParams.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity.alert;
+package com.streamxhub.streamx.console.core.bean;
 
 import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
 import lombok.Data;
@@ -29,7 +29,7 @@
  */
 @Data
 @JsonIgnoreProperties(ignoreUnknown = true)
-public class LarkParams implements Serializable {
+public class AlertLarkParams implements Serializable {
     @NotBlank(message = "The access token of Lark must not be empty")
     private String token;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/AlertLarkRobotResponse.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity.alert;
+package com.streamxhub.streamx.console.core.bean;
 
 import com.fasterxml.jackson.annotation.JsonProperty;
 import lombok.Data;
@@ -28,7 +28,7 @@
  */
 @NoArgsConstructor
 @Data
-public class LarkRobotResponse {
+public class AlertLarkRobotResponse {
     @JsonProperty("Extra")
     private Object extra;
     @JsonProperty("StatusCode")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/AlertTemplate.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity.alert;
+package com.streamxhub.streamx.console.core.bean;
 
 import com.streamxhub.streamx.common.enums.ExecutionMode;
 import com.streamxhub.streamx.common.util.DateUtils;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/AlertWeComParams.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity.alert;
+package com.streamxhub.streamx.console.core.bean;
 
 import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
 import lombok.Data;
@@ -29,7 +29,7 @@
  */
 @Data
 @JsonIgnoreProperties(ignoreUnknown = true)
-public class WeComParams implements Serializable {
+public class AlertWeComParams implements Serializable {
     @NotBlank(message = "The access token of WeCom must not be empty")
     private String token;
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/AppBuildDockerResolvedDetail.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity;
+package com.streamxhub.streamx.console.core.bean;
 
 import com.streamxhub.streamx.flink.packer.pipeline.DockerBuildSnapshot;
 import com.streamxhub.streamx.flink.packer.pipeline.DockerPullSnapshot;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/AppControl.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity;
+package com.streamxhub.streamx.console.core.bean;
 
 import lombok.Data;
 import lombok.experimental.Accessors;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/Note.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity;
+package com.streamxhub.streamx.console.core.bean;
 
 import lombok.AllArgsConstructor;
 import lombok.Data;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/ResponseResult.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity;
+package com.streamxhub.streamx.console.core.bean;
 
 import lombok.Data;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/RobotResponse.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity.alert;
+package com.streamxhub.streamx.console.core.bean;
 
 import lombok.Data;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/bean/SenderEmail.java
Patch:
@@ -14,7 +14,7 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity;
+package com.streamxhub.streamx.console.core.bean;
 
 import lombok.Data;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/AlertController.java
Patch:
@@ -20,9 +20,9 @@
 import com.streamxhub.streamx.console.base.domain.RestRequest;
 import com.streamxhub.streamx.console.base.domain.RestResponse;
 import com.streamxhub.streamx.console.base.exception.AlertException;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfig;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfigWithParams;
-import com.streamxhub.streamx.console.core.entity.alert.AlertTemplate;
+import com.streamxhub.streamx.console.core.bean.AlertConfigWithParams;
+import com.streamxhub.streamx.console.core.bean.AlertTemplate;
+import com.streamxhub.streamx.console.core.entity.AlertConfig;
 import com.streamxhub.streamx.console.core.service.alert.AlertConfigService;
 import com.streamxhub.streamx.console.core.service.alert.AlertService;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationBuildPipelineController.java
Patch:
@@ -19,7 +19,7 @@
 import com.streamxhub.streamx.console.base.domain.ApiDocConstant;
 import com.streamxhub.streamx.console.base.domain.RestResponse;
 import com.streamxhub.streamx.console.core.annotation.ApiAccess;
-import com.streamxhub.streamx.console.core.entity.AppBuildDockerResolvedDetail;
+import com.streamxhub.streamx.console.core.bean.AppBuildDockerResolvedDetail;
 import com.streamxhub.streamx.console.core.entity.AppBuildPipeline;
 import com.streamxhub.streamx.console.core.entity.Application;
 import com.streamxhub.streamx.console.core.service.AppBuildPipeService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -25,7 +25,7 @@
 import com.streamxhub.streamx.console.base.exception.InternalException;
 import com.streamxhub.streamx.console.base.util.MoreFutures;
 import com.streamxhub.streamx.console.core.annotation.ApiAccess;
-import com.streamxhub.streamx.console.core.entity.AppControl;
+import com.streamxhub.streamx.console.core.bean.AppControl;
 import com.streamxhub.streamx.console.core.entity.Application;
 import com.streamxhub.streamx.console.core.entity.ApplicationBackUp;
 import com.streamxhub.streamx.console.core.entity.ApplicationLog;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkClusterController.java
Patch:
@@ -18,8 +18,8 @@
 
 import com.streamxhub.streamx.console.base.domain.RestResponse;
 import com.streamxhub.streamx.console.base.exception.InternalException;
+import com.streamxhub.streamx.console.core.bean.ResponseResult;
 import com.streamxhub.streamx.console.core.entity.FlinkCluster;
-import com.streamxhub.streamx.console.core.entity.ResponseResult;
 import com.streamxhub.streamx.console.core.service.FlinkClusterService;
 
 import lombok.extern.slf4j.Slf4j;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/NoteBookController.java
Patch:
@@ -16,7 +16,7 @@
 
 package com.streamxhub.streamx.console.core.controller;
 
-import com.streamxhub.streamx.console.core.entity.Note;
+import com.streamxhub.streamx.console.core.bean.Note;
 
 import lombok.extern.slf4j.Slf4j;
 import org.springframework.validation.annotation.Validated;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/AlertConfig.java
Patch:
@@ -14,9 +14,10 @@
  * limitations under the License.
  */
 
-package com.streamxhub.streamx.console.core.entity.alert;
+package com.streamxhub.streamx.console.core.entity;
 
 import com.streamxhub.streamx.console.base.util.JacksonUtils;
+import com.streamxhub.streamx.console.core.bean.AlertConfigWithParams;
 
 import com.baomidou.mybatisplus.annotation.IdType;
 import com.baomidou.mybatisplus.annotation.TableId;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/AppBuildPipeline.java
Patch:
@@ -65,7 +65,7 @@
 @Slf4j
 public class AppBuildPipeline {
 
-    @TableId(value = "app_id", type = IdType.INPUT)
+    @TableId(type = IdType.INPUT)
     private Long appId;
 
     @TableField(value = "pipe_type")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/ApplicationConfig.java
Patch:
@@ -20,7 +20,9 @@
 import com.streamxhub.streamx.common.util.PropertiesUtils;
 
 import com.baomidou.mybatisplus.annotation.FieldStrategy;
+import com.baomidou.mybatisplus.annotation.IdType;
 import com.baomidou.mybatisplus.annotation.TableField;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import com.fasterxml.jackson.annotation.JsonIgnore;
 import lombok.Data;
@@ -38,6 +40,7 @@
 @Slf4j
 public class ApplicationConfig {
 
+    @TableId(type = IdType.AUTO)
     private Long id;
 
     private Long appId;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/ApplicationLog.java
Patch:
@@ -16,6 +16,8 @@
 
 package com.streamxhub.streamx.console.core.entity;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import lombok.Data;
 import lombok.extern.slf4j.Slf4j;
@@ -30,6 +32,7 @@
 @Slf4j
 public class ApplicationLog {
 
+    @TableId(type = IdType.AUTO)
     private Long id;
     /**
      * appId

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/FlameGraph.java
Patch:
@@ -18,6 +18,8 @@
 
 import com.streamxhub.streamx.common.util.DeflaterUtils;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import com.fasterxml.jackson.annotation.JsonIgnore;
 import lombok.Data;
@@ -35,6 +37,7 @@
 @Slf4j
 public class FlameGraph {
 
+    @TableId(type = IdType.AUTO)
     private Long id;
 
     private Long appId;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/FlinkCluster.java
Patch:
@@ -23,6 +23,8 @@
 import com.streamxhub.streamx.common.util.HttpClientUtils;
 import com.streamxhub.streamx.console.base.util.JacksonUtils;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import com.fasterxml.jackson.annotation.JsonFormat;
 import com.fasterxml.jackson.annotation.JsonIgnore;
@@ -47,6 +49,7 @@
 @TableName("t_flink_cluster")
 public class FlinkCluster implements Serializable {
 
+    @TableId(type = IdType.AUTO)
     private Long id;
 
     private String address;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/FlinkEnv.java
Patch:
@@ -21,6 +21,8 @@
 import com.streamxhub.streamx.common.util.PropertiesUtils;
 import com.streamxhub.streamx.console.base.exception.ApiException;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import com.fasterxml.jackson.annotation.JsonIgnore;
 import lombok.Data;
@@ -38,6 +40,7 @@
 @TableName("t_flink_env")
 public class FlinkEnv implements Serializable {
 
+    @TableId(type = IdType.AUTO)
     private Long id;
 
     private String flinkName;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Message.java
Patch:
@@ -18,6 +18,8 @@
 
 import com.streamxhub.streamx.console.core.enums.NoticeType;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import lombok.Data;
 
@@ -27,6 +29,7 @@
 @TableName("t_message")
 public class Message {
 
+    @TableId(type = IdType.AUTO)
     private Long id;
 
     private Long appId;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Project.java
Patch:
@@ -53,7 +53,7 @@
 @Data
 @TableName("t_flink_project")
 public class Project implements Serializable {
-    @TableId(value = "ID", type = IdType.AUTO)
+    @TableId(type = IdType.AUTO)
     private Long id;
     private Long teamId;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/SavePoint.java
Patch:
@@ -16,6 +16,8 @@
 
 package com.streamxhub.streamx.console.core.entity;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import lombok.Data;
 import lombok.extern.slf4j.Slf4j;
@@ -30,6 +32,7 @@
 @Slf4j
 public class SavePoint {
 
+    @TableId(type = IdType.AUTO)
     private Long id;
 
     private Long appId;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Setting.java
Patch:
@@ -16,6 +16,8 @@
 
 package com.streamxhub.streamx.console.core.entity;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import lombok.Data;
 import lombok.extern.slf4j.Slf4j;
@@ -34,6 +36,7 @@ public class Setting implements Serializable {
 
     private String settingName;
 
+    @TableId(type = IdType.INPUT)
     private String settingKey;
 
     private String settingValue;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Tutorial.java
Patch:
@@ -16,6 +16,8 @@
 
 package com.streamxhub.streamx.console.core.entity;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import lombok.Data;
 
@@ -27,6 +29,7 @@
 @Data
 @TableName("t_flink_tutorial")
 public class Tutorial {
+    @TableId(type = IdType.AUTO)
     private Long id;
     private String name;
     private Integer type;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/mapper/AlertConfigMapper.java
Patch:
@@ -16,7 +16,7 @@
 
 package com.streamxhub.streamx.console.core.mapper;
 
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfig;
+import com.streamxhub.streamx.console.core.entity.AlertConfig;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;
 import org.apache.ibatis.annotations.Param;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/mapper/SettingMapper.java
Patch:
@@ -31,6 +31,6 @@ public interface SettingMapper extends BaseMapper<Setting> {
     @Select("select * from t_setting where setting_key=#{key}")
     Setting get(@Param("key") String key);
 
-    @Update("update t_setting set setting_value = #{setting.value} where setting_key = #{setting.key}")
+    @Update("update t_setting set setting_value = #{setting.settingValue} where setting_key = #{setting.settingKey}")
     void updateByKey(@Param("setting") Setting setting);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/FlinkClusterService.java
Patch:
@@ -16,8 +16,8 @@
 
 package com.streamxhub.streamx.console.core.service;
 
+import com.streamxhub.streamx.console.core.bean.ResponseResult;
 import com.streamxhub.streamx.console.core.entity.FlinkCluster;
-import com.streamxhub.streamx.console.core.entity.ResponseResult;
 
 import com.baomidou.mybatisplus.extension.service.IService;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/SettingService.java
Patch:
@@ -16,7 +16,7 @@
 
 package com.streamxhub.streamx.console.core.service;
 
-import com.streamxhub.streamx.console.core.entity.SenderEmail;
+import com.streamxhub.streamx.console.core.bean.SenderEmail;
 import com.streamxhub.streamx.console.core.entity.Setting;
 
 import com.baomidou.mybatisplus.extension.service.IService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/alert/AlertConfigService.java
Patch:
@@ -18,8 +18,8 @@
 
 import com.streamxhub.streamx.console.base.domain.RestRequest;
 import com.streamxhub.streamx.console.base.exception.AlertException;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfig;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfigWithParams;
+import com.streamxhub.streamx.console.core.bean.AlertConfigWithParams;
+import com.streamxhub.streamx.console.core.entity.AlertConfig;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;
 import com.baomidou.mybatisplus.extension.service.IService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/alert/AlertNotifyService.java
Patch:
@@ -17,8 +17,8 @@
 package com.streamxhub.streamx.console.core.service.alert;
 
 import com.streamxhub.streamx.console.base.exception.AlertException;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfigWithParams;
-import com.streamxhub.streamx.console.core.entity.alert.AlertTemplate;
+import com.streamxhub.streamx.console.core.bean.AlertConfigWithParams;
+import com.streamxhub.streamx.console.core.bean.AlertTemplate;
 
 /**
  * @author weijinglun

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/alert/AlertService.java
Patch:
@@ -17,9 +17,9 @@
 package com.streamxhub.streamx.console.core.service.alert;
 
 import com.streamxhub.streamx.console.base.exception.AlertException;
+import com.streamxhub.streamx.console.core.bean.AlertConfigWithParams;
+import com.streamxhub.streamx.console.core.bean.AlertTemplate;
 import com.streamxhub.streamx.console.core.entity.Application;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfigWithParams;
-import com.streamxhub.streamx.console.core.entity.alert.AlertTemplate;
 import com.streamxhub.streamx.console.core.enums.CheckPointStatus;
 import com.streamxhub.streamx.console.core.enums.FlinkAppState;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/alert/impl/AlertConfigServiceImpl.java
Patch:
@@ -19,9 +19,9 @@
 import com.streamxhub.streamx.console.base.domain.RestRequest;
 import com.streamxhub.streamx.console.base.exception.AlertException;
 import com.streamxhub.streamx.console.base.mybatis.pager.MybatisPager;
+import com.streamxhub.streamx.console.core.bean.AlertConfigWithParams;
+import com.streamxhub.streamx.console.core.entity.AlertConfig;
 import com.streamxhub.streamx.console.core.entity.Application;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfig;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfigWithParams;
 import com.streamxhub.streamx.console.core.mapper.AlertConfigMapper;
 import com.streamxhub.streamx.console.core.service.ApplicationService;
 import com.streamxhub.streamx.console.core.service.alert.AlertConfigService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/alert/impl/AlertServiceImpl.java
Patch:
@@ -18,10 +18,10 @@
 
 import com.streamxhub.streamx.console.base.exception.AlertException;
 import com.streamxhub.streamx.console.base.util.SpringContextUtils;
+import com.streamxhub.streamx.console.core.bean.AlertConfigWithParams;
+import com.streamxhub.streamx.console.core.bean.AlertTemplate;
+import com.streamxhub.streamx.console.core.entity.AlertConfig;
 import com.streamxhub.streamx.console.core.entity.Application;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfig;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfigWithParams;
-import com.streamxhub.streamx.console.core.entity.alert.AlertTemplate;
 import com.streamxhub.streamx.console.core.enums.AlertType;
 import com.streamxhub.streamx.console.core.enums.CheckPointStatus;
 import com.streamxhub.streamx.console.core.enums.FlinkAppState;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/alert/impl/EmailAlertNotifyServiceImpl.java
Patch:
@@ -18,9 +18,9 @@
 
 import com.streamxhub.streamx.console.base.exception.AlertException;
 import com.streamxhub.streamx.console.base.util.FreemarkerUtils;
-import com.streamxhub.streamx.console.core.entity.SenderEmail;
-import com.streamxhub.streamx.console.core.entity.alert.AlertConfigWithParams;
-import com.streamxhub.streamx.console.core.entity.alert.AlertTemplate;
+import com.streamxhub.streamx.console.core.bean.AlertConfigWithParams;
+import com.streamxhub.streamx.console.core.bean.AlertTemplate;
+import com.streamxhub.streamx.console.core.bean.SenderEmail;
 import com.streamxhub.streamx.console.core.service.SettingService;
 import com.streamxhub.streamx.console.core.service.alert.AlertNotifyService;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -22,9 +22,9 @@
 import com.streamxhub.streamx.common.enums.ResolveOrder;
 import com.streamxhub.streamx.common.util.ThreadUtils;
 import com.streamxhub.streamx.common.util.Utils;
+import com.streamxhub.streamx.console.core.bean.ResponseResult;
 import com.streamxhub.streamx.console.core.entity.FlinkCluster;
 import com.streamxhub.streamx.console.core.entity.FlinkEnv;
-import com.streamxhub.streamx.console.core.entity.ResponseResult;
 import com.streamxhub.streamx.console.core.mapper.FlinkClusterMapper;
 import com.streamxhub.streamx.console.core.service.CommonService;
 import com.streamxhub.streamx.console.core.service.FlinkClusterService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/SettingServiceImpl.java
Patch:
@@ -18,7 +18,7 @@
 
 import com.streamxhub.streamx.common.conf.CommonConfig;
 import com.streamxhub.streamx.common.conf.InternalConfigHolder;
-import com.streamxhub.streamx.console.core.entity.SenderEmail;
+import com.streamxhub.streamx.console.core.bean.SenderEmail;
 import com.streamxhub.streamx.console.core.entity.Setting;
 import com.streamxhub.streamx.console.core.mapper.SettingMapper;
 import com.streamxhub.streamx.console.core.service.SettingService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/Menu.java
Patch:
@@ -41,7 +41,7 @@ public class Menu implements Serializable {
 
     public static final String DISPLAY_NONE = "0";
 
-    @TableId(value = "MENU_ID", type = IdType.AUTO)
+    @TableId(type = IdType.AUTO)
     private Long menuId;
 
     private Long parentId;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/Role.java
Patch:
@@ -34,7 +34,7 @@ public class Role implements Serializable {
 
     private static final long serialVersionUID = -1714476694755654924L;
 
-    @TableId(value = "ROLE_ID", type = IdType.AUTO)
+    @TableId(type = IdType.AUTO)
     private Long roleId;
 
     @NotBlank(message = "{required}")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/RoleMenu.java
Patch:
@@ -16,6 +16,8 @@
 
 package com.streamxhub.streamx.console.system.entity;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import lombok.Data;
 
@@ -27,6 +29,7 @@ public class RoleMenu implements Serializable {
 
     private static final long serialVersionUID = -7573904024872252113L;
 
+    @TableId(type = IdType.AUTO)
     private Long id;
 
     private Long roleId;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/TeamUser.java
Patch:
@@ -16,6 +16,8 @@
 
 package com.streamxhub.streamx.console.system.entity;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import lombok.Data;
 import lombok.extern.slf4j.Slf4j;
@@ -30,6 +32,7 @@
 @Slf4j
 public class TeamUser {
 
+    @TableId(type = IdType.AUTO)
     private Long teamId;
 
     private Long userId;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/User.java
Patch:
@@ -55,7 +55,7 @@ public class User implements Serializable {
     // 默认密码
     public static final String DEFAULT_PASSWORD = "streamx666";
 
-    @TableId(value = "USER_ID", type = IdType.AUTO)
+    @TableId(type = IdType.AUTO)
     private Long userId;
 
     @Size(min = 4, max = 20, message = "{range}")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/UserRole.java
Patch:
@@ -16,6 +16,8 @@
 
 package com.streamxhub.streamx.console.system.entity;
 
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
 import lombok.Data;
 
@@ -27,6 +29,7 @@ public class UserRole implements Serializable {
 
     private static final long serialVersionUID = -3166012934498268403L;
 
+    @TableId(type = IdType.AUTO)
     private Long id;
 
     private Long userId;

File: streamx-console/streamx-console-service/src/test/java/SendEmailTest.java
Patch:
@@ -17,9 +17,9 @@
 import com.streamxhub.streamx.common.util.DateUtils;
 import com.streamxhub.streamx.common.util.YarnUtils;
 import com.streamxhub.streamx.console.base.util.FreemarkerUtils;
+import com.streamxhub.streamx.console.core.bean.AlertTemplate;
+import com.streamxhub.streamx.console.core.bean.SenderEmail;
 import com.streamxhub.streamx.console.core.entity.Application;
-import com.streamxhub.streamx.console.core.entity.SenderEmail;
-import com.streamxhub.streamx.console.core.entity.alert.AlertTemplate;
 import com.streamxhub.streamx.console.core.enums.FlinkAppState;
 
 import freemarker.template.Template;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/domain/Constant.java
Patch:
@@ -29,6 +29,8 @@ public class Constant {
     // 排序规则： ascend 升序
     public static final String ORDER_ASC = "asc";
 
+    public static final String DEFAULT_SORT_FIELD = "create_time";
+
     // 按钮
     public static final String TYPE_BUTTON = "1";
     // 菜单

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/mybatis/pager/MybatisPager.java
Patch:
@@ -37,7 +37,7 @@
 public final class MybatisPager<T> {
 
     public Page<T> getDefaultPage(RestRequest request) {
-        return getPage(request, "create_time", Constant.ORDER_DESC);
+        return getPage(request, Constant.DEFAULT_SORT_FIELD, Constant.ORDER_DESC);
     }
 
     public Page<T> getPage(RestRequest request, String defaultSort, String defaultOrder) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/mapper/ProjectMapper.java
Patch:
@@ -29,7 +29,7 @@
  */
 public interface ProjectMapper extends BaseMapper<Project> {
 
-    IPage<Project> findProject(Page<Project> page, @Param("project") Project project);
+    IPage<Project> page(Page<Project> page, @Param("project") Project project);
 
     @Update("update t_flink_project set BUILD_STATE=2 where id=#{project.id}")
     void failureBuild(@Param("project") Project project);
@@ -40,5 +40,4 @@ public interface ProjectMapper extends BaseMapper<Project> {
     @Update("update t_flink_project set BUILD_STATE=0 where id=#{project.id}")
     void startBuild(@Param("project") Project project);
 
-    Long getCountByTeam(@Param("teamId") Long teamId);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Message.java
Patch:
@@ -43,7 +43,7 @@ public class Message {
 
     private String context;
 
-    private Boolean readed;
+    private Integer readed;
 
     private Date createTime;
 
@@ -57,7 +57,7 @@ public Message(Long userId, Long appId, String title, String context, NoticeType
         this.context = context;
         this.type = noticeType.get();
         this.createTime = new Date();
-        this.readed = false;
+        this.readed = 0;
     }
 
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/MessageServiceImpl.java
Patch:
@@ -54,7 +54,7 @@ public void push(Message message) {
     public IPage<Message> getUnRead(NoticeType noticeType, RestRequest request) {
         Page<Message> page = new Page<>();
         LambdaQueryWrapper<Message> query = new QueryWrapper<Message>().lambda();
-        query.eq(Message::getReaded, false).orderByDesc(Message::getCreateTime);
+        query.eq(Message::getReaded, 0).orderByDesc(Message::getCreateTime);
         query.eq(Message::getType, noticeType.get());
         SortUtils.handlePageSort(request, page, "create_time", Constant.ORDER_DESC, false);
         return this.baseMapper.selectPage(page, query);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/StreamXConsole.java
Patch:
@@ -19,6 +19,7 @@
 import com.streamxhub.streamx.common.util.SystemPropertyUtils;
 
 import lombok.extern.slf4j.Slf4j;
+import org.mybatis.spring.annotation.MapperScan;
 import org.springframework.boot.SpringApplication;
 import org.springframework.boot.autoconfigure.SpringBootApplication;
 import org.springframework.boot.context.ApplicationPidFileWriter;
@@ -54,6 +55,7 @@
 @Slf4j
 @SpringBootApplication
 @EnableScheduling
+@MapperScan(value = {"com.streamxhub.streamx.console.*.dao"})
 public class StreamXConsole {
 
     public static void main(String[] args) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Application.java
Patch:
@@ -93,10 +93,10 @@ public class Application implements Serializable {
      */
     private String jobName;
 
-    @TableField(strategy = FieldStrategy.IGNORED)
+    @TableField(updateStrategy = FieldStrategy.IGNORED)
     private String appId;
 
-    @TableField(strategy = FieldStrategy.IGNORED)
+    @TableField(updateStrategy = FieldStrategy.IGNORED)
     private String jobId;
 
     /**
@@ -180,7 +180,7 @@ public class Application implements Serializable {
     private Date startTime;
 
     @JsonFormat(pattern = "yyyy-MM-dd HH:mm:ss", timezone = "GMT+8")
-    @TableField(strategy = FieldStrategy.IGNORED)
+    @TableField(updateStrategy = FieldStrategy.IGNORED)
     private Date endTime;
 
     private Long duration;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/ApplicationConfig.java
Patch:
@@ -53,7 +53,7 @@ public class ApplicationConfig {
      */
     private Integer version = 1;
 
-    @TableField(strategy = FieldStrategy.IGNORED)
+    @TableField(updateStrategy = FieldStrategy.IGNORED)
     private String content;
 
     private Date createTime;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/alert/impl/AlertConfigServiceImpl.java
Patch:
@@ -79,7 +79,7 @@ public boolean exist(AlertConfig alertConfig) {
 
     @Override
     public boolean deleteById(Long id) throws AlertException {
-        int count = applicationService.count(new LambdaQueryWrapper<Application>().eq(id != null, Application::getAlertId, id));
+        long count = applicationService.count(new LambdaQueryWrapper<Application>().eq(id != null, Application::getAlertId, id));
         if (count > 0) {
             throw new AlertException(String.format("AlertId:%d, this is bound by application. Please clear the configuration first", id));
         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -620,7 +620,7 @@ public boolean create(Application appParam) {
     @SneakyThrows
     @Transactional(rollbackFor = {Exception.class})
     public Long copy(Application appParam) {
-        int count = this.baseMapper.selectCount(
+        long count = this.baseMapper.selectCount(
                 new QueryWrapper<Application>().lambda()
                         .eq(Application::getJobName, appParam.getJobName()));
         if (count > 0) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/EffectiveServiceImpl.java
Patch:
@@ -61,7 +61,7 @@ public void saveOrUpdate(Long appId, EffectiveType type, Long id) {
             .lambda()
             .eq(Effective::getAppId, appId)
             .eq(Effective::getTargetType, type.getType());
-        int count = count(queryWrapper);
+        long count = count(queryWrapper);
         if (count == 0) {
             Effective effective = new Effective();
             effective.setAppId(appId);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -60,7 +60,7 @@ public boolean exists(FlinkEnv version) {
 
     @Override
     public boolean create(FlinkEnv version) throws Exception {
-        int count = this.baseMapper.selectCount(null);
+        long count = this.baseMapper.selectCount(null);
         if (count == 0) {
             version.setIsDefault(true);
         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -107,7 +107,7 @@ public RestResponse create(Project project) {
         QueryWrapper<Project> queryWrapper = new QueryWrapper<>();
         queryWrapper.lambda().eq(Project::getName, project.getName());
         queryWrapper.eq(true, "team_id", project.getTeamId());
-        int count = count(queryWrapper);
+        long count = count(queryWrapper);
         if (count == 0) {
             project.setDate(new Date());
             boolean status = save(project);
@@ -162,7 +162,7 @@ public boolean delete(Long id) {
         assert project != null;
         LambdaQueryWrapper<Application> queryWrapper = new QueryWrapper<Application>().lambda();
         queryWrapper.eq(Application::getProjectId, id);
-        int count = applicationService.count(queryWrapper);
+        long count = applicationService.count(queryWrapper);
         if (count > 0) {
             return false;
         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/AccessToken.java
Patch:
@@ -41,7 +41,7 @@ public class AccessToken implements Serializable {
     public static final Integer STATUS_ENABLE = 1;
     public static final Integer STATUS_DISABLE = 0;
 
-    @TableId(value = "ID", type = IdType.AUTO)
+    @TableId(type = IdType.AUTO)
     private Long id;
 
     @NotBlank(message = "{required}")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/SysLog.java
Patch:
@@ -30,7 +30,7 @@ public class SysLog implements Serializable {
 
     private static final long serialVersionUID = -8878596941954995444L;
 
-    @TableId(value = "ID", type = IdType.AUTO)
+    @TableId(type = IdType.AUTO)
     private Long id;
 
     private String username;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/Team.java
Patch:
@@ -33,12 +33,11 @@
 @Slf4j
 public class Team {
 
-    @TableId(value = "TEAM_ID", type = IdType.AUTO)
+    @TableId(type = IdType.AUTO)
     private Long teamId;
 
     private String teamCode;
 
-    @TableId(value = "TEAM_NAME")
     private String teamName;
 
     private Date createTime;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/SettingController.java
Patch:
@@ -48,7 +48,7 @@ public class SettingController {
     @PostMapping("all")
     @RequiresPermissions("setting:view")
     public RestResponse all() {
-        LambdaQueryWrapper<Setting> query = new QueryWrapper<Setting>().lambda().orderByAsc(Setting::getNum);
+        LambdaQueryWrapper<Setting> query = new QueryWrapper<Setting>().lambda().orderByAsc(Setting::getOrderNum);
         List<Setting> setting = settingService.list(query);
         return RestResponse.success(setting);
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/SettingMapper.java
Patch:
@@ -28,9 +28,9 @@
  */
 public interface SettingMapper extends BaseMapper<Setting> {
 
-    @Select("select * from t_setting where `key`=#{key}")
+    @Select("select * from t_setting where setting_key=#{key}")
     Setting get(@Param("key") String key);
 
-    @Update("update t_setting set `value` = #{setting.value} where `key` = #{setting.key}")
+    @Update("update t_setting set setting_value = #{setting.value} where setting_key = #{setting.key}")
     void updateByKey(@Param("setting") Setting setting);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1498,8 +1498,8 @@ private String getSavePointPath(Application appParam) throws Exception {
                 if (!config.isEmpty()) {
                     savepointPath = config.get(ConfigConst.KEY_FLINK_STATE_SAVEPOINTS_DIR().substring(6));
                 }
-            } else if (ExecutionMode.isYarnMode(application.getExecutionMode())) {
-                // 3.2) 如是 on yarn模式. 则读取绑定的flink里的flink-conf.yml中的savepoint
+            } else {
+                // 3.2) 如是 on yarn 或者 kubernetes模式. 则读取绑定的flink里的flink-conf.yml中的savepoint
                 FlinkEnv flinkEnv = flinkEnvService.getById(application.getVersionId());
                 savepointPath = flinkEnv.convertFlinkYamlAsMap().get(ConfigConst.KEY_FLINK_STATE_SAVEPOINTS_DIR().substring(6));
             }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1176,7 +1176,7 @@ public String checkSavepointPath(Application appParam) throws Exception {
             }
             return error;
         } else {
-            return "When custom savepoint is not set, state.savepoints.dir needs to be set in Dynamic Option or flick-conf.yaml of application";
+            return "When custom savepoint is not set, state.savepoints.dir needs to be set in Dynamic Option or flink-conf.yaml of application";
         }
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/impl/UserServiceImpl.java
Patch:
@@ -258,7 +258,6 @@ public List<User> getNoTokenUser() {
                 u.setPassword(null);
                 u.setSalt(null);
                 u.setRoleId(null);
-                u.setMobile(null);
             });
         }
         return users;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -736,7 +736,9 @@ public boolean update(Application appParam) {
                     !ObjectUtils.safeTrimEquals(application.getK8sJmPodTemplate(), appParam.getK8sJmPodTemplate()) ||
                     !ObjectUtils.safeTrimEquals(application.getK8sTmPodTemplate(), appParam.getK8sTmPodTemplate()) ||
                     !ObjectUtils.safeTrimEquals(application.getK8sPodTemplates(), appParam.getK8sPodTemplates()) ||
-                    !ObjectUtils.safeTrimEquals(application.getK8sHadoopIntegration(), appParam.getK8sHadoopIntegration())) {
+                    !ObjectUtils.safeTrimEquals(application.getK8sHadoopIntegration(), appParam.getK8sHadoopIntegration()) ||
+                    !ObjectUtils.safeTrimEquals(application.getFlinkImage(), appParam.getFlinkImage())
+                ) {
                     application.setBuild(true);
                 }
             }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -454,7 +454,7 @@ private void removeApp(Application application) {
             //曾经设置过yarn-application类型,尝试删除,不留后患.
             HdfsOperator.delete(Workspace.of(StorageType.HDFS).APP_WORKSPACE().concat("/").concat(appId.toString()));
         } catch (Exception e) {
-            //skip
+            log.error(e.getMessage(), e);
         }
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1312,7 +1312,8 @@ public void start(Application appParam, boolean auto) throws Exception {
         if (executionMode.equals(ExecutionMode.YARN_APPLICATION)) {
             buildResult = new ShadedBuildResponse(null, flinkUserJar, true);
         } else {
-            if (ExecutionMode.isKubernetesMode(application.getExecutionMode())) {
+            if (ExecutionMode.isKubernetesApplicationMode(application.getExecutionMode())) {
+                assert buildResult != null;
                 DockerImageBuildResponse result = buildResult.as(DockerImageBuildResponse.class);
                 String ingressTemplates = application.getIngressTemplate();
                 String domainName = application.getDefaultModeIngress();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/StreamXConsole.java
Patch:
@@ -83,7 +83,7 @@ private static Integer getPid() {
         try {
             return Integer.parseInt(name.substring(0, name.indexOf('@')));
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
         }
         return -1;
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/CommonUtils.java
Patch:
@@ -537,7 +537,7 @@ public static Double fixedNum(Number number, int offset) {
         try {
             return Double.parseDouble(df.format(number));
         } catch (NumberFormatException e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
             return 0.0;
         }
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/GZipUtils.java
Patch:
@@ -19,6 +19,7 @@
 
 package com.streamxhub.streamx.console.base.util;
 
+import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.compress.archivers.ArchiveInputStream;
 import org.apache.commons.compress.archivers.ArchiveStreamFactory;
 import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
@@ -33,6 +34,7 @@
 /**
  * @author benjobs
  */
+@Slf4j
 public final class GZipUtils {
 
     private GZipUtils() {
@@ -84,7 +86,7 @@ public static File decompress(String tarZipSource, String targetDir) {
                 entry = (TarArchiveEntry) archiveInput.getNextEntry();
             }
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
         }
 
         return unFile;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/MetricsController.java
Patch:
@@ -88,7 +88,7 @@ public RestResponse report(@RequestBody JvmProfiler jvmProfiler) {
                 flameGraphService.save(flameGraph);
             }
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
         }
         return RestResponse.success();
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Project.java
Patch:
@@ -31,6 +31,7 @@
 import com.baomidou.mybatisplus.annotation.TableName;
 import com.fasterxml.jackson.annotation.JsonIgnore;
 import lombok.Data;
+import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.io.FileUtils;
 import org.apache.commons.lang3.StringUtils;
 import org.eclipse.jgit.api.Git;
@@ -51,6 +52,7 @@
 /**
  * @author benjobs
  */
+@Slf4j
 @Data
 @TableName("t_flink_project")
 public class Project implements Serializable {
@@ -179,7 +181,7 @@ public List<String> getAllBranches() {
             }
             return branchList;
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
         }
         return Collections.emptyList();
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationBackUpServiceImpl.java
Patch:
@@ -173,7 +173,7 @@ public void rollback(ApplicationBackUp backParam) {
                     return null;
                 });
             } catch (Exception e) {
-                e.printStackTrace();
+                log.error(e.getMessage(), e);
             }
         });
     }
@@ -207,7 +207,7 @@ public void rollbackFlinkSql(Application application, FlinkSql sql) {
                 return null;
             });
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
         }
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationConfigServiceImpl.java
Patch:
@@ -249,7 +249,7 @@ public synchronized String readTemplate() {
                 this.flinkConfTemplate = Base64.getEncoder().encodeToString(template.getBytes());
             } catch (Exception e) {
                 log.error("Read conf/flink-application.conf failed, please check your deployment");
-                e.printStackTrace();
+                log.error(e.getMessage(), e);
             }
         }
         return this.flinkConfTemplate;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -407,7 +407,7 @@ public Boolean delete(Application paramApp) {
             }
             return true;
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
             throw e;
         }
     }
@@ -768,7 +768,7 @@ public boolean update(Application appParam) {
             baseMapper.updateById(application);
             return true;
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
             return false;
         }
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -203,7 +203,7 @@ public ResponseResult start(FlinkCluster flinkCluster) {
             }
             return result;
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
             updateWrapper.eq(FlinkCluster::getId, flinkCluster.getId());
             updateWrapper.set(FlinkCluster::getClusterState, ClusterState.STOPED.getValue());
             updateWrapper.set(FlinkCluster::getException, e.toString());
@@ -279,7 +279,7 @@ public ResponseResult shutdown(FlinkCluster flinkCluster) {
             result.setMsg("clusterId is not exists!");
             return result;
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
             updateWrapper.set(FlinkCluster::getException, e.toString());
             update(flinkCluster, updateWrapper);
             result.setStatus(0);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -153,7 +153,7 @@ public boolean update(Project projectParam) {
             baseMapper.updateById(project);
             return true;
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
             return false;
         }
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/FlinkTrackingTask.java
Patch:
@@ -248,7 +248,7 @@ private void tracking() {
                                         try {
                                             applicationService.start(application, true);
                                         } catch (Exception e) {
-                                            e.printStackTrace();
+                                            log.error(e.getMessage(), e);
                                         }
                                     }
                                 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/websocket/WebSocketEndpoint.java
Patch:
@@ -69,7 +69,7 @@ public void onClose() throws IOException {
 
     @OnError
     public void onError(Session session, Throwable e) {
-        e.printStackTrace();
+        log.error(e.getMessage(), e);
     }
 
     public static void writeMessage(String socketId, String message) {
@@ -79,7 +79,7 @@ public static void writeMessage(String socketId, String message) {
                 session.getBasicRemote().sendText(message);
             }
         } catch (IOException e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
         }
     }
 
@@ -90,7 +90,7 @@ public static void pushNotice(Message message) {
                 session.getBasicRemote().sendObject(message);
             }
         } catch (Exception e) {
-            e.printStackTrace();
+            log.error(e.getMessage(), e);
         }
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/controller/TeamController.java
Patch:
@@ -26,6 +26,7 @@
 
 import com.baomidou.mybatisplus.core.metadata.IPage;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.shiro.authz.annotation.Logical;
 import org.apache.shiro.authz.annotation.RequiresPermissions;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.validation.annotation.Validated;
@@ -50,7 +51,7 @@ public class TeamController {
     private TeamService teamService;
 
     @PostMapping("list")
-    @RequiresPermissions("team:view")
+    @RequiresPermissions(value = {"team:view", "app:view"}, logical = Logical.OR)
     public RestResponse teamList(RestRequest restRequest, Team team) {
         IPage<Team> groupList = teamService.findTeams(team, restRequest);
         return RestResponse.success(groupList);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/controller/UserController.java
Patch:
@@ -29,6 +29,7 @@
 import com.baomidou.mybatisplus.core.toolkit.StringPool;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.lang3.StringUtils;
+import org.apache.shiro.authz.annotation.Logical;
 import org.apache.shiro.authz.annotation.RequiresPermissions;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.validation.annotation.Validated;
@@ -62,7 +63,7 @@ public User detail(@NotBlank(message = "{required}") @PathVariable String userna
     }
 
     @PostMapping("list")
-    @RequiresPermissions("user:view")
+    @RequiresPermissions(value = {"user:view", "app:view"}, logical = Logical.OR)
     public RestResponse userList(RestRequest restRequest, User user) {
         IPage<User> userList = userService.findUserDetail(user, restRequest);
         return RestResponse.success(userList);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/FlinkTrackingTask.java
Patch:
@@ -488,7 +488,7 @@ private void getFromYarnRestApi(Application application, StopFrom stopFrom) thro
                 }
             } else {
                 try {
-                    String state = appInfo.getApp().getState();
+                    String state = appInfo.getApp().getFinalStatus();
                     FlinkAppState flinkAppState = FlinkAppState.of(state);
                     if (FlinkAppState.OTHER.equals(flinkAppState)) {
                         return;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/K8sFlinkChangeEventListener.java
Patch:
@@ -100,7 +100,7 @@ public void subscribeJobStatusChange(FlinkJobStatusChangeEvent event) {
         // when a flink job status change event can be received, it means
         // that the operation command sent by streamx has been completed.
         app.setOptionState(OptionState.NONE.getValue());
-        applicationService.update(app);
+        applicationService.updateById(app);
 
         // email alerts when necessary
         FlinkAppState state = FlinkAppState.of(app.getState());
@@ -132,7 +132,7 @@ public void subscribeMetricsChange(FlinkClusterMetricChangeEvent event) {
         app.setTotalTM(metrics.totalTm());
         app.setTotalSlot(metrics.totalSlot());
         app.setAvailableSlot(metrics.availableSlot());
-        applicationService.update(app);
+        applicationService.updateById(app);
     }
 
     @SuppressWarnings("UnstableApiUsage")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/alert/impl/AlertConfigServiceImpl.java
Patch:
@@ -30,6 +30,7 @@
 import com.streamxhub.streamx.console.core.service.ApplicationService;
 import com.streamxhub.streamx.console.core.service.alert.AlertConfigService;
 
+import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
 import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;
 import com.baomidou.mybatisplus.core.metadata.IPage;
 import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
@@ -81,8 +82,7 @@ public boolean exist(AlertConfig alertConfig) {
 
     @Override
     public boolean deleteById(Long id) throws AlertException {
-        int count = applicationService.count(applicationService.lambdaQuery()
-                .eq(Application::getAlertId, id));
+        int count = applicationService.count(new LambdaQueryWrapper<Application>().eq(id != null, Application::getAlertId, id));
         if (count > 0) {
             throw new AlertException(String.format("AlertId:%d, this is bound by application. Please clear the configuration first", id));
         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationService.java
Patch:
@@ -53,6 +53,8 @@ public interface ApplicationService extends IService<Application> {
 
     AppExistsState checkExists(Application app);
 
+    String checkSavepointPath(Application app) throws Exception;
+
     void cancel(Application app) throws Exception;
 
     void updateTracking(Application application);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -201,7 +201,7 @@ public RestResponse forcedStop(Application app) {
 
     @PostMapping("yarn")
     public RestResponse yarn() {
-        return RestResponse.create().data(YarnUtils.getRMWebAppURL());
+        return RestResponse.create().data(YarnUtils.getRMWebAppProxyURL());
     }
 
     @PostMapping("name")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -34,7 +34,6 @@
 import com.streamxhub.streamx.common.util.CompletableFutureUtils;
 import com.streamxhub.streamx.common.util.DeflaterUtils;
 import com.streamxhub.streamx.common.util.ExceptionUtils;
-import com.streamxhub.streamx.common.util.FlinkUtils;
 import com.streamxhub.streamx.common.util.ThreadUtils;
 import com.streamxhub.streamx.common.util.Utils;
 import com.streamxhub.streamx.common.util.YarnUtils;
@@ -1143,7 +1142,7 @@ public void start(Application appParam, boolean auto) throws Exception {
             throw new UnsupportedOperationException("Unsupported...");
         }
 
-        String[] dynamicOption = FlinkUtils.parseDynamicOptions(application.getDynamicOptions());
+        Map<String, String> dynamicOption = FlinkSubmitter.extractDynamicOptionAsJava(application.getDynamicOptions());
 
         Map<String, Object> extraParameter = new HashMap<>(0);
         extraParameter.put(ConfigConst.KEY_JOB_ID(), application.getId());

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -23,7 +23,6 @@
 import com.streamxhub.streamx.common.enums.ClusterState;
 import com.streamxhub.streamx.common.enums.ExecutionMode;
 import com.streamxhub.streamx.common.enums.ResolveOrder;
-import com.streamxhub.streamx.common.util.FlinkUtils;
 import com.streamxhub.streamx.common.util.ThreadUtils;
 import com.streamxhub.streamx.common.util.Utils;
 import com.streamxhub.streamx.console.core.dao.FlinkClusterMapper;
@@ -171,7 +170,7 @@ public ResponseResult start(FlinkCluster flinkCluster) {
             FlinkEnv flinkEnv = flinkEnvService.getById(flinkCluster.getVersionId());
             Map<String, Object> extraParameter = flinkCluster.getOptionMap();
             ResolveOrder resolveOrder = ResolveOrder.of(flinkCluster.getResolveOrder());
-            String[] dynamicOption = FlinkUtils.parseDynamicOptions(flinkCluster.getDynamicOptions());
+            Map<String, String> dynamicOption = FlinkSubmitter.extractDynamicOptionAsJava(flinkCluster.getDynamicOptions());
             DeployRequest deployRequest = new DeployRequest(
                 flinkEnv.getFlinkVersion(),
                 flinkCluster.getClusterId(),

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/alert/AlertTemplate.java
Patch:
@@ -52,6 +52,7 @@ public class AlertTemplate implements Serializable {
     private Boolean restart;
     private Integer restartIndex;
     private Integer totalRestart;
+    private boolean atAll = false;
 
     private static AlertTemplate of(Application application) {
         long duration;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/AlertType.java
Patch:
@@ -35,7 +35,8 @@ public enum AlertType {
     email(1),
     dingTalk(2),
     weCom(4),
-    httpCallback(8);
+    httpCallback(8),
+    lark(16);
 
     private final Integer code;
     private static Map<Integer, AlertType> cacheMap;
@@ -46,7 +47,7 @@ public enum AlertType {
 
     /*
      * 报警方式，二进制位表示
-     * 其中第 1 位表示:邮件报警，第 2 位表示: 钉钉报警，第 3 位表示: 企微报警，第 4 位表示: callback。
+     * 其中第 1 位表示:邮件报警，第 2 位表示: 钉钉报警，第 3 位表示: 企微报警，第 4 位表示: callback，第 5 位表示: 飞书。
      * 示例：
      * level= 3，其二进制位为：0000 0011， 则对应的报警方式位：钉钉，邮件
      * level= 10，其二进制位为：0000 1010， 则对应的报警方式位：钉钉，callback

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/alert/impl/EmailAlertNotifyServiceImpl.java
Patch:
@@ -30,6 +30,7 @@
 import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.mail.HtmlEmail;
 import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.context.annotation.Lazy;
 import org.springframework.stereotype.Service;
 import org.springframework.util.StringUtils;
 
@@ -44,6 +45,7 @@
  */
 @Slf4j
 @Service
+@Lazy
 public class EmailAlertNotifyServiceImpl implements AlertNotifyService {
 
     private Template template;
@@ -65,7 +67,7 @@ public boolean doAlert(AlertConfigWithParams alertConfig, AlertTemplate template
             this.senderEmail = settingService.getSenderEmail();
         }
         String contacts = alertConfig.getEmailParams() == null ? null : alertConfig.getEmailParams().getContacts();
-        if (this.senderEmail != null && !StringUtils.isEmpty(contacts)) {
+        if (this.senderEmail != null && StringUtils.hasLength(contacts)) {
             String[] emails = contacts.split(",");
             return sendEmail(template, emails);
         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/FlinkSql.java
Patch:
@@ -86,8 +86,9 @@ public ChangedType checkChange(FlinkSql target) {
         // 1) 判断sql语句是否发生变化
         boolean sqlDifference = !this.getSql().trim().equals(target.getSql().trim());
         // 2) 判断 依赖是否发生变化
-        Application.Dependency thisDependency = Application.Dependency.jsonToDependency(this.getDependency());
-        Application.Dependency targetDependency = Application.Dependency.jsonToDependency(target.getDependency());
+        Application.Dependency thisDependency = Application.Dependency.toDependency(this.getDependency());
+        Application.Dependency targetDependency = Application.Dependency.toDependency(target.getDependency());
+
         boolean depDifference = !thisDependency.eq(targetDependency);
         if (sqlDifference && depDifference) {
             return ChangedType.ALL;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/websocket/WebSocketEndpoint.java
Patch:
@@ -54,15 +54,15 @@ public class WebSocketEndpoint {
 
     @OnOpen
     public void onOpen(Session session, @PathParam("id") String id) {
-        log.info("websocket onOpen....");
+        log.debug("websocket onOpen....");
         this.id = id;
         this.session = session;
         SOCKET_SESSIONS.put(id, session);
     }
 
     @OnClose
     public void onClose() throws IOException {
-        log.info("websocket onClose....");
+        log.debug("websocket onClose....");
         this.session.close();
         SOCKET_SESSIONS.remove(this.id);
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Application.java
Patch:
@@ -504,7 +504,7 @@ public CheckPoints httpCheckpoints(FlinkCluster flinkCluster) throws IOException
         final String flinkUrl = "jobs/%s/checkpoints";
         if (ExecutionMode.isYarnMode(executionMode)) {
             String format = "proxy/%s/" + flinkUrl;
-            String reqURL = String.format(format, appId);
+            String reqURL = String.format(format, appId, jobId);
             return yarnRestRequest(reqURL, CheckPoints.class);
         } else if (ExecutionMode.isRemoteMode(executionMode)) {
             if (jobId != null) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -172,11 +172,11 @@ public FlinkSqlValidationResult verifySql(String sql, Long versionId) {
                 Class<?> clazz = classLoader.loadClass("com.streamxhub.streamx.flink.core.FlinkSqlValidator");
                 Method method = clazz.getDeclaredMethod("verifySql", String.class);
                 method.setAccessible(true);
-                Object sqlError = method.invoke(null, sql);
-                if (sqlError == null) {
+                Object result = method.invoke(null, sql);
+                if (result == null) {
                     return null;
                 }
-                return FlinkShimsProxy.getObject(this.getClass().getClassLoader(), sqlError);
+                return FlinkShimsProxy.getObject(this.getClass().getClassLoader(), result);
             } catch (Throwable e) {
                 log.error("verifySql invocationTargetException: {}", ExceptionUtils.stringifyException(e));
             }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/K8sFlinkTrkMonitorWrapper.java
Patch:
@@ -51,10 +51,10 @@
  * Flink K8s Tracking Monitor Wrapper.
  * <p>
  * todo Notes
- * Currentlty Tracking Monitor of Flink on K8s and on YARN are independent
+ * Currently Tracking Monitor of Flink on K8s and on YARN are independent
  * of each other, this is because the tracking behavior of Flink on K8s is
  * quite difference.
- * Mybe we need to refactor to a unified Flink Tracking Monitor in the
+ * Maybe we need to refactor to a unified Flink Tracking Monitor in the
  * future, both tracking-on-k8s and tracking-on-yarn will exist as plugins
  * for this unified implementation.
  * <p>

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -201,7 +201,7 @@ public RestResponse forcedStop(Application app) {
 
     @PostMapping("yarn")
     public RestResponse yarn() {
-        return RestResponse.create().data(YarnUtils.getRMWebAppURL(false));
+        return RestResponse.create().data(YarnUtils.getRMWebAppURL());
     }
 
     @PostMapping("name")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/AlertServiceImpl.java
Patch:
@@ -176,7 +176,7 @@ private MailTemplate getMailTemplate(Application application) {
         String url = "";
         if (ExecutionMode.isYarnMode(application.getExecutionMode())) {
             String format = "%s/proxy/%s/";
-            url = String.format(format, YarnUtils.getRMWebAppURL(false), application.getAppId());
+            url = String.format(format, YarnUtils.getRMWebAppURL(), application.getAppId());
         }
 
         MailTemplate template = new MailTemplate();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -31,7 +31,7 @@
 import com.streamxhub.streamx.console.core.service.EffectiveService;
 import com.streamxhub.streamx.console.core.service.FlinkEnvService;
 import com.streamxhub.streamx.console.core.service.FlinkSqlService;
-import com.streamxhub.streamx.flink.core.SqlError;
+import com.streamxhub.streamx.flink.core.FlinkSqlValidationResult;
 import com.streamxhub.streamx.flink.proxy.FlinkShimsProxy;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
@@ -165,9 +165,9 @@ public void rollback(Application application) {
     }
 
     @Override
-    public SqlError verifySql(String sql, Long versionId) {
+    public FlinkSqlValidationResult verifySql(String sql, Long versionId) {
         FlinkEnv flinkEnv = flinkEnvService.getById(versionId);
-        return FlinkShimsProxy.proxy(flinkEnv.getFlinkVersion(), (Function<ClassLoader, SqlError>) classLoader -> {
+        return FlinkShimsProxy.proxy(flinkEnv.getFlinkVersion(), (Function<ClassLoader, FlinkSqlValidationResult>) classLoader -> {
             try {
                 Class<?> clazz = classLoader.loadClass("com.streamxhub.streamx.flink.core.FlinkSqlValidator");
                 Method method = clazz.getDeclaredMethod("verifySql", String.class);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/FlinkTrackingTask.java
Patch:
@@ -607,7 +607,6 @@ public static void setOptionState(Long appId, OptionState state) {
             return;
         }
         log.info("flinkTrackingTask setOptioning");
-        Long optioningTime = System.currentTimeMillis();
         OPTIONING.put(appId, state);
         //从streamx停止
         if (state.equals(OptionState.CANCELLING)) {

File: streamx-console/streamx-console-service/src/test/java/SendEmailTest.java
Patch:
@@ -131,7 +131,7 @@ private MailTemplate getAlertBaseInfo(Application application) {
         }
         duration = duration / 1000 / 60;
         String format = "%s/proxy/%s/";
-        String url = String.format(format, YarnUtils.getRMWebAppURL(false), application.getAppId());
+        String url = String.format(format, YarnUtils.getRMWebAppURL(), application.getAppId());
 
         MailTemplate template = new MailTemplate();
         template.setJobName(application.getJobName());

File: streamx-console/streamx-console-service/src/test/java/YarnTest.java
Patch:
@@ -47,7 +47,7 @@ public void getURL() {
          * 将hadoop的配置文件放到一个目录下,
          * 在运行该类的时候加上jvm级别的参数(idea里的 vmOption ) -DHADOOP_CONF_DIR=${目录}
          */
-        String url = YarnUtils.getRMWebAppURL(true);
+        String url = YarnUtils.getRMWebAppURL();
         System.out.println(url);
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -201,7 +201,7 @@ public RestResponse forcedStop(Application app) {
 
     @PostMapping("yarn")
     public RestResponse yarn() {
-        return RestResponse.create().data(YarnUtils.getRMWebAppProxyURL());
+        return RestResponse.create().data(YarnUtils.getRMWebAppURL(false));
     }
 
     @PostMapping("name")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -221,7 +221,7 @@ public Map<String, Serializable> dashboard() {
                 totalJmMemory += v.getJmMemory();
             }
             if (v.getTmMemory() != null) {
-                totalTmMemory += v.getTmMemory();
+                totalTmMemory += v.getTmMemory() * v.getTotalTM();
             }
             if (v.getTotalTM() != null) {
                 totalTm += v.getTotalTM();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -189,7 +189,7 @@ public RestResponse cancel(@ApiIgnore Application app) {
 
     @PostMapping("yarn")
     public RestResponse yarn() {
-        return RestResponse.create().data(HadoopUtils.getRMWebAppURL(false));
+        return RestResponse.create().data(HadoopUtils.getRMWebAppProxyURL());
     }
 
     @PostMapping("name")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/JWTUtil.java
Patch:
@@ -40,6 +40,7 @@
 @Slf4j
 public class JWTUtil {
 
+
     private static final long JWT_TIME_OUT = SpringContextUtils.getBean(ShiroProperties.class).getJwtTimeOut() * 1000;
 
     /**

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/controller/PassportController.java
Patch:
@@ -88,8 +88,8 @@ public RestResponse signin(
 
         // 更新用户登录时间
         this.userService.updateLoginTime(username);
-        String token = WebUtils.encryptToken(JWTUtil.sign(username, password));
         LocalDateTime expireTime = LocalDateTime.now().plusSeconds(properties.getJwtTimeOut());
+        String token = WebUtils.encryptToken(JWTUtil.sign(username, password));
         String expireTimeStr = DateUtils.formatFullTime(expireTime);
         JWTToken jwtToken = new JWTToken(token, expireTimeStr);
         String userId = RandomStringUtils.randomAlphanumeric(20);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/ShiroRealm.java
Patch:
@@ -96,21 +96,21 @@ protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authent
         String token = (String) authenticationToken.getCredentials();
         String username = JWTUtil.getUsername(token);
         if (StringUtils.isBlank(username)) {
-            throw new AuthenticationException("token校验不通过");
+            throw new AuthenticationException("Token verification failed");
         }
         // 通过用户名查询用户信息
         User user = userService.findByName(username);
 
         if (user == null) {
-            throw new AuthenticationException("用户名或密码错误");
+            throw new AuthenticationException("ERROR Incorrect username or password!");
         }
 
         if (!JWTUtil.verify(token, username, user.getPassword())) {
             //校验是否属于api的token，权限是否有效
             String tokenDb = WebUtils.encryptToken(token);
             boolean effective = accessTokenService.checkTokenEffective(user.getUserId(), tokenDb);
             if (!effective) {
-                throw new AuthenticationException("token校验不通过,请检查user状态或token状态");
+                throw new AuthenticationException("Token checked failed: 1-[Browser Request] please check the username or password; 2-[Api Request] please check the user status or accessToken status");
             }
             SecurityUtils.getSubject().getSession().setAttribute(AccessToken.IS_API_TOKEN, true);
         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/impl/AccessTokenServiceImpl.java
Patch:
@@ -38,11 +38,11 @@
 import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
 import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.lang3.StringUtils;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.stereotype.Service;
 import org.springframework.transaction.annotation.Propagation;
 import org.springframework.transaction.annotation.Transactional;
-import org.springframework.util.StringUtils;
 
 import java.util.Date;
 import java.util.List;
@@ -69,7 +69,8 @@ public RestResponse generateToken(Long userId, String expireTime, String descrip
             expireTime = AccessToken.DEFAULT_EXPIRE_TIME;
         }
 
-        String token = WebUtils.encryptToken(JWTUtil.sign(user.getUsername(), UUID.randomUUID().toString(), DateUtils.getTime(expireTime, DateUtils.fullFormat(), TimeZone.getDefault())));
+        Long ttl = DateUtils.getTime(expireTime, DateUtils.fullFormat(), TimeZone.getDefault());
+        String token = WebUtils.encryptToken(JWTUtil.sign(user.getUsername(), UUID.randomUUID().toString(), ttl));
         JWTToken jwtToken = new JWTToken(token, expireTime);
 
         AccessToken accessToken = new AccessToken();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkClusterServiceImpl.java
Patch:
@@ -23,9 +23,9 @@
 import com.streamxhub.streamx.common.enums.ClusterState;
 import com.streamxhub.streamx.common.enums.ExecutionMode;
 import com.streamxhub.streamx.common.enums.ResolveOrder;
+import com.streamxhub.streamx.common.util.FlinkUtils;
 import com.streamxhub.streamx.common.util.ThreadUtils;
 import com.streamxhub.streamx.common.util.Utils;
-import com.streamxhub.streamx.console.base.util.CommonUtils;
 import com.streamxhub.streamx.console.core.dao.FlinkClusterMapper;
 import com.streamxhub.streamx.console.core.entity.FlinkCluster;
 import com.streamxhub.streamx.console.core.entity.FlinkEnv;
@@ -171,7 +171,7 @@ public ResponseResult start(FlinkCluster flinkCluster) {
             FlinkEnv flinkEnv = flinkEnvService.getById(flinkCluster.getVersionId());
             Map<String, Object> extraParameter = flinkCluster.getOptionMap();
             ResolveOrder resolveOrder = ResolveOrder.of(flinkCluster.getResolveOrder());
-            String[] dynamicOption = CommonUtils.notEmpty(flinkCluster.getDynamicOptions()) ? flinkCluster.getDynamicOptions().split("\\s+") : new String[0];
+            String[] dynamicOption = FlinkUtils.parseDynamicOptions(flinkCluster.getDynamicOptions());
             DeployRequest deployRequest = new DeployRequest(
                 flinkEnv.getFlinkVersion(),
                 flinkCluster.getClusterId(),

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/impl/AccessTokenServiceImpl.java
Patch:
@@ -47,6 +47,7 @@
 import java.util.Date;
 import java.util.List;
 import java.util.Objects;
+import java.util.TimeZone;
 import java.util.UUID;
 
 @Slf4j
@@ -68,7 +69,7 @@ public RestResponse generateToken(Long userId, String expireTime, String descrip
             expireTime = AccessToken.DEFAULT_EXPIRE_TIME;
         }
 
-        String token = WebUtils.encryptToken(JWTUtil.sign(user.getUsername(), UUID.randomUUID().toString()));
+        String token = WebUtils.encryptToken(JWTUtil.sign(user.getUsername(), UUID.randomUUID().toString(), DateUtils.getTime(expireTime, DateUtils.fullFormat(), TimeZone.getDefault())));
         JWTToken jwtToken = new JWTToken(token, expireTime);
 
         AccessToken accessToken = new AccessToken();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/FlinkTrackingTask.java
Patch:
@@ -522,7 +522,7 @@ private void getFromYarnRestApi(Application application, StopFrom stopFrom) thro
                 }
             } else {
                 try {
-                    String state = appInfo.getApp().getFinalStatus();
+                    String state = appInfo.getApp().getState();
                     FlinkAppState flinkAppState = FlinkAppState.of(state);
                     if (FlinkAppState.OTHER.equals(flinkAppState)) {
                         return;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/handler/GlobalExceptionHandler.java
Patch:
@@ -19,6 +19,7 @@
 
 package com.streamxhub.streamx.console.base.handler;
 
+import com.streamxhub.streamx.console.base.domain.ResponseCode;
 import com.streamxhub.streamx.console.base.domain.RestResponse;
 import com.streamxhub.streamx.console.base.exception.ApiException;
 import com.streamxhub.streamx.console.base.exception.ServiceException;
@@ -74,7 +75,7 @@ public RestResponse handleException(HttpRequestMethodNotSupportedException e) {
     @ResponseStatus(HttpStatus.OK)
     public RestResponse handleException(ApiException e) {
         log.info("api exception：{}", e.getMessage());
-        return RestResponse.fail("api fail, msg:" + e.getMessage());
+        return RestResponse.fail("api fail, msg:" + e.getMessage(), ResponseCode.CODE_FAIL);
     }
 
     /**

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/aspect/StreamXConsoleAspect.java
Patch:
@@ -77,7 +77,7 @@ public RestResponse response(ProceedingJoinPoint joinPoint) {
         RestResponse response;
         try {
             response = (RestResponse) joinPoint.proceed();
-            response.put("status", "success");
+            response.put("status", RestResponse.STATUS_SUCCESS);
         } catch (Throwable e) {
             e.printStackTrace();
             response =

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/dao/AccessTokenMapper.java
Patch:
@@ -31,4 +31,6 @@ public interface AccessTokenMapper extends BaseMapper<AccessToken> {
     IPage<AccessToken> page(Page<AccessToken> page, @Param("accessToken") AccessToken accessToken);
 
     AccessToken getTokenInfo(@Param("username") String username, @Param("accessToken") String accessToken);
+
+    AccessToken getTokenInfoById(@Param("id") Long id);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationBuildPipelineController.java
Patch:
@@ -73,10 +73,10 @@ public class ApplicationBuildPipelineController {
      * @return Whether the pipeline was successfully started
      */
     @ApiAccess
-    @ApiOperation(value = "Launch application", notes = "Launch application", tags = ApiDocConstant.FLINK_APP_OP_TAG)
+    @ApiOperation(value = "Launch application", notes = "Launch application", tags = ApiDocConstant.FLINK_APP_OP_TAG, consumes = "x-www-form-urlencoded")
     @ApiImplicitParams({
-        @ApiImplicitParam(name = "appId", value = "APP_ID", required = true, dataType = "Long"),
-        @ApiImplicitParam(name = "forceBuild", value = "FORCE_BUILD", required = true, dataType = "Boolean", defaultValue = "false"),
+        @ApiImplicitParam(name = "appId", value = "APP_ID", required = true, paramType = "form", dataType = "Long"),
+        @ApiImplicitParam(name = "forceBuild", value = "FORCE_BUILD", required = true, paramType = "form", dataType = "Boolean", defaultValue = "false"),
     })
     @PostMapping("/build")
     @RequiresPermissions("app:create")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/config/SwaggerConfig.java
Patch:
@@ -50,10 +50,9 @@ public class SwaggerConfig implements WebMvcConfigurer {
 
     @Bean
     public Docket createRestApi() {
-
-        ParameterBuilder tokenPar = new ParameterBuilder();
         List<Parameter> pars = new ArrayList<Parameter>();
-        tokenPar.name("Authorization").description("请在admin管理页面获取 accessToken").modelRef(new ModelRef("string")).parameterType("header").required(false).build();
+        ParameterBuilder tokenPar = new ParameterBuilder();
+        tokenPar.name("Authorization").description("accessToken").modelRef(new ModelRef("string")).parameterType("header").required(true).build();
         pars.add(tokenPar.build());
         return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).select().apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class)).paths(PathSelectors.any()).build().globalOperationParameters(pars);
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -19,7 +19,6 @@
 
 package com.streamxhub.streamx.console.core.controller;
 
-import com.baomidou.mybatisplus.core.metadata.IPage;
 import com.streamxhub.streamx.common.util.HadoopUtils;
 import com.streamxhub.streamx.common.util.Utils;
 import com.streamxhub.streamx.console.base.domain.RestRequest;
@@ -36,6 +35,8 @@
 import com.streamxhub.streamx.console.core.service.ApplicationLogService;
 import com.streamxhub.streamx.console.core.service.ApplicationService;
 import com.streamxhub.streamx.flink.packer.pipeline.PipelineStatus;
+
+import com.baomidou.mybatisplus.core.metadata.IPage;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.shiro.authz.annotation.RequiresPermissions;
 import org.springframework.beans.factory.annotation.Autowired;

File: streamx-common/src/main/scala/com/streamxhub/streamx/common/domain/FlinkMemorySize.java
Patch:
@@ -16,6 +16,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.common.domain;
 
 import com.streamxhub.streamx.common.util.AssertUtils;
@@ -42,7 +43,7 @@ public class FlinkMemorySize implements java.io.Serializable, Comparable<FlinkMe
 
     public static final FlinkMemorySize MAX_VALUE = new FlinkMemorySize(Long.MAX_VALUE);
 
-    private static final List<FlinkMemorySize.MemoryUnit> ORDERED_UNITS = Arrays.asList(BYTES, KILO_BYTES, MEGA_BYTES, GIGA_BYTES, TERA_BYTES);
+    private static final List<MemoryUnit> ORDERED_UNITS = Arrays.asList(BYTES, KILO_BYTES, MEGA_BYTES, GIGA_BYTES, TERA_BYTES);
 
     // ------------------------------------------------------------------------
 
@@ -308,7 +309,7 @@ public static long parseBytes(String text) throws IllegalArgumentException {
         return result;
     }
 
-    private static Optional<FlinkMemorySize.MemoryUnit> parseUnit(String unit) {
+    private static Optional<MemoryUnit> parseUnit(String unit) {
         if (matchesAny(unit, BYTES)) {
             return Optional.of(BYTES);
         } else if (matchesAny(unit, KILO_BYTES)) {

File: streamx-common/src/main/scala/com/streamxhub/streamx/common/enums/DevelopmentMode.java
Patch:
@@ -16,6 +16,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.common.enums;
 
 import java.io.Serializable;

File: streamx-common/src/main/scala/com/streamxhub/streamx/common/enums/ExecutionMode.java
Patch:
@@ -16,6 +16,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.common.enums;
 
 import com.google.common.collect.Lists;

File: streamx-common/src/main/scala/com/streamxhub/streamx/common/enums/SqlErrorType.java
Patch:
@@ -16,6 +16,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.common.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/config/SwaggerConfig.java
Patch:
@@ -20,7 +20,7 @@
 package com.streamxhub.streamx.console.base.config;
 
 import com.github.xiaoymin.swaggerbootstrapui.annotations.EnableSwaggerBootstrapUI;
-import io.swagger.annotations.Api;
+import io.swagger.annotations.ApiOperation;
 import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;
 import org.springframework.context.annotation.Bean;
 import org.springframework.context.annotation.Configuration;
@@ -53,9 +53,9 @@ public Docket createRestApi() {
 
         ParameterBuilder tokenPar = new ParameterBuilder();
         List<Parameter> pars = new ArrayList<Parameter>();
-        tokenPar.name("Authorization").description("access-token").modelRef(new ModelRef("string")).parameterType("header").required(false).build();
+        tokenPar.name("Authorization").description("请在admin管理页面获取 accessToken").modelRef(new ModelRef("string")).parameterType("header").required(false).build();
         pars.add(tokenPar.build());
-        return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).select().apis(RequestHandlerSelectors.withClassAnnotation(Api.class)).paths(PathSelectors.any()).build().globalOperationParameters(pars);
+        return new Docket(DocumentationType.SWAGGER_2).apiInfo(apiInfo()).select().apis(RequestHandlerSelectors.withMethodAnnotation(ApiOperation.class)).paths(PathSelectors.any()).build().globalOperationParameters(pars);
     }
 
     private ApiInfo apiInfo() {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/domain/Constant.java
Patch:
@@ -46,4 +46,5 @@ public class Constant {
     public static final String TYPE_MENU = "0";
     public static final String APP_MENU_ID = "100015";
     public static final String APP_DETAIL_MENU_ID = "100018";
+
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/JWTToken.java
Patch:
@@ -54,4 +54,5 @@ public Object getPrincipal() {
     public Object getCredentials() {
         return token;
     }
+
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/ShiroRealm.java
Patch:
@@ -20,12 +20,14 @@
 package com.streamxhub.streamx.console.system.authentication;
 
 import com.streamxhub.streamx.console.base.util.WebUtils;
+import com.streamxhub.streamx.console.system.entity.AccessToken;
 import com.streamxhub.streamx.console.system.entity.User;
 import com.streamxhub.streamx.console.system.service.AccessTokenService;
 import com.streamxhub.streamx.console.system.service.RoleService;
 import com.streamxhub.streamx.console.system.service.UserService;
 
 import org.apache.commons.lang3.StringUtils;
+import org.apache.shiro.SecurityUtils;
 import org.apache.shiro.authc.AuthenticationException;
 import org.apache.shiro.authc.AuthenticationInfo;
 import org.apache.shiro.authc.AuthenticationToken;
@@ -110,8 +112,8 @@ protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authent
             if (!effective) {
                 throw new AuthenticationException("token校验不通过,请检查user状态或token状态");
             }
+            SecurityUtils.getSubject().getSession().setAttribute(AccessToken.IS_API_TOKEN, true);
         }
-
         return new SimpleAuthenticationInfo(token, token, "streamx_shiro_realm");
     }
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/AccessToken.java
Patch:
@@ -38,6 +38,8 @@ public class AccessToken implements Serializable {
 
     public static final String DEFAULT_PASSWORD = "X-api";
     public static final String DEFAULT_EXPIRE_TIME = "9999-01-01 00:00:00";
+    public static final String IS_API_TOKEN = "is_api_token";
+
 
     @TableId(value = "ID", type = IdType.AUTO)
     private Long id;

File: streamx-flink/streamx-flink-connector/streamx-flink-connector-base/src/main/scala/com/streamxhub/streamx/flink/connector/function/TransformFunction.java
Patch:
@@ -25,7 +25,7 @@
  * @author benjobs
  */
 @FunctionalInterface
-public interface TransformFunction<T,R> extends Serializable {
+public interface TransformFunction<T, R> extends Serializable {
     /**
      * @param bean: bean
      * @return String:

File: streamx-flink/streamx-flink-connector/streamx-flink-connector-mongo/src/main/scala/com/streamxhub/streamx/flink/connector/mongo/source/MongoJavaSource.java
Patch:
@@ -21,9 +21,9 @@
 
 import com.streamxhub.streamx.common.util.Utils;
 import com.streamxhub.streamx.flink.connector.function.RunningFunction;
-import com.streamxhub.streamx.flink.connector.mongo.internal.MongoSourceFunction;
 import com.streamxhub.streamx.flink.connector.mongo.function.MongoQueryFunction;
 import com.streamxhub.streamx.flink.connector.mongo.function.MongoResultFunction;
+import com.streamxhub.streamx.flink.connector.mongo.internal.MongoSourceFunction;
 import com.streamxhub.streamx.flink.core.scala.StreamingContext;
 import org.apache.flink.streaming.api.datastream.DataStreamSource;
 

File: streamx-plugin/streamx-flink-repl/src/main/scala/com/streamxhub/streamx/flink/repl/shell/ScalaShellStreamEnvironment.java
Patch:
@@ -73,7 +73,6 @@ public JobClient executeAsync(StreamGraph streamGraph) throws Exception {
         return super.executeAsync(streamGraph);
     }
 
-
     public static void disableAllContextAndOtherEnvironments() {
         initializeContextEnvironment(
             configuration -> {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/runner/EnvInitializer.java
Patch:
@@ -82,16 +82,16 @@ public void run(ApplicationArguments args) throws Exception {
                 " more detail: http://www.streamxhub.com/docs/user-guide/development");
         }
 
-        // init ConfigHub
-        initConfigHub(context.getEnvironment());
+        // init InternalConfig
+        initInternalConfig(context.getEnvironment());
         // overwrite system variable HADOOP_USER_NAME
         String hadoopUserName = InternalConfigHolder.get(CommonConfig.STREAMX_HADOOP_USER_NAME());
         overrideSystemProp(ConfigConst.KEY_HADOOP_USER_NAME(), hadoopUserName);
         // initialize local file system resources
         storageInitialize(LFS);
     }
 
-    private void initConfigHub(Environment springEnv) {
+    private void initInternalConfig(Environment springEnv) {
         // override config from spring application.yaml
         InternalConfigHolder
             .keys()

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlameGraphServiceImpl.java
Patch:
@@ -84,7 +84,6 @@ public String generateFlameGraph(FlameGraph flameGraph) throws IOException {
             String title = application.getJobName().concat(" ___ FlameGraph");
             // generate...
             List<String> commands = Arrays.asList(
-                    String.format("cd %s", flameGraphPath.getAbsolutePath()),
                     String.format("python ./stackcollapse.py -i %s > %s ", jsonPath, foldedPath),
                     String.format(
                             "./flamegraph.pl --title=\"%s\" --width=%d --colors=java %s > %s ",
@@ -94,7 +93,7 @@ public String generateFlameGraph(FlameGraph flameGraph) throws IOException {
                             svgPath
                     )
             );
-            CommandUtils.execute(commands, (line) -> log.info("flameGraph: {} ", line));
+            CommandUtils.execute(flameGraphPath.getAbsolutePath(), commands, (line) -> log.info("flameGraph: {} ", line));
             return svgPath;
         }
         return null;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/StreamXConsole.java
Patch:
@@ -25,7 +25,6 @@
 import org.springframework.boot.autoconfigure.SpringBootApplication;
 import org.springframework.boot.context.ApplicationPidFileWriter;
 import org.springframework.scheduling.annotation.EnableScheduling;
-import org.springframework.web.bind.annotation.CrossOrigin;
 
 import java.io.File;
 import java.lang.management.ManagementFactory;
@@ -55,7 +54,6 @@
  * @author benjobs
  */
 @Slf4j
-@CrossOrigin
 @SpringBootApplication
 @EnableScheduling
 public class StreamXConsole {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -259,7 +259,7 @@ public RestResponse verifySchema(String path) {
         final String scheme = uri.getScheme();
         final String pathPart = uri.getPath();
         RestResponse restResponse = RestResponse.create().data(true);
-        String error = null;
+        String error;
         if (scheme == null) {
             error = "The scheme (hdfs://, file://, etc) is null. Please specify the file system scheme explicitly in the URI.";
             restResponse.data(false).message(error);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -128,6 +128,7 @@ public boolean update(Project projectParam) {
             project.setPassword(projectParam.getPassword());
             project.setPom(projectParam.getPom());
             project.setDescription(projectParam.getDescription());
+            project.setBuildArgs(projectParam.getBuildArgs());
             if (projectParam.getBuildState() != null) {
                 project.setBuildState(projectParam.getBuildState());
                 if (BuildState.of(projectParam.getBuildState()).equals(BuildState.NEED_REBUILD)) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -210,8 +210,8 @@ public RestResponse rollback(ApplicationBackUp backUp) {
         return RestResponse.create();
     }
 
-    @PostMapping("startlog")
-    public RestResponse startlog(ApplicationLog applicationLog, RestRequest request) {
+    @PostMapping("optionlog")
+    public RestResponse optionlog(ApplicationLog applicationLog, RestRequest request) {
         IPage<ApplicationLog> applicationList = applicationLogService.page(applicationLog, request);
         return RestResponse.create().data(applicationList);
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Application.java
Patch:
@@ -757,7 +757,7 @@ public void doSetHotParams() {
     @SneakyThrows
     public void updateHotParams(Application appParam) {
         ExecutionMode executionModeEnum = appParam.getExecutionModeEnum();
-        Map<String, String> hotParams = new HashMap<>();
+        Map<String, String> hotParams = new HashMap<>(0);
         if (ExecutionMode.YARN_APPLICATION.equals(executionModeEnum)) {
             if (StringUtils.isNotEmpty(appParam.getYarnQueue())) {
                 hotParams.put(ConfigConst.KEY_YARN_APP_QUEUE(), appParam.getYarnQueue());

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/ApplicationLog.java
Patch:
@@ -48,9 +48,9 @@ public class ApplicationLog {
     private Boolean success;
 
     /**
-     * 启动时间
+     * 操作时间
      */
-    private Date startTime;
+    private Date optionTime;
 
     /**
      * 启动失败的异常

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationLogServiceImpl.java
Patch:
@@ -46,7 +46,7 @@ public class ApplicationLogServiceImpl extends ServiceImpl<ApplicationLogMapper,
     @Override
     public IPage<ApplicationLog> page(ApplicationLog applicationLog, RestRequest request) {
         Page<Application> page = new Page<>();
-        SortUtils.handlePageSort(request, page, "start_time", Constant.ORDER_DESC, false);
+        SortUtils.handlePageSort(request, page, "option_time", Constant.ORDER_DESC, false);
         return this.baseMapper.page(page, applicationLog.getAppId());
     }
 

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/sink/doris/DorisSinkFunction.java
Patch:
@@ -29,6 +29,7 @@
 import org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper;
 import org.apache.flink.streaming.api.checkpoint.CheckpointedFunction;
 import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
 import org.apache.flink.util.concurrent.ExecutorThreadFactory;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -111,7 +112,7 @@ public void open(Configuration parameters) throws Exception {
     }
 
     @Override
-    public void invoke(T value, Context context) throws Exception {
+    public void invoke(T value, SinkFunction.Context context) throws Exception {
         checkFlushException();
         addBatch(value);
         if (batchSize > 0 && batch.size() >= batchSize) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/StreamXConsole.java
Patch:
@@ -46,7 +46,7 @@
  *      GitHub :  https://github.com/streamxhub/streamx
  *      Gitee  :  https://gitee.com/streamxhub/streamx
  *
- *      [StreamX] Make stream processing easier ô‿ô!
+ *      [StreamX] Make stream processing easier ô~ô!
  *
  *      十步杀一人 千里不留行 事了拂衣去 深藏身与名
  *

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationBackUpService.java
Patch:
@@ -34,7 +34,7 @@ public interface ApplicationBackUpService extends IService<ApplicationBackUp> {
 
     Boolean delete(Long id) throws ServiceException;
 
-    void backup(Application app);
+    void backup(Application application, FlinkSql flinkSql);
 
     IPage<ApplicationBackUp> page(ApplicationBackUp backUp, RestRequest request);
 

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/sink/doris/DorisStreamLoad.java
Patch:
@@ -129,7 +129,7 @@ protected boolean isRedirectable(String method) {
     private String getBasicAuthHeader(String username, String password) {
         String auth = username + ":" + password;
         byte[] encodedAuth = Base64.encodeBase64(auth.getBytes(StandardCharsets.UTF_8));
-        return new StringBuilder("Basic ").append(new String(encodedAuth)).toString();
+        return "Basic " + new String(encodedAuth);
     }
 
     public static class LoadResponse {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/SpringContextUtils.java
Patch:
@@ -31,6 +31,7 @@
  */
 @Component
 public class SpringContextUtils implements ApplicationContextAware {
+
     private static ApplicationContext applicationContext;
 
     @Override

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationBuildPipelineController.java
Patch:
@@ -74,7 +74,7 @@ public RestResponse buildApplication(Long appId, boolean forceBuild) {
                 return RestResponse.create().data(false);
             }
             Application app = applicationService.getById(appId);
-            // 检查是否需要走build这一步流程(如:jar和pom发送变化了则需要走build流程,其他普通参数修改了,不需要走build流程)
+            // 检查是否需要走build这一步流程(jar和pom发生变化了则需要走build流程, 其他普通参数修改了,不需要走build流程)
             boolean needBuild = applicationService.checkBuildAndUpdate(app);
             if (!needBuild) {
                 return RestResponse.create().data(true);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/ProjectMapper.java
Patch:
@@ -33,12 +33,12 @@ public interface ProjectMapper extends BaseMapper<Project> {
 
     IPage<Project> findProject(Page<Project> page, @Param("project") Project project);
 
-    @Update("update t_flink_project set BUILDSTATE=2 where id=#{project.id}")
+    @Update("update t_flink_project set BUILD_STATE=2 where id=#{project.id}")
     void failureBuild(@Param("project") Project project);
 
-    @Update("update t_flink_project set lastBuild=now(),BUILDSTATE=1 where id=#{project.id}")
+    @Update("update t_flink_project set LAST_BUILD = now(),BUILD_STATE=1 where id=#{project.id}")
     void successBuild(@Param("project") Project project);
 
-    @Update("update t_flink_project set BUILDSTATE=0 where id=#{project.id}")
+    @Update("update t_flink_project set BUILD_STATE=0 where id=#{project.id}")
     void startBuild(@Param("project") Project project);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationService.java
Patch:
@@ -87,4 +87,5 @@ public interface ApplicationService extends IService<Application> {
 
     List<Application> getByProjectId(Long id);
 
+    boolean checkBuildAndUpdate(Application app);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -135,7 +135,7 @@ public boolean update(Project projectParam) {
                     // 更新部署状态
                     FlinkTrackingTask.refreshTracking(() -> applications.forEach((app) -> {
                         log.info("update deploy by project: {}, appName:{}", project.getName(), app.getJobName());
-                        app.setLaunch(LaunchState.NEED_CHECK_AFTER_PROJECT_CHANGED.get());
+                        app.setLaunch(LaunchState.NEED_CHECK.get());
                         applicationService.updateLaunch(app);
                     }));
                 }
@@ -195,7 +195,7 @@ public void build(Long id, String socketId) throws Exception {
                         // 更新部署状态
                         FlinkTrackingTask.refreshTracking(() -> applications.forEach((app) -> {
                             log.info("update deploy by project: {}, appName:{}", project.getName(), app.getJobName());
-                            app.setLaunch(LaunchState.NEED_LAUNCH_AFTER_BUILD.get());
+                            app.setLaunch(LaunchState.NEED_LAUNCH.get());
                             this.applicationService.updateLaunch(app);
                         }));
                     } catch (Exception e) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplBuildPipeServiceImpl.java
Patch:
@@ -297,6 +297,7 @@ private BuildPipeline createPipelineInstance(@Nonnull Application app) {
                 );
                 log.info("Submit params to building pipeline : {}", yarnAppRequest);
                 return FlinkYarnApplicationBuildPipeline.of(yarnAppRequest);
+            case YARN_PER_JOB:
             case YARN_SESSION:
             case REMOTE:
                 FlinkRemoteBuildRequest remoteBuildRequest = new FlinkRemoteBuildRequest(

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1004,7 +1004,7 @@ public boolean start(Application appParam, boolean auto) throws Exception {
                         ConfigConst.KEY_FLINK_APPLICATION_MAIN_CLASS(),
                         application.getMainClass()
                     );
-                    flinkUserJar = String.format("%s/%s", application.getAppHome(), application.getJar());
+                    flinkUserJar = String.format("%s/%s", application.getAppLib(), application.getJar());
                 } else {
                     switch (application.getApplicationType()) {
                         case STREAMX_FLINK:
@@ -1017,7 +1017,7 @@ public boolean start(Application appParam, boolean auto) throws Exception {
                                 ConfigConst.KEY_FLINK_APPLICATION_MAIN_CLASS(),
                                 application.getMainClass()
                             );
-                            flinkUserJar = String.format("%s/%s", application.getAppHome(), application.getJar());
+                            flinkUserJar = String.format("%s/%s", application.getAppLib(), application.getJar());
                             break;
                         default:
                             throw new IllegalArgumentException("[StreamX] ApplicationType must be (StreamX flink | Apache flink)... ");

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/AppBuildPipeline.java
Patch:
@@ -19,6 +19,7 @@
 
 package com.streamxhub.streamx.console.core.entity;
 
+import com.baomidou.mybatisplus.annotation.IdType;
 import com.baomidou.mybatisplus.annotation.TableField;
 import com.baomidou.mybatisplus.annotation.TableId;
 import com.baomidou.mybatisplus.annotation.TableName;
@@ -65,7 +66,7 @@
 @Slf4j
 public class AppBuildPipeline {
 
-    @TableId(value = "app_id")
+    @TableId(value = "app_id", type = IdType.INPUT)
     private Long appId;
 
     @TableField(value = "pipe_type")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplBuildPipeServiceImpl.java
Patch:
@@ -292,6 +292,7 @@ private BuildPipeline createPipelineInstance(@Nonnull Application app) {
                 );
                 log.info("Submit params to building pipeline : {}", yarnAppRequest);
                 return FlinkYarnApplicationBuildPipeline.of(yarnAppRequest);
+            case YARN_SESSION:
             case REMOTE:
                 FlinkRemoteBuildRequest remoteBuildRequest = new FlinkRemoteBuildRequest(
                         app.getJobName(),

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationBackUpServiceImpl.java
Patch:
@@ -244,7 +244,7 @@ public Boolean delete(Long id) throws ServiceException {
     @Transactional(rollbackFor = {Exception.class})
     public void backup(Application application) {
         //1) 基础的配置文件备份
-        String appHome = application.isCustomCodeJob() ? application.getDistHome() : application.getAppHome();
+        String appHome = (application.isCustomCodeJob() && application.isCICDJob()) ? application.getDistHome() : application.getAppHome();
         FsOperator fsOperator = application.getFsOperator();
         if (fsOperator.exists(appHome)) {
             // 3) 需要备份的做备份,移动文件到备份目录...

File: streamx-common/src/main/scala/com/streamxhub/streamx/common/enums/ApplicationType.java
Patch:
@@ -41,8 +41,9 @@ public enum ApplicationType implements Serializable {
      * Apache Spark
      */
     APACHE_SPARK(4, "Apache Spark");
-    int type;
-    String name;
+
+    private final int type;
+    private final String name;
 
     ApplicationType(int type, String name) {
         this.type = type;

File: streamx-common/src/main/scala/com/streamxhub/streamx/common/enums/DevelopmentMode.java
Patch:
@@ -18,10 +18,12 @@
  */
 package com.streamxhub.streamx.common.enums;
 
+import java.io.Serializable;
+
 /**
  * @author benjobs
  */
-public enum DevelopmentMode {
+public enum DevelopmentMode implements Serializable {
 
     /**
      * custom code

File: streamx-common/src/main/scala/com/streamxhub/streamx/common/enums/FlinkK8sRestExposedType.java
Patch:
@@ -19,10 +19,12 @@
 
 package com.streamxhub.streamx.common.enums;
 
+import java.io.Serializable;
+
 /**
  * kubernetes.rest-service.exposed.type
  */
-public enum FlinkK8sRestExposedType {
+public enum FlinkK8sRestExposedType implements Serializable {
 
     /**
      * LoadBalancer

File: streamx-common/src/main/scala/com/streamxhub/streamx/common/enums/StorageType.java
Patch:
@@ -21,7 +21,9 @@
 
 import org.apache.commons.lang3.StringUtils;
 
-public enum StorageType {
+import java.io.Serializable;
+
+public enum StorageType implements Serializable {
 
     /**
      * hdfs

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkSqlController.java
Patch:
@@ -64,7 +64,7 @@ public RestResponse verify(String sql, Long versionId) {
             RestResponse response = RestResponse.create()
                 .data(false)
                 .message(sqlError.exception())
-                .put("type", sqlError.errorType().errorType)
+                .put("type", sqlError.errorType().getValue())
                 .put("start", start)
                 .put("end", end);
             //语法异常

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/AppExistsState.java
Patch:
@@ -52,7 +52,7 @@ public enum AppExistsState implements Serializable {
      */
     INVALID(4);
 
-    int value;
+    private final int value;
 
     AppExistsState(int value) {
         this.value = value;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/BuildState.java
Patch:
@@ -51,7 +51,7 @@ public enum BuildState implements Serializable {
      */
     FAILED(2);
 
-    int value;
+    private final int value;
 
     BuildState(int value) {
         this.value = value;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/ChangedType.java
Patch:
@@ -48,7 +48,7 @@ public enum ChangedType implements Serializable {
     ALL(3);
 
 
-    int value;
+    private final int value;
 
     ChangedType(int value) {
         this.value = value;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/CheckPointType.java
Patch:
@@ -37,7 +37,7 @@ public enum CheckPointType implements Serializable {
 
     SYNC_SAVEPOINT(3);
 
-    int value;
+    private final int value;
 
     public int get() {
         return this.value;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/EffectiveType.java
Patch:
@@ -34,7 +34,7 @@ public enum EffectiveType implements Serializable {
      */
     FLINKSQL(2);
 
-    int type;
+    private final int type;
 
     EffectiveType(int value) {
         this.type = value;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/FlinkAppState.java
Patch:
@@ -137,7 +137,7 @@ public enum FlinkAppState implements Serializable {
      */
     KILLED(-9);
 
-    int value;
+    private final int value;
 
     FlinkAppState(int value) {
         this.value = value;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/GitAuthorizedError.java
Patch:
@@ -47,7 +47,7 @@ public enum GitAuthorizedError implements Serializable {
      */
     UNKNOW(3);
 
-    int value;
+    private final int value;
 
     GitAuthorizedError(int value) {
         this.value = value;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/LaunchState.java
Patch:
@@ -84,7 +84,7 @@ public enum LaunchState implements Serializable {
      */
     REVOKED(10);
 
-    int value;
+    private final int value;
 
     LaunchState(int value) {
         this.value = value;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/OptionState.java
Patch:
@@ -53,7 +53,7 @@ public enum OptionState implements Serializable {
      */
     SAVEPOINTING(4);
 
-    int value;
+    private final int value;
 
     OptionState(int value) {
         this.value = value;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/ResourceFrom.java
Patch:
@@ -19,13 +19,14 @@
 
 package com.streamxhub.streamx.console.core.enums;
 
+import java.io.Serializable;
 import java.util.Arrays;
 
 /**
  * @author benjobs
  */
 
-public enum ResourceFrom {
+public enum ResourceFrom implements Serializable {
 
     /**
      * cicd(build from cvs)
@@ -37,7 +38,7 @@ public enum ResourceFrom {
      */
     UPLOAD(2);
 
-    Integer value;
+    private final Integer value;
 
     ResourceFrom(Integer value) {
         this.value = value;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplBuildPipeServiceImpl.java
Patch:
@@ -169,12 +169,13 @@ public void onStart(PipeSnapshot snapshot) throws Exception {
                 applicationService.checkEnv(app);
 
                 // 2) some preparatory work
+                String appUploads = app.getWorkspace().APP_UPLOADS();
                 if (app.isCustomCodeJob()) {
+                    // customCode upload jar to appHome...
                     String appHome = app.getAppHome();
                     FsOperator fsOperator = app.getFsOperator();
                     fsOperator.delete(appHome);
                     if (app.isUploadJob()) {
-                        String appUploads = app.getWorkspace().APP_UPLOADS();
                         File temp = WebUtils.getAppTempDir();
                         File localJar = new File(temp, app.getJar());
                         String targetJar = appUploads.concat("/").concat(app.getJar());
@@ -191,7 +192,6 @@ public void onStart(PipeSnapshot snapshot) throws Exception {
                         for (String jar : app.getDependencyObject().getJar()) {
                             File jarFile = new File(WebUtils.getAppTempDir(), jar);
                             assert jarFile.exists();
-                            String appUploads = Workspace.local().APP_UPLOADS();
                             String targetJar = appUploads.concat("/").concat(jar);
                             checkOrElseUploadJar(FsOperator.lfs(), jarFile, targetJar, appUploads);
                         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/JacksonUtils.java
Patch:
@@ -30,7 +30,7 @@
 
 import java.text.SimpleDateFormat;
 
-public class JsonUtils {
+public class JacksonUtils {
 
     private static final ObjectMapper MAPPER;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/FlinkEnv.java
Patch:
@@ -24,7 +24,7 @@
 import com.streamxhub.streamx.common.util.DeflaterUtils;
 import com.streamxhub.streamx.common.util.PropertiesUtils;
 import lombok.Data;
-import net.minidev.json.annotate.JsonIgnore;
+import com.fasterxml.jackson.annotation.JsonIgnore;
 import org.apache.commons.io.FileUtils;
 
 import java.io.File;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/FlinkSql.java
Patch:
@@ -24,7 +24,6 @@
 import com.streamxhub.streamx.common.util.DeflaterUtils;
 import com.streamxhub.streamx.console.core.enums.ChangedType;
 import lombok.Data;
-import net.minidev.json.annotate.JsonIgnore;
 
 import java.util.Base64;
 import java.util.Date;
@@ -40,7 +39,6 @@ public class FlinkSql {
     @TableField("`sql`")
     private String sql;
     private String dependency;
-    @JsonIgnore
     private Integer version = 1;
 
     /**
@@ -51,7 +49,6 @@ public class FlinkSql {
      */
     private Integer candidate;
 
-    @JsonIgnore
     private Date createTime;
     private transient boolean effective = false;
     /**

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/AppBuildPipeService.java
Patch:
@@ -39,7 +39,7 @@ public interface AppBuildPipeService extends IService<AppBuildPipeline> {
      * Build application.
      * This is an async call method.
      */
-    boolean buildApplication(@Nonnull Application app);
+    boolean buildApplication(@Nonnull Application app) throws Exception;
 
     /**
      * Get current build pipeline instance of specified application

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationService.java
Patch:
@@ -52,8 +52,6 @@ public interface ApplicationService extends IService<Application> {
 
     AppExistsState checkExists(Application app);
 
-    void deploy(Application app, String socketId);
-
     void cancel(Application app);
 
     void updateTracking(Application application);
@@ -88,4 +86,5 @@ public interface ApplicationService extends IService<Application> {
     void updateDeploy(Application application);
 
     List<Application> getByProjectId(Long id);
+
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -239,8 +239,8 @@ private void deploy(Project project) throws Exception {
                 // 2) .jar文件(普通,官方标准的flink工程)
                 Utils.checkJarFile(app.toURI().toURL());
                 String moduleName = app.getName().replace(".jar", "");
-                File appBase = project.getDistHome();
-                File targetDir = new File(appBase, moduleName);
+                File distHome = project.getDistHome();
+                File targetDir = new File(distHome, moduleName);
                 if (!targetDir.exists()) {
                     targetDir.mkdirs();
                 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/controller/MenuController.java
Patch:
@@ -22,7 +22,7 @@
 import com.baomidou.mybatisplus.core.toolkit.StringPool;
 import com.streamxhub.streamx.console.base.domain.RestResponse;
 import com.streamxhub.streamx.console.base.domain.router.VueRouter;
-import com.streamxhub.streamx.console.system.authentication.ServerComponent;
+import com.streamxhub.streamx.console.core.service.CommonService;
 import com.streamxhub.streamx.console.system.entity.Menu;
 import com.streamxhub.streamx.console.system.service.MenuService;
 import lombok.extern.slf4j.Slf4j;
@@ -53,11 +53,11 @@ public class MenuController {
     private MenuService menuService;
 
     @Autowired
-    private ServerComponent serverComponent;
+    private CommonService commonService;
 
     @PostMapping("router")
     public RestResponse getUserRouters() {
-        ArrayList<VueRouter<Menu>> routers = this.menuService.getUserRouters(serverComponent.getUser());
+        ArrayList<VueRouter<Menu>> routers = this.menuService.getUserRouters(commonService.getCurrentUser());
         return RestResponse.create().data(routers);
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -551,7 +551,8 @@ else if (ExecutionMode.isKubernetesMode(appParam.getExecutionMode())
     @Transactional(rollbackFor = {Exception.class})
     public boolean create(Application appParam) {
         appParam.setUserId(serverComponent.getUser().getUserId());
-        appParam.setState(FlinkAppState.CREATED.getValue());
+        appParam.setState(FlinkAppState.ADDED.getValue());
+        appParam.setDeploy(DeployState.NEED_DEPLOY_AFTER_BUILD.get());
         appParam.setOptionState(OptionState.NONE.getValue());
         appParam.setCreateTime(new Date());
         appParam.doSetHotParams();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/SettingService.java
Patch:
@@ -28,7 +28,7 @@
  */
 public interface SettingService extends IService<Setting> {
 
-    String KEY_MAVEN_REPOSITORY = "maven.central.repository";
+    String KEY_MAVEN_REPOSITORY = "streamx.maven.central.repository";
     String KEY_STREAMX_ADDRESS = "streamx.console.webapp.address";
 
     String KEY_ALERT_EMAIL_HOST = "alert.email.host";

File: streamx-plugin/streamx-flink-packer/src/main/java/com/streamxhub/streamx/flink/packer/pipeline/PipelineType.java
Patch:
@@ -85,7 +85,7 @@ public enum PipelineType {
                     .put(2, "Resolve maven dependencies")
                     .put(3, "upload jar to yarn.provided.lib.dirs")
                     .build(),
-            DockerImageBuildResponse.class
+            SimpleBuildResponse.class
     );
 
 

File: streamx-plugin/streamx-flink-packer/src/main/java/com/streamxhub/streamx/flink/packer/pipeline/PipeType.java
Patch:
@@ -74,7 +74,7 @@ public enum PipeType {
             .put(1, "Create building workspace")
             .put(2, "Build shaded flink app jar")
             .build(),
-        FlinkStandaloneBuildResponse.class
+        FlinkRemoteBuildResponse.class
     ),
     // todo FLINK_YARN_APPLICATION(),
     // todo FLINK_YARN_SESSION(),

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/StreamXConsole.java
Patch:
@@ -46,7 +46,7 @@
  *      GitHub :  https://github.com/streamxhub/streamx
  *      Gitee  :  https://gitee.com/streamxhub/streamx
  *
- *      [StreamX] Make Flink|Spark easier ô‿ô!
+ *      [StreamX] Make stream processing easier ô‿ô!
  *
  *      十步杀一人 千里不留行 事了拂衣去 深藏身与名
  *

File: streamx-common/src/main/scala/com/streamxhub/streamx/common/enums/ApplicationType.java
Patch:
@@ -19,10 +19,12 @@
 package com.streamxhub.streamx.common.enums;
 
 
+import java.io.Serializable;
+
 /**
  * @author benjobs
  */
-public enum ApplicationType {
+public enum ApplicationType implements Serializable {
     /**
      * StreamX Flink
      */

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Application.java
Patch:
@@ -28,6 +28,7 @@
 import com.streamxhub.streamx.common.conf.ConfigConst;
 import com.streamxhub.streamx.common.conf.K8sFlinkConfig;
 import com.streamxhub.streamx.common.conf.Workspace;
+import com.streamxhub.streamx.common.enums.ApplicationType;
 import com.streamxhub.streamx.common.enums.DevelopmentMode;
 import com.streamxhub.streamx.common.enums.ExecutionMode;
 import com.streamxhub.streamx.common.enums.FlinkK8sRestExposedType;
@@ -39,7 +40,6 @@
 import com.streamxhub.streamx.common.util.Utils;
 import com.streamxhub.streamx.console.base.util.JsonUtils;
 import com.streamxhub.streamx.console.base.util.ObjectUtils;
-import com.streamxhub.streamx.console.core.enums.ApplicationType;
 import com.streamxhub.streamx.console.core.enums.DeployState;
 import com.streamxhub.streamx.console.core.enums.FlinkAppState;
 import com.streamxhub.streamx.console.core.enums.ResourceFrom;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -28,6 +28,7 @@
 import com.streamxhub.streamx.common.conf.ConfigConst;
 import com.streamxhub.streamx.common.conf.Workspace;
 import com.streamxhub.streamx.common.domain.FlinkMemorySize;
+import com.streamxhub.streamx.common.enums.ApplicationType;
 import com.streamxhub.streamx.common.enums.DevelopmentMode;
 import com.streamxhub.streamx.common.enums.ExecutionMode;
 import com.streamxhub.streamx.common.enums.ResolveOrder;
@@ -57,7 +58,6 @@
 import com.streamxhub.streamx.console.core.entity.Project;
 import com.streamxhub.streamx.console.core.entity.SavePoint;
 import com.streamxhub.streamx.console.core.enums.AppExistsState;
-import com.streamxhub.streamx.console.core.enums.ApplicationType;
 import com.streamxhub.streamx.console.core.enums.CandidateType;
 import com.streamxhub.streamx.console.core.enums.ChangedType;
 import com.streamxhub.streamx.console.core.enums.CheckPointType;
@@ -1292,7 +1292,7 @@ public boolean start(Application appParam, boolean auto) throws Exception {
                 resolveOrder,
                 application.getJobName(),
                 appConf,
-                application.getApplicationType().getName(),
+                application.getApplicationType(),
                 getSavePointed(appParam),
                 appParam.getFlameGraph() ? getFlameGraph(application) : null,
                 option.toString(),

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1007,7 +1007,9 @@ public Application getApp(Application appParam) {
 
         if (ExecutionMode.YARN_APPLICATION.equals(application.getExecutionModeEnum())) {
             if (!application.getHotParamsMap().isEmpty()) {
-                application.setYarnQueue(application.getHotParamsMap().get(ConfigConst.KEY_YARN_APP_QUEUE()).toString());
+                if (application.getHotParamsMap().containsKey(ConfigConst.KEY_YARN_APP_QUEUE())) {
+                    application.setYarnQueue(application.getHotParamsMap().get(ConfigConst.KEY_YARN_APP_QUEUE()).toString());
+                }
             }
         }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -252,7 +252,7 @@ public Map<String, Serializable> dashboard() {
             }
         }
 
-        // mergee metrics from flink kubernetes cluster
+        // merge metrics from flink kubernetes cluster
         FlinkMetricCV k8sMetric = k8sFlinkTrkMonitor.getAccClusterMetrics();
         totalJmMemory += k8sMetric.totalJmMemory();
         totalTmMemory += k8sMetric.totalTmMemory();
@@ -288,13 +288,13 @@ public void tailMvnDownloading(Long id) {
     @Override
     public String upload(MultipartFile file) throws Exception {
         String temp = WebUtils.getAppDir("temp");
-        File saveFile = new File(temp, file.getOriginalFilename());
+        File saveFile = new File(temp, Objects.requireNonNull(file.getOriginalFilename()));
         // delete when exists
         if (saveFile.exists()) {
             saveFile.delete();
         }
         // save file to temp dir
-        FileUtils.writeByteArrayToFile(saveFile, file.getBytes());
+        file.transferTo(saveFile);
         return saveFile.getAbsolutePath();
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -931,6 +931,9 @@ private void uploadDependency(Application application, Collection<String> depend
                 String targetJar = appUploads.concat("/").concat(jar);
                 checkOrElseUploadJar(application, localJar, targetJar);
                 //3) 将upload目录下的文件上传到app/lib下.
+                if (!fsOperator.exists(application.getAppLib())) {
+                    fsOperator.mkdirs(application.getAppLib());
+                }
                 fsOperator.copy(targetJar, application.getAppLib(), false, true);
             }
         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/runner/EnvInitializer.java
Patch:
@@ -87,7 +87,6 @@ public void run(ApplicationArguments args) throws Exception {
     }
 
     private void initConfigHub(Environment springEnv) {
-        ConfigHub.init();
         // override config from spring application.yaml
         ConfigHub
             .keys()

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/TreeUtils.java
Patch:
@@ -113,7 +113,7 @@ public static <T> ArrayList<VueRouter<T>> buildVueRouter(List<VueRouter<T>> rout
 
         ArrayList<VueRouter<T>> list = new ArrayList<>();
         VueRouter<T> root = new VueRouter<>();
-        root.setName("主页");
+        root.setName("Root");
         root.setComponent("BasicView");
         root.setPath("/");
         root.setChildren(topRoutes);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/impl/MenuServiceImpl.java
Patch:
@@ -123,7 +123,7 @@ public void deleteMenus(String[] menuIds) throws Exception {
     @Override
     public ArrayList<VueRouter<Menu>> getUserRouters(User user) {
         List<VueRouter<Menu>> routes = new ArrayList<>();
-        // 只差type为菜单类型
+        // 查询type为菜单类型
         List<Menu> menus = this.findUserMenus(user.getUsername());
         menus.forEach(menu -> {
             VueRouter<Menu> route = new VueRouter<>();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/runner/EnvInitializer.java
Patch:
@@ -74,7 +74,7 @@ public void run(ApplicationArguments args) throws Exception {
             throw new ExceptionInInitializerError("[StreamX] System initialization check failed," +
                 " The system initialization check failed. If started local for development and debugging," +
                 " please ensure the -Dapp.home parameter is clearly specified," +
-                " more detail: http://www.streamxhub.com/zh/doc/console/deployment");
+                " more detail: http://www.streamxhub.com/docs/user-guide/development");
         }
 
         // init ConfigHub

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/runner/EnvInitializer.java
Patch:
@@ -19,6 +19,7 @@
 
 package com.streamxhub.streamx.console.core.runner;
 
+import com.streamxhub.streamx.common.conf.CommonConfig;
 import com.streamxhub.streamx.common.conf.ConfigConst;
 import com.streamxhub.streamx.common.conf.ConfigHub;
 import com.streamxhub.streamx.common.conf.ConfigOption;
@@ -79,7 +80,7 @@ public void run(ApplicationArguments args) throws Exception {
         // init ConfigHub
         initConfigHub(context.getEnvironment());
         // overwrite system variable HADOOP_USER_NAME
-        String hadoopUserName = ConfigHub.get(ConfigConst.KEY_HADOOP_USER_NAME());
+        String hadoopUserName = ConfigHub.get(CommonConfig.STREAMX_HADOOP_USER_NAME());
         overrideSystemProp(ConfigConst.KEY_HADOOP_USER_NAME(), hadoopUserName);
         // initialize local file system resources
         storageInitialize(LFS);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/runner/EnvInitializer.java
Patch:
@@ -75,15 +75,12 @@ public void run(ApplicationArguments args) throws Exception {
                 " please ensure the -Dapp.home parameter is clearly specified," +
                 " more detail: http://www.streamxhub.com/zh/doc/console/deployment");
         }
-        overrideSystemProp(ConfigConst.KEY_DOCKER_IMAGE_NAMESPACE(), ConfigConst.DOCKER_IMAGE_NAMESPACE_DEFAULT());
 
         // init ConfigHub
         initConfigHub(context.getEnvironment());
-
         // overwrite system variable HADOOP_USER_NAME
         String hadoopUserName = ConfigHub.get(ConfigConst.KEY_HADOOP_USER_NAME());
         overrideSystemProp(ConfigConst.KEY_HADOOP_USER_NAME(), hadoopUserName);
-
         // initialize local file system resources
         storageInitialize(LFS);
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Application.java
Patch:
@@ -25,6 +25,7 @@
 import com.fasterxml.jackson.annotation.JsonFormat;
 import com.fasterxml.jackson.annotation.JsonIgnore;
 import com.fasterxml.jackson.core.type.TypeReference;
+import com.streamxhub.streamx.common.conf.K8sFlinkConfig;
 import com.streamxhub.streamx.common.conf.Workspace;
 import com.streamxhub.streamx.common.enums.DevelopmentMode;
 import com.streamxhub.streamx.common.enums.ExecutionMode;
@@ -64,7 +65,6 @@
 import java.util.Objects;
 import java.util.stream.Collectors;
 
-import static com.streamxhub.streamx.common.conf.ConfigurationOptions.KUBERNETES_NAMESPACE_DEFAULT_VALUE;
 import static com.streamxhub.streamx.console.core.enums.FlinkAppState.of;
 
 /**
@@ -118,7 +118,7 @@ public class Application implements Serializable {
     /**
      * k8s部署下的namespace
      */
-    private String k8sNamespace = KUBERNETES_NAMESPACE_DEFAULT_VALUE;
+    private String k8sNamespace = K8sFlinkConfig.DEFAULT_KUBERNETES_NAMESPACE();
 
 
     private Integer state;
@@ -278,7 +278,7 @@ public class Application implements Serializable {
     private transient AppControl appControl;
 
     public void setK8sNamespace(String k8sNamespace) {
-        this.k8sNamespace = StringUtils.isBlank(k8sNamespace) ? KUBERNETES_NAMESPACE_DEFAULT_VALUE : k8sNamespace;
+        this.k8sNamespace = StringUtils.isBlank(k8sNamespace) ? K8sFlinkConfig.DEFAULT_KUBERNETES_NAMESPACE() : k8sNamespace;
     }
 
     public K8sPodTemplates getK8sPodTemplates() {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -78,7 +78,9 @@ public boolean create(FlinkEnv version) throws Exception {
     @Override
     public void update(FlinkEnv version) throws IOException {
         FlinkEnv flinkEnv = super.getById(version.getId());
-        assert flinkEnv != null;
+        if (flinkEnv == null){
+            throw new RuntimeException("flink home message lost, please check database status!");
+        }
         flinkEnv.setDescription(version.getDescription());
         flinkEnv.setFlinkName(version.getFlinkName());
         if (!version.getFlinkHome().equals(flinkEnv.getFlinkHome())) {

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/api/command/HackPullImageResultCallback.java
Patch:
@@ -21,7 +21,6 @@
 
 import com.github.dockerjava.api.listener.PullImageCallbackListener;
 import com.github.dockerjava.api.model.PullResponseItem;
-import org.apache.commons.lang3.tuple.Pair;
 
 /**
  * @author Al-assad
@@ -37,8 +36,8 @@ public HackPullImageResultCallback(PullImageCallbackListener listener) {
     @Override
     public void onNext(PullResponseItem item) {
         super.onNext(item);
-        if (item.getProgressDetail() != null && item.getId() != null){
-            listener.watchPullProcess(Pair.of(item.getId(), item));
+        if (item.getStatus() != null && item.getId() != null){
+            listener.watchPullProcess(item);
         }
     }
 

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/api/command/HackPushImageResultCallback.java
Patch:
@@ -22,7 +22,6 @@
 import com.github.dockerjava.api.listener.PushImageCallbackListener;
 import com.github.dockerjava.api.model.PushResponseItem;
 import com.github.dockerjava.core.command.PushImageResultCallback;
-import org.apache.commons.lang3.tuple.Pair;
 
 /**
  * @author Al-assad
@@ -40,7 +39,7 @@ public HackPushImageResultCallback(PushImageCallbackListener listener) {
     public void onNext(PushResponseItem item) {
         super.onNext(item);
         if (item.getStatus() != null && item.getId() != null) {
-            listener.watchPushProcess(Pair.of(item.getId(), item));
+            listener.watchPushProcess(item);
         }
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/FlinkTrackingTask.java
Patch:
@@ -40,6 +40,7 @@
 import com.streamxhub.streamx.console.core.service.SavePointService;
 import lombok.Data;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.lang3.StringUtils;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.scheduling.annotation.Scheduled;
 import org.springframework.stereotype.Component;
@@ -254,7 +255,7 @@ private void tracking() {
      */
     private void getFromFlinkRestApi(Application application, StopFrom stopFrom) throws Exception {
         JobsOverview jobsOverview = application.httpJobsOverview();
-        Optional<JobsOverview.Job> optional = jobsOverview.getJobs().stream().findFirst();
+        Optional<JobsOverview.Job> optional = jobsOverview.getJobs().size() > 1 ? jobsOverview.getJobs().stream().filter(a -> StringUtils.equals(application.getJobId(), a.getId())).findFirst() : jobsOverview.getJobs().stream().findFirst();
 
         if (optional.isPresent()) {
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/NoteBookController.java
Patch:
@@ -49,4 +49,5 @@ public void submit(Note note) {
     public void submit2(Note note) {
         noteBookService.submit2(note);
     }
+
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/K8sFlinkChangeEventListener.java
Patch:
@@ -106,7 +106,7 @@ public void persistentK8sFlinkJobStatusChange(FlinkJobStatusChangeEvent event) {
 
         // email alerts when necessary
         FlinkAppState state = FlinkAppState.of(app.getState());
-        if (FlinkAppState.FAILED.equals(state) || FlinkAppState.LOST.equals(state)){
+        if (FlinkAppState.FAILED.equals(state) || FlinkAppState.LOST.equals(state)) {
             Application finalApp = app;
             executor.execute(() -> alertService.alert(finalApp, state));
         }
@@ -144,7 +144,7 @@ private Application updateApplicationWithJobStatusCV(Application app, JobStatusC
             }
         }
         app.setStartTime(new Date(startTime > 0 ? startTime : 0));
-        app.setEndTime(new Date(endTime > 0 && endTime >= startTime ? endTime : 0));
+        app.setEndTime(endTime > 0 && endTime >= startTime ? new Date(endTime) : null);
         app.setDuration(duration > 0 ? duration : 0);
 
         return app;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Application.java
Patch:
@@ -41,6 +41,7 @@
 import com.streamxhub.streamx.console.core.enums.ApplicationType;
 import com.streamxhub.streamx.console.core.enums.DeployState;
 import com.streamxhub.streamx.console.core.enums.FlinkAppState;
+import com.streamxhub.streamx.console.core.enums.ResourceFrom;
 import com.streamxhub.streamx.console.core.metrics.flink.CheckPoints;
 import com.streamxhub.streamx.console.core.metrics.flink.JobsOverview;
 import com.streamxhub.streamx.console.core.metrics.flink.Overview;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -67,7 +67,6 @@
 import com.streamxhub.streamx.console.core.enums.FlinkAppState;
 import com.streamxhub.streamx.console.core.enums.NoticeType;
 import com.streamxhub.streamx.console.core.enums.OptionState;
-import com.streamxhub.streamx.console.core.enums.ResourceFrom;
 import com.streamxhub.streamx.console.core.metrics.flink.JobsOverview;
 import com.streamxhub.streamx.console.core.runner.EnvInitializer;
 import com.streamxhub.streamx.console.core.service.ApplicationBackUpService;
@@ -752,7 +751,7 @@ public void deploy(Application application, String socketId) {
                             FsOperator fsOperator = application.getFsOperator();
                             fsOperator.delete(appHome);
                             if (application.isUploadJob()) {
-                                String APP_UPLOADS = application.getWorkspace().APP_UPLOADS();
+                                String appUploads = application.getWorkspace().APP_UPLOADS();
                                 String temp = WebUtils.getAppDir("temp");
                                 File localJar = new File(temp, application.getJar());
                                 String targetJar = appUploads.concat("/").concat(application.getJar());
@@ -1241,7 +1240,7 @@ public boolean start(Application appParam, boolean auto) throws Exception {
             } else {
                 FlinkSql flinkSql = flinkSqlService.getEffective(application.getId(), false);
                 jarPackDeps = Application.Dependency.jsonToDependency(flinkSql.getDependency()).toJarPackDeps();
-                optionMap.put(ConfigConst.keyFlinkSql(null), flinkSql.getSql());
+                optionMap.put(ConfigConst.KEY_FLINK_SQL(null), flinkSql.getSql());
             }
 
             ResolveOrder resolveOrder = ResolveOrder.of(application.getResolveOrder());

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/config/AsyncExecutorPoolConfig.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.config;
 
 import org.springframework.context.annotation.Bean;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/config/CorssOriginConfig.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.config;
 
 import org.springframework.context.annotation.Bean;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/config/MybatisPlusConfig.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.config;
 
 import com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/config/P6spySqlFormatConfig.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.config;
 
 import com.p6spy.engine.spy.appender.MessageFormattingStrategy;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/config/WebMvcConfig.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.config;
 
 import com.fasterxml.jackson.databind.DeserializationFeature;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/config/WebSocketConfig.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.config;
 
 import org.springframework.context.annotation.Bean;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/domain/Constant.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.domain;
 
 /**

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/domain/RestRequest.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.domain;
 
 import lombok.Data;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/domain/RestResponse.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.domain;
 
 import java.util.HashMap;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/domain/router/RouterMeta.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.domain.router;
 
 import com.fasterxml.jackson.annotation.JsonInclude;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/domain/router/RouterTree.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.domain.router;
 
 import com.fasterxml.jackson.annotation.JsonInclude;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/domain/router/VueRouter.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.domain.router;
 
 import com.fasterxml.jackson.annotation.JsonIgnore;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/exception/ServiceException.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.exception;
 
 /**

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/handler/GlobalExceptionHandler.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.handler;
 
 import com.baomidou.mybatisplus.core.toolkit.StringPool;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/properties/ShiroProperties.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.properties;
 
 import lombok.Data;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/EncryptUtils.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.util;
 
 import javax.crypto.Cipher;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/JsonUtils.java
Patch:
@@ -18,8 +18,8 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.console.base.util;
 
+package com.streamxhub.streamx.console.base.util;
 
 import com.fasterxml.jackson.annotation.JsonInclude;
 import com.fasterxml.jackson.core.JsonProcessingException;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/ObjectUtils.java
Patch:
@@ -142,9 +142,7 @@ public static boolean containsConstant(Enum<?>[] enumValues, String constant) {
     public static boolean containsConstant(
         Enum<?>[] enumValues, String constant, boolean caseSensitive) {
         for (Enum<?> candidate : enumValues) {
-            if (caseSensitive
-                ? candidate.toString().equals(constant)
-                : candidate.toString().equalsIgnoreCase(constant)) {
+            if (caseSensitive ? candidate.toString().equals(constant) : candidate.toString().equalsIgnoreCase(constant)) {
                 return true;
             }
         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/ShaHashUtils.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.util;
 
 import org.apache.shiro.crypto.hash.Sha256Hash;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/SortUtils.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.util;
 
 import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/SpringContextUtils.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.util;
 
 import org.springframework.beans.BeansException;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/TreeUtils.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.util;
 
 import com.streamxhub.streamx.console.base.domain.router.RouterTree;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/util/WebUtils.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.base.util;
 
 import com.baomidou.mybatisplus.core.toolkit.StringPool;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/annotation/RefreshCache.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.annotation;
 
 import java.lang.annotation.ElementType;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/aspect/StreamXConsoleAspect.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.aspect;
 
 import com.streamxhub.streamx.common.util.ExceptionUtils;
@@ -50,7 +51,6 @@ public class StreamXConsoleAspect {
     public void response() {
     }
 
-
     @Pointcut("@annotation(com.streamxhub.streamx.console.core.annotation.RefreshCache)")
     public void refreshCache() {
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -14,6 +14,7 @@
  * express or implied. See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;
@@ -188,7 +189,6 @@ public RestResponse backups(ApplicationBackUp backUp, RestRequest request) {
         return RestResponse.create().data(backups);
     }
 
-
     @PostMapping("rollback")
     public RestResponse rollback(ApplicationBackUp backUp) {
         //TODO: next version implementation

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationHistoryController.java
Patch:
@@ -14,6 +14,7 @@
  * express or implied. See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.streamxhub.streamx.common.enums.ExecutionMode;
@@ -41,9 +42,9 @@
 @RequestMapping("flink/history")
 public class ApplicationHistoryController {
 
-    private final int DEFAULT_HISTORY_RECORD_LIMIT = 25;
+    private static final int DEFAULT_HISTORY_RECORD_LIMIT = 25;
 
-    private final int DEFAULT_HISTORY_POD_TMPL_RECORD_LIMIT = 5;
+    private static final int DEFAULT_HISTORY_POD_TMPL_RECORD_LIMIT = 5;
 
     @Autowired
     private ApplicationHistoryService applicationHistoryService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ConfigController.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkEnvController.java
Patch:
@@ -14,6 +14,7 @@
  * express or implied. See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.streamxhub.streamx.console.base.domain.RestResponse;
@@ -29,7 +30,6 @@
 
 import java.util.List;
 
-
 /**
  * @author benjobs
  */

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkPodTemplateController.java
Patch:
@@ -14,13 +14,14 @@
  * express or implied. See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.streamxhub.streamx.common.util.HostsUtils;
 import com.streamxhub.streamx.console.base.domain.RestResponse;
 import com.streamxhub.streamx.flink.kubernetes.PodTemplateParser;
 import lombok.extern.slf4j.Slf4j;
-import org.apache.commons.lang.StringUtils;
+import org.apache.commons.lang3.StringUtils;
 import org.springframework.validation.annotation.Validated;
 import org.springframework.web.bind.annotation.PostMapping;
 import org.springframework.web.bind.annotation.RequestMapping;
@@ -94,5 +95,4 @@ public RestResponse previewHostAlias(String hosts) {
         return RestResponse.create().data(podTemplate);
     }
 
-
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkSqlController.java
Patch:
@@ -14,6 +14,7 @@
  * express or implied. See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.streamxhub.streamx.common.enums.SqlErrorType;
@@ -32,7 +33,6 @@
 
 import java.util.List;
 
-
 /**
  * @author benjobs
  */

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/IndexController.java
Patch:
@@ -14,6 +14,7 @@
  * express or implied. See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import org.springframework.stereotype.Controller;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/MetricsController.java
Patch:
@@ -14,6 +14,7 @@
  * express or implied. See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;
@@ -51,7 +52,7 @@
 @RequestMapping("metrics")
 public class MetricsController {
 
-    private final String STACKTRACE_PROFILER_NAME = "Stacktrace";
+    private static final String STACKTRACE_PROFILER_NAME = "Stacktrace";
 
     @Autowired
     private FlameGraphService flameGraphService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ProjectController.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/SavePointController.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/SettingController.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/TutorialController.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.controller;
 
 import com.streamxhub.streamx.console.base.domain.RestResponse;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/ApplicationBackUpMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/ApplicationConfigMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/ApplicationLogMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/ApplicationMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;
@@ -53,7 +54,6 @@ public interface ApplicationMapper extends BaseMapper<Application> {
     @Update("update t_flink_app set option_state=0")
     void resetOptionState();
 
-
     @Select("select k8s_namespace from " +
         "(select k8s_namespace, max(create_time) as ct from t_flink_app " +
         "where k8s_namespace is not null group by k8s_namespace order by ct desc) as ns " +
@@ -93,6 +93,4 @@ public interface ApplicationMapper extends BaseMapper<Application> {
         "limit #{limitSize}")
     List<String> getRecentK8sTmPodTemplate(@Param("limitSize") int limit);
 
-
-
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/EffectiveMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/FlameGraphMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/FlinkEnvMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/FlinkSqlMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/MessageMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/ProjectMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/SavePointMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/SettingMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/TutorialMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/ApplicationBackUp.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.TableName;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/ApplicationConfig.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.FieldStrategy;
@@ -65,7 +66,6 @@ public class ApplicationConfig {
 
     private transient boolean effective = false;
 
-
     public void setToApplication(Application application) {
         String unzipString = DeflaterUtils.unzipString(content);
         String encode = Base64.getEncoder().encodeToString(unzipString.getBytes());

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/ApplicationLog.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.TableName;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Effective.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.TableName;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/FlameGraph.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.TableName;
@@ -54,7 +55,7 @@ public class FlameGraph {
 
     private transient Integer width = 1280;
 
-    private final transient Integer QUERY_DURATION = 60 * 4;
+    private static final transient Integer QUERY_DURATION = 60 * 4;
 
     @JsonIgnore
     public Date getStart() {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/FlinkEnv.java
Patch:
@@ -14,8 +14,8 @@
  * express or implied. See the License for the specific language governing permissions and
  * limitations under the License.
  */
-package com.streamxhub.streamx.console.core.entity;
 
+package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.TableName;
 import com.streamxhub.streamx.common.domain.FlinkVersion;
@@ -113,5 +113,4 @@ public String getVersionOfLast() {
         return this.version.split("\\.")[2];
     }
 
-
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/FlinkSql.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.TableField;
@@ -64,7 +65,6 @@ public class FlinkSql {
      */
     private transient boolean dependencyDifference = false;
 
-
     public FlinkSql() {
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Message.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.TableName;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Note.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import lombok.AllArgsConstructor;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/SavePoint.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.TableName;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/SenderEmail.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import lombok.Data;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Setting.java
Patch:
@@ -18,8 +18,8 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.console.core.entity;
 
+package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.TableField;
 import com.baomidou.mybatisplus.annotation.TableName;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Tutorial.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.entity;
 
 import com.baomidou.mybatisplus.annotation.TableName;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/AppExistsState.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/ApplicationType.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/CandidateType.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/ChangedType.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/CheckPointStatus.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.util.Arrays;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/CheckPointType.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/DeployState.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/EffectiveType.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/GitAuthorizedError.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/NoticeType.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/OptionState.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import lombok.Getter;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/ResourceFrom.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.util.Arrays;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/StopFrom.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.enums;
 
 import java.io.Serializable;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/metrics/flink/CheckPoints.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.metrics.flink;
 
 import com.fasterxml.jackson.annotation.JsonProperty;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/metrics/flink/JobsOverview.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.metrics.flink;
 
 import com.fasterxml.jackson.annotation.JsonProperty;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/metrics/flink/JvmProfiler.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.metrics.flink;
 
 import com.fasterxml.jackson.annotation.JsonIgnore;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/metrics/flink/MailTemplate.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.metrics.flink;
 
 import lombok.Data;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/metrics/flink/Overview.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.metrics.flink;
 
 import com.fasterxml.jackson.annotation.JsonProperty;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/metrics/yarn/AppInfo.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.metrics.yarn;
 
 import com.fasterxml.jackson.annotation.JsonIgnoreProperties;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/AlertService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.streamxhub.streamx.console.core.entity.Application;
@@ -36,8 +37,6 @@ public interface AlertService {
      */
     void alert(Application application, CheckPointStatus checkPointStatus);
 
-
     void alert(Application application, FlinkAppState appState);
 
-
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationBackUpService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationConfigService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationHistoryService.java
Patch:
@@ -14,6 +14,7 @@
  * express or implied. See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.streamxhub.streamx.common.enums.StorageType;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationLogService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/EffectiveService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.extension.service.IService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/FlameGraphService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.extension.service.IService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/FlinkEnvService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.extension.service.IService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/FlinkSqlService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.extension.service.IService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/MessageService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/NoteBookService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.streamxhub.streamx.console.core.entity.Note;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ProjectService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/SavePointService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/SettingService.java
Patch:
@@ -18,13 +18,13 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.extension.service.IService;
 import com.streamxhub.streamx.console.core.entity.SenderEmail;
 import com.streamxhub.streamx.console.core.entity.Setting;
 
-
 /**
  * @author benjobs
  */

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/TutorialService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service;
 
 import com.baomidou.mybatisplus.extension.service.IService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationConfigServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service.impl;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
@@ -64,7 +65,7 @@ public class ApplicationConfigServiceImpl
 
     private String flinkConfTemplate = null;
 
-    private String PROD_ENV_NAME = "prod";
+    private String prodEnvName = "prod";
 
     @Autowired
     private ApplicationContext context;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationHistoryServiceImpl.java
Patch:
@@ -14,6 +14,7 @@
  * express or implied. See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package com.streamxhub.streamx.console.core.service.impl;
 
 import com.streamxhub.streamx.common.conf.Workspace;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationLogServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service.impl;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/EffectiveServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service.impl;
 
 import com.baomidou.mybatisplus.core.conditions.Wrapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlameGraphServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service.impl;
 
 import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service.impl;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service.impl;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/MessageServiceImpl.java
Patch:
@@ -18,8 +18,8 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.console.core.service.impl;
 
+package com.streamxhub.streamx.console.core.service.impl;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
 import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/NoteBookServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service.impl;
 
 import com.streamxhub.streamx.common.util.ThreadUtils;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/SavePointServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service.impl;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
@@ -61,7 +62,6 @@ public void obsolete(Long appId) {
         this.baseMapper.obsolete(appId);
     }
 
-
     @Override
     public boolean save(SavePoint entity) {
         this.expire(entity);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/TutorialServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.service.impl;
 
 import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/K8sFlinkChangeEventListener.java
Patch:
@@ -114,7 +114,6 @@ public void persistentK8sFlinkJobStatusChange(FlinkJobStatusChangeEvent event) {
         }
     }
 
-
     private Application updateApplicationWithJobStatusCV(Application app, JobStatusCV jobStatus) {
         // infer the final flink job state
         Enumeration.Value state = jobStatus.jobState();
@@ -183,5 +182,4 @@ public void persistentK8sFlinkMetricsChange(FlinkClusterMetricChangeEvent event)
         applicationService.update(update);
     }
 
-
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/PackerResourceGCTask.java
Patch:
@@ -19,6 +19,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.task;
 
 import com.streamxhub.streamx.flink.packer.PackerResourceGC;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/websocket/WebSocketEndpoint.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.core.websocket;
 
 import com.streamxhub.streamx.console.core.entity.Message;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/JWTFilter.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.authentication;
 
 import com.baomidou.mybatisplus.core.toolkit.StringPool;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/JWTToken.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.authentication;
 
 import lombok.Data;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/JWTUtil.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.authentication;
 
 import com.auth0.jwt.JWT;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/ServerComponent.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.authentication;
 
 import com.streamxhub.streamx.console.system.entity.User;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/ShiroConfig.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.authentication;
 
 import org.apache.shiro.mgt.SecurityManager;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/ShiroRealm.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.authentication;
 
 import com.streamxhub.streamx.console.system.entity.User;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/controller/PassportController.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.controller;
 
 import com.streamxhub.streamx.common.util.DateUtils;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/dao/MenuMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/dao/RoleMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/dao/RoleMenuMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/dao/UserMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/dao/UserRoleMapper.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.dao;
 
 import com.baomidou.mybatisplus.core.mapper.BaseMapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/Menu.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.entity;
 
 import com.baomidou.mybatisplus.annotation.IdType;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/Role.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.entity;
 
 import com.baomidou.mybatisplus.annotation.IdType;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/RoleMenu.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.entity;
 
 import com.baomidou.mybatisplus.annotation.TableName;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/SysLog.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.entity;
 
 import com.baomidou.mybatisplus.annotation.IdType;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/User.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.entity;
 
 import com.baomidou.mybatisplus.annotation.IdType;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/UserRole.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.entity;
 
 import com.baomidou.mybatisplus.annotation.TableName;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/runner/StartedUpRunner.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.runner;
 
 import com.streamxhub.streamx.common.conf.ConfigConst;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/MenuService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.service;
 
 import com.baomidou.mybatisplus.extension.service.IService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/RoleMenuServie.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.service;
 
 import com.baomidou.mybatisplus.extension.service.IService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/RoleService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.service;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/UserRoleService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.service;
 
 import com.baomidou.mybatisplus.extension.service.IService;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/UserService.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.service;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/impl/RoleMenuServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.service.impl;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/impl/RoleServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.service.impl;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
@@ -45,7 +46,6 @@
 import java.util.Set;
 import java.util.stream.Collectors;
 
-
 @Slf4j
 @Service
 @Transactional(propagation = Propagation.SUPPORTS, readOnly = true, rollbackFor = Exception.class)

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/service/impl/UserRoleServiceImpl.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.console.system.service.impl;
 
 import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
@@ -50,7 +51,6 @@ public void deleteUserRolesByUserId(String[] userIds) {
         Arrays.stream(userIds).forEach(id -> baseMapper.deleteByUserId(Long.valueOf(id)));
     }
 
-
     @Override
     public List<String> findUserIdsByRoleId(String[] roleIds) {
         List<UserRole> list =

File: streamx-console/streamx-console-service/src/test/java/StreamXConsoleTest.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 import com.streamxhub.streamx.console.StreamXConsole;
 import com.streamxhub.streamx.console.core.entity.Application;
 import com.streamxhub.streamx.console.core.service.ApplicationService;
@@ -43,7 +44,7 @@ public void start() throws Exception {
         application.setSavePointed(false);
         application.setAllowNonRestored(false);
 
-        boolean status = applicationService.start(application,false);
+        boolean status = applicationService.start(application, false);
         System.out.println(status);
     }
 

File: streamx-console/streamx-console-service/src/test/java/YarnTest.java
Patch:
@@ -11,7 +11,7 @@
 public class YarnTest {
 
     @Test
-    public void vCore() throws IOException, YarnException {
+    public void vcore() throws IOException, YarnException {
         int numYarnMaxVcores = HadoopUtils.yarnClient().getNodeReports(NodeState.RUNNING)
             .stream()
             .mapToInt(report -> report.getCapability().getVirtualCores())
@@ -30,7 +30,6 @@ public void getURL() {
         System.out.println(url);
     }
 
-
     @Test
     public void loadFlinkYaml() {
         String path = System.getenv("FLINK_HOME").concat("/conf/flink-conf.yaml");
@@ -39,5 +38,4 @@ public void loadFlinkYaml() {
         System.out.println(map.size());
     }
 
-
 }

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/function/HBaseQueryFunction.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.function;
 
 import com.streamxhub.streamx.flink.core.java.wrapper.HBaseQuery;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/function/HBaseResultFunction.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.function;
 
 import org.apache.hadoop.hbase.client.Result;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/function/MongoQueryFunction.java
Patch:
@@ -18,13 +18,13 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.function;
 
 import com.mongodb.client.FindIterable;
 import com.mongodb.client.MongoCollection;
 import org.bson.Document;
 
-
 /**
  * @author benjobs
  */

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/function/MongoResultFunction.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.function;
 
 import com.mongodb.client.MongoCursor;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/function/RunningFunction.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.function;
 
 import java.io.Serializable;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/function/SQLFromFunction.java
Patch:
@@ -18,8 +18,8 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.flink.core.java.function;
 
+package com.streamxhub.streamx.flink.core.java.function;
 
 import java.io.Serializable;
 

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/function/SQLQueryFunction.java
Patch:
@@ -18,8 +18,8 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.flink.core.java.function;
 
+package com.streamxhub.streamx.flink.core.java.function;
 
 import java.io.Serializable;
 

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/function/SQLResultFunction.java
Patch:
@@ -18,8 +18,8 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.flink.core.java.function;
 
+package com.streamxhub.streamx.flink.core.java.function;
 
 import java.io.Serializable;
 import java.util.Map;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/function/StreamEnvConfigFunction.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.function;
 
 import org.apache.flink.api.java.utils.ParameterTool;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/function/TableEnvConfigFunction.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.function;
 
 import org.apache.flink.api.java.utils.ParameterTool;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/sink/JdbcSink.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.sink;
 
 import com.streamxhub.streamx.common.util.AssertUtils;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/sink/KafkaSink.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.sink;
 
 import com.streamxhub.streamx.flink.core.scala.StreamingContext;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/source/HBaseSource.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.source;
 
 import com.streamxhub.streamx.common.util.Utils;
@@ -30,7 +31,6 @@
 
 import java.util.Properties;
 
-
 /**
  * @author benjobs
  */

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/source/JdbcSource.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.source;
 
 import com.streamxhub.streamx.common.util.ConfigUtils;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/source/KafkaSource.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.source;
 
 import com.streamxhub.streamx.flink.core.scala.StreamingContext;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/source/MongoSource.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.source;
 
 import com.streamxhub.streamx.common.util.Utils;

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/wrapper/HBaseQuery.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core.java.wrapper;
 
 import com.streamxhub.streamx.common.util.HBaseClient;

File: streamx-flink/streamx-flink-shims/streamx-flink-shims-base/src/main/java/com/streamxhub/streamx/flink/core/StreamEnvConfigFunction.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core;
 
 import org.apache.flink.api.java.utils.ParameterTool;

File: streamx-flink/streamx-flink-shims/streamx-flink-shims-base/src/main/java/com/streamxhub/streamx/flink/core/TableEnvConfigFunction.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.flink.core;
 
 import org.apache.flink.api.java.utils.ParameterTool;

File: streamx-flink/streamx-flink-test/streamx-flink-test-datastream/src/main/java/com/streamxhub/streamx/test/flink/java/bean/LogBean.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.test.flink.java.bean;
 
 import lombok.Data;

File: streamx-flink/streamx-flink-test/streamx-flink-test-datastream/src/main/java/com/streamxhub/streamx/test/flink/java/bean/OrderInfo.java
Patch:
@@ -18,8 +18,8 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.test.flink.java.bean;
 
+package com.streamxhub.streamx.test.flink.java.bean;
 
 import lombok.Data;
 

File: streamx-flink/streamx-flink-test/streamx-flink-test-datastream/src/main/java/com/streamxhub/streamx/test/flink/java/datastream/KafkaJavaApp.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.test.flink.java.datastream;
 
 import com.streamxhub.streamx.flink.core.StreamEnvConfig;
@@ -75,5 +76,4 @@ public LogBean deserialize(ConsumerRecord<byte[], byte[]> record) {
         context.start();
     }
 
-
 }

File: streamx-flink/streamx-flink-test/streamx-flink-test-tablesql/src/main/java/com/streamxhub/streamx/test/flink/java/bean/LogBean.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.test.flink.java.bean;
 
 import lombok.Data;

File: streamx-flink/streamx-flink-test/streamx-flink-test-tablesql/src/main/java/com/streamxhub/streamx/test/flink/java/bean/OrderInfo.java
Patch:
@@ -18,8 +18,8 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.test.flink.java.bean;
 
+package com.streamxhub.streamx.test.flink.java.bean;
 
 import lombok.Data;
 

File: streamx-flink/streamx-flink-test/streamx-flink-test-tablesql/src/main/java/com/streamxhub/streamx/test/flink/java/tablesql/JavaTableApp.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.streamxhub.streamx.test.flink.java.tablesql;
 
 import org.apache.flink.table.api.EnvironmentSettings;

File: streamx-plugin/streamx-flink-kubernetes/src/main/java/org/apache/flink/kubernetes/kubeclient/resources/CompKubernetesDeployment.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package org.apache.flink.kubernetes.kubeclient.resources;
 
 import io.fabric8.kubernetes.api.model.apps.Deployment;

File: streamx-plugin/streamx-flink-kubernetes/src/main/java/org/apache/flink/kubernetes/kubeclient/resources/CompatibleKubernetesWatcher.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package org.apache.flink.kubernetes.kubeclient.resources;
 
 import io.fabric8.kubernetes.api.model.HasMetadata;

File: streamx-plugin/streamx-flink-kubernetes/src/main/java/org/apache/flink/kubernetes/kubeclient/resources/SilentWatchCallbackHandler.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package org.apache.flink.kubernetes.kubeclient.resources;
 
 import org.apache.flink.kubernetes.kubeclient.FlinkKubeClient;

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/api/command/HackBuildImageResultCallback.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.github.dockerjava.api.command;
 
 import com.github.dockerjava.api.listener.BuildImageCallbackListener;
@@ -30,7 +31,7 @@ public class HackBuildImageResultCallback extends BuildImageResultCallback {
 
     private final BuildImageCallbackListener listener;
 
-    private final static String STEP_PREFIX = "Step";
+    private static final String STEP_PREFIX = "Step";
 
     public HackBuildImageResultCallback(BuildImageCallbackListener listener) {
         this.listener = listener;
@@ -47,5 +48,4 @@ public void onNext(BuildResponseItem item) {
         }
     }
 
-
 }

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/api/command/HackPullImageResultCallback.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.github.dockerjava.api.command;
 
 import com.github.dockerjava.api.listener.PullImageCallbackListener;
@@ -43,7 +44,4 @@ public void onNext(PullResponseItem item) {
         }
     }
 
-
-
-
 }

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/api/command/HackPushImageResultCallback.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.github.dockerjava.api.command;
 
 import com.github.dockerjava.api.listener.PushImageCallbackListener;

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/api/listener/BuildImageCallbackListener.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.github.dockerjava.api.listener;
 
 /**

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/api/listener/PullImageCallbackListener.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.github.dockerjava.api.listener;
 
 import com.github.dockerjava.api.model.PullResponseItem;

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/api/listener/PushImageCallbackListener.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.github.dockerjava.api.listener;
 
 import com.github.dockerjava.api.model.PushResponseItem;

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/core/HackDockerClient.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.github.dockerjava.core;
 
 import com.github.dockerjava.core.command.HackBuildImageCmd;
@@ -53,7 +54,6 @@ public HackBuildImageCmd buildImageCmd() {
         return new HackBuildImageCmd(dockerCmdExecFactory.createBuildImageCmdExec());
     }
 
-
     @Override
     public HackPullImageCmd pullImageCmd(String repository) {
         return new HackPullImageCmd(

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/core/command/HackBuildImageCmd.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.github.dockerjava.core.command;
 
 import com.github.dockerjava.api.command.HackBuildImageResultCallback;

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/core/command/HackPullImageCmd.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.github.dockerjava.core.command;
 
 import com.github.dockerjava.api.command.HackPullImageResultCallback;

File: streamx-plugin/streamx-flink-packer/src/main/java/com/github/dockerjava/core/command/HackPushImageCmd.java
Patch:
@@ -18,6 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
+
 package com.github.dockerjava.core.command;
 
 import com.github.dockerjava.api.command.HackPushImageResultCallback;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -17,7 +17,6 @@
 package com.streamxhub.streamx.console.core.controller;
 
 import com.baomidou.mybatisplus.core.metadata.IPage;
-import com.streamxhub.streamx.common.enums.StorageType;
 import com.streamxhub.streamx.common.util.HadoopUtils;
 import com.streamxhub.streamx.common.util.Utils;
 import com.streamxhub.streamx.console.base.domain.RestRequest;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -933,7 +933,7 @@ public Application getApp(Application appParam) {
             FlinkSql flinkSql = flinkSqlService.getEffective(application.getId(), true);
             flinkSql.setToApplication(application);
         } else {
-            if (!application.isCICDJob()) {
+            if (application.isCICDJob()) {
                 String path = this.projectService.getAppConfPath(application.getProjectId(), application.getModule());
                 application.setConfPath(path);
             }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/enums/ResourceFrom.java
Patch:
@@ -38,17 +38,17 @@ public enum ResourceFrom {
      */
     UPLOAD(2);
 
-    int value;
+    Integer value;
 
-    ResourceFrom(int value) {
+    ResourceFrom(Integer value) {
         this.value = value;
     }
 
     public static ResourceFrom of(Integer value) {
         return Arrays.stream(values()).filter((x) -> x.value == value).findFirst().orElse(null);
     }
 
-    public int getValue() {
+    public Integer getValue() {
         return value;
     }
 }

File: streamx-common/src/main/scala/com/streamxhub/streamx/common/enums/ExecutionMode.java
Patch:
@@ -41,9 +41,9 @@ public enum ExecutionMode implements Serializable {
      */
     REMOTE(1, "remote"),
     /**
-     * yarn-pre-job mode
+     * yarn-per-job mode
      */
-    YARN_PRE_JOB(2, "yarn-pre-job"),
+    YARN_PER_JOB(2, "yarn-per-job"),
     /**
      * yarn session
      */
@@ -96,7 +96,7 @@ public String getName() {
     }
 
     public static boolean isYarnMode(ExecutionMode mode) {
-        return YARN_PRE_JOB.equals(mode) || YARN_APPLICATION.equals(mode) || YARN_SESSION.equals(mode);
+        return YARN_PER_JOB.equals(mode) || YARN_APPLICATION.equals(mode) || YARN_SESSION.equals(mode);
     }
 
     public static boolean isYarnMode(Integer value) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/Application.java
Patch:
@@ -381,7 +381,7 @@ public String getAppHome() {
         switch (this.getExecutionModeEnum()) {
             case KUBERNETES_NATIVE_APPLICATION:
             case KUBERNETES_NATIVE_SESSION:
-            case YARN_PRE_JOB:
+            case YARN_PER_JOB:
             case YARN_SESSION:
             case LOCAL:
                 return getLocalAppHome();
@@ -620,7 +620,7 @@ public static StorageType getStorageType(Integer execMode) {
         switch (Objects.requireNonNull(executionMode)) {
             case YARN_APPLICATION:
                 return StorageType.HDFS;
-            case YARN_PRE_JOB:
+            case YARN_PER_JOB:
             case YARN_SESSION:
             case KUBERNETES_NATIVE_SESSION:
             case KUBERNETES_NATIVE_APPLICATION:

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/entity/ApplicationBackUp.java
Patch:
@@ -60,7 +60,7 @@ public ApplicationBackUp(Application application) {
         switch (application.getExecutionModeEnum()) {
             case KUBERNETES_NATIVE_APPLICATION:
             case KUBERNETES_NATIVE_SESSION:
-            case YARN_PRE_JOB:
+            case YARN_PER_JOB:
             case YARN_SESSION:
             case LOCAL:
                 this.path = String.format(

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationBackUpServiceImpl.java
Patch:
@@ -205,7 +205,7 @@ public void rollbackFlinkSql(Application application, FlinkSql sql) {
                 switch (application.getExecutionModeEnum()) {
                     case KUBERNETES_NATIVE_APPLICATION:
                     case KUBERNETES_NATIVE_SESSION:
-                    case YARN_PRE_JOB:
+                    case YARN_PER_JOB:
                     case YARN_SESSION:
                     case LOCAL:
                         if (application.isFlinkSqlJob()) {
@@ -268,7 +268,7 @@ public void backup(Application application) {
         switch (application.getExecutionModeEnum()) {
             case KUBERNETES_NATIVE_APPLICATION:
             case KUBERNETES_NATIVE_SESSION:
-            case YARN_PRE_JOB:
+            case YARN_PER_JOB:
             case YARN_SESSION:
             case LOCAL:
                 if (application.isFlinkSqlJob()) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -1167,7 +1167,7 @@ public boolean start(Application appParam, boolean auto) throws Exception {
                 assert executionMode != null;
                 //3) plugin
                 switch (executionMode) {
-                    case YARN_PRE_JOB:
+                    case YARN_PER_JOB:
                     case KUBERNETES_NATIVE_SESSION:
                     case KUBERNETES_NATIVE_APPLICATION:
                         flinkUserJar = Workspace.local().APP_PLUGINS().concat("/").concat(sqlDistJar);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/FlinkSqlService.java
Patch:
@@ -34,6 +34,7 @@
 public interface FlinkSqlService extends IService<FlinkSql> {
 
     //TODO 所有的历史记录和版本相关功能,需要重构,重新讨论实现
+
     /**
      * @param flinkSql
      * @param latest   是否latest

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ProjectService.java
Patch:
@@ -41,7 +41,7 @@ public interface ProjectService extends IService<Project> {
 
     IPage<Project> page(Project project, RestRequest restRequest);
 
-    void build(Long id) throws Exception;
+    void build(Long id, String socketId) throws Exception;
 
     void tailBuildLog(Long id);
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -53,7 +53,7 @@ public class FlinkEnvServiceImpl extends ServiceImpl<FlinkEnvMapper, FlinkEnv> i
     public boolean exists(FlinkEnv version) {
         //1) check name
         LambdaQueryWrapper<FlinkEnv> nameQuery = new LambdaQueryWrapper<FlinkEnv>()
-                .eq(FlinkEnv::getFlinkName, version.getFlinkName());
+            .eq(FlinkEnv::getFlinkName, version.getFlinkName());
         if (version.getId() != null) {
             nameQuery.ne(FlinkEnv::getId, version.getId());
         }
@@ -103,7 +103,7 @@ public FlinkEnv getByAppId(Long appId) {
     @Override
     public FlinkEnv getDefault() {
         return this.baseMapper.selectOne(
-                new LambdaQueryWrapper<FlinkEnv>().eq(FlinkEnv::getIsDefault, true)
+            new LambdaQueryWrapper<FlinkEnv>().eq(FlinkEnv::getIsDefault, true)
         );
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -157,7 +157,7 @@ public void removeApp(Long appId) {
     }
 
     @Override
-    @Transactional(propagation = Propagation.REQUIRES_NEW,rollbackFor = Exception.class)
+    @Transactional(propagation = Propagation.REQUIRES_NEW, rollbackFor = Exception.class)
     public void rollback(Application application) {
         FlinkSql sql = getCandidate(application.getId(), CandidateType.HISTORY);
         assert sql != null;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/FlinkTrackingTask.java
Patch:
@@ -67,7 +67,6 @@
  */
 @Slf4j
 @Component
-@DependsOn({"flyway", "flywayInitializer"})
 public class FlinkTrackingTask {
 
     /**

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/RoleMenu.java
Patch:
@@ -31,6 +31,8 @@ public class RoleMenu implements Serializable {
 
     private static final long serialVersionUID = -7573904024872252113L;
 
+    private Long id;
+
     private Long roleId;
 
     private Long menuId;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/entity/UserRole.java
Patch:
@@ -31,6 +31,8 @@ public class UserRole implements Serializable {
 
     private static final long serialVersionUID = -3166012934498268403L;
 
+    private Long id;
+
     private Long userId;
 
     private Long roleId;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -37,7 +37,6 @@
 import com.streamxhub.streamx.common.enums.ResolveOrder;
 import com.streamxhub.streamx.common.enums.StorageType;
 import com.streamxhub.streamx.common.fs.FsOperator;
-import com.streamxhub.streamx.common.fs.LfsOperator;
 import com.streamxhub.streamx.common.util.*;
 import com.streamxhub.streamx.console.base.domain.Constant;
 import com.streamxhub.streamx.console.base.domain.RestRequest;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -233,7 +233,7 @@ private void findTarOrJar(List<File> list, File path) {
                             jar = targetFile;
                         } else {
                             // 可能存在会找到多个jar,这种情况下,选择体积最大的那个jar返回...(不要问我为什么.)
-                            if (targetFile.getTotalSpace() > jar.getTotalSpace()) {
+                            if (targetFile.length() > jar.length()) {
                                 jar = targetFile;
                             }
                         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -238,5 +238,4 @@ public RestResponse upload(MultipartFile file, Integer executionMode) throws Exc
         return RestResponse.create().data(upload);
     }
 
-
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationService.java
Patch:
@@ -30,6 +30,7 @@
 
 import java.io.IOException;
 import java.io.Serializable;
+import java.util.List;
 import java.util.Map;
 
 /**

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ProjectServiceImpl.java
Patch:
@@ -233,7 +233,7 @@ private void findTarOrJar(List<File> list, File path) {
                             jar = targetFile;
                         } else {
                             // 可能存在会找到多个jar,这种情况下,选择体积最大的那个jar返回...(不要问我为什么.)
-                            if (targetFile.getTotalSpace() > jar.getTotalSpace()) {
+                            if (targetFile.length() > jar.length()) {
                                 jar = targetFile;
                             }
                         }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/StreamXConsole.java
Patch:
@@ -71,7 +71,7 @@ public static void main(String[] args) {
         }
 
         Runtime.getRuntime().addShutdownHook(new Thread(() -> {
-            logger.info("[StreamX] application shutdown now, pid: " + getPid());
+            logger.info("application shutdown now, pid: " + getPid());
             if (pid != null) {
                 File pidFile = new File(pid);
                 pidFile.delete();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ProjectController.java
Patch:
@@ -58,7 +58,8 @@ public RestResponse create(Project project) {
     @PostMapping("build")
     @RequiresPermissions("project:build")
     public RestResponse build(Long id) throws Exception {
-        return projectService.build(id);
+        projectService.build(id);
+        return RestResponse.create();
     }
 
     @PostMapping("closebuild")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ProjectService.java
Patch:
@@ -41,7 +41,7 @@ public interface ProjectService extends IService<Project> {
 
     IPage<Project> page(Project project, RestRequest restRequest);
 
-    RestResponse build(Long id) throws Exception;
+    void build(Long id) throws Exception;
 
     void tailBuildLog(Long id);
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/SettingService.java
Patch:
@@ -60,8 +60,6 @@ public interface SettingService extends IService<Setting> {
 
     String getMavenRepository();
 
-    boolean checkWorkspace();
-
     SenderEmail getSenderEmail();
 
     String getDockerRegisterAddress();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/StreamXConsole.java
Patch:
@@ -86,7 +86,7 @@ private static Integer getPid() {
         String name = runtime.getName();
         try {
             return Integer.parseInt(name.substring(0, name.indexOf('@')));
-        } catch (Exception e) {
+        } catch (Exception ignored) {
         }
         return -1;
     }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationService.java
Patch:
@@ -47,6 +47,8 @@ public interface ApplicationService extends IService<Application> {
 
     boolean start(Application app, boolean auto) throws Exception;
 
+    void restart(Application application) throws Exception;
+
     String getYarnName(Application app);
 
     AppExistsState checkExists(Application app);
@@ -82,7 +84,5 @@ public interface ApplicationService extends IService<Application> {
 
     Boolean delete(Application app);
 
-    void restart(Application application) throws Exception;
-
-    boolean checkEnv(Application app);
+    boolean checkEnv(Application app) throws Exception;
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/FlinkEnvService.java
Patch:
@@ -44,7 +44,7 @@ public interface FlinkEnvService extends IService<FlinkEnv> {
      * @param version
      * @throws IOException
      */
-    boolean create(FlinkEnv version);
+    boolean create(FlinkEnv version) throws Exception;
 
     /**
      * update

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkEnvServiceImpl.java
Patch:
@@ -61,7 +61,7 @@ public boolean exists(FlinkEnv version) {
     }
 
     @Override
-    public boolean create(FlinkEnv version) {
+    public boolean create(FlinkEnv version) throws Exception {
         int count = this.baseMapper.selectCount(null);
         if (count == 0) {
             version.setIsDefault(true);
@@ -72,8 +72,7 @@ public boolean create(FlinkEnv version) {
             version.doSetFlinkConf();
             return save(version);
         } catch (Exception e) {
-            log.error(e.getMessage());
-            return false;
+            throw e;
         }
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationBackUpServiceImpl.java
Patch:
@@ -306,7 +306,7 @@ public void backup(Application application) {
 
             this.save(applicationBackUp);
             fsOperator.mkdirs(applicationBackUp.getPath());
-            fsOperator.move(appHome, applicationBackUp.getPath());
+            fsOperator.copyDir(appHome, applicationBackUp.getPath());
         }
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -192,7 +192,8 @@ public RestResponse backups(ApplicationBackUp backUp, RestRequest request) {
 
     @PostMapping("rollback")
     public RestResponse rollback(ApplicationBackUp backUp) {
-        backUpService.rollback(backUp);
+        //TODO: next version implementation
+        //backUpService.rollback(backUp);
         return RestResponse.create();
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/K8sFlinkChangeEventListener.java
Patch:
@@ -93,7 +93,7 @@ public void persistentK8sFlinkJobStatusChange(FlinkJobStatusChangeEvent event) {
         if (ExecutionMode.KUBERNETES_NATIVE_SESSION.equals(mode)) {
             query.eq("job_id", jobStatus.jobId());
         }
-        query.orderByDesc("create_time");
+        query.orderByDesc("create_time").last("limit 1");
         Application app = applicationService.getOne(query);
         if (app == null) {
             return;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -177,7 +177,7 @@ public void rollback(Application application) {
     @Override
     public SqlError verifySql(String sql, Long versionId) {
         FlinkEnv flinkEnv = flinkEnvService.getById(versionId);
-        String error = FlinkShimsProxy.proxy(flinkEnv.getFlinkVersion(), (Function<ClassLoader, String>) classLoader -> {
+        return FlinkShimsProxy.proxy(flinkEnv.getFlinkVersion(), (Function<ClassLoader, SqlError>) classLoader -> {
             try {
                 Class<?> clazz = classLoader.loadClass("com.streamxhub.streamx.flink.core.FlinkSqlValidator");
                 Method method = clazz.getDeclaredMethod("verifySql", String.class);
@@ -186,13 +186,12 @@ public SqlError verifySql(String sql, Long versionId) {
                 if (sqlError == null) {
                     return null;
                 }
-                return sqlError.toString();
+                return FlinkShimsProxy.getObject(this.getClass().getClassLoader(), sqlError);
             } catch (Throwable e) {
                 log.error("verifySql invocationTargetException: {}", ExceptionUtils.stringifyException(e));
             }
             return null;
         });
-        return SqlError.fromString(error);
     }
 
     private boolean isFlinkSqlBacked(FlinkSql sql) {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/FlinkTrackingTask.java
Patch:
@@ -525,6 +525,9 @@ private void getFromYarnRestApi(Application application, StopFrom stopFrom) thro
                         cleanSavepoint(application);
                         application.setEndTime(new Date());
                     }
+                    if(FlinkAppState.SUCCEEDED.equals(flinkAppState)) {
+                        flinkAppState = FlinkAppState.FINISHED;
+                    }
                     application.setState(flinkAppState.getValue());
                     //能运行到这一步,说明到YARN REST api中成功查询到信息
                     cleanOptioning(optionState, application.getId());

File: streamx-plugin/streamx-flink-proxy/src/main/scala/com/streamxhub/streamx/flink/proxy/ChildFirstClassLoader.java
Patch:
@@ -211,4 +211,4 @@ private Class<?> loadClassWithoutExceptionHandling(String name, boolean resolve)
         return c;
     }
 
-}
+}
\ No newline at end of file

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkEnvController.java
Patch:
@@ -36,7 +36,7 @@
 @Slf4j
 @Validated
 @RestController
-@RequestMapping("flink/version")
+@RequestMapping("flink/env")
 public class FlinkEnvController {
 
     @Autowired

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/dao/FlinkEnvMapper.java
Patch:
@@ -36,7 +36,7 @@ public interface FlinkEnvMapper extends BaseMapper<FlinkEnv> {
      *
      * @param id
      */
-    @Update("update t_flink_version set is_default = case id when #{id} then 1 else 0 end")
+    @Update("update t_flink_env set is_default = case id when #{id} then 1 else 0 end")
     void setDefault(@Param("id") Long id);
 
     /**
@@ -45,6 +45,6 @@ public interface FlinkEnvMapper extends BaseMapper<FlinkEnv> {
      * @param appId
      * @return
      */
-    @Select("select v.* from t_flink_version v inner join (select version_id from t_flink_app where id=#{appId}) as t on v.id = t.version_id")
+    @Select("select v.* from t_flink_env v inner join (select version_id from t_flink_app where id=#{appId}) as t on v.id = t.version_id")
     FlinkEnv getByAppId(@Param("appId") Long appId);
 }

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -60,8 +60,8 @@
 import com.streamxhub.streamx.flink.packer.docker.DockerAuthConf;
 import com.streamxhub.streamx.flink.packer.maven.JarPackDeps;
 import com.streamxhub.streamx.flink.submit.FlinkSubmit;
-import com.streamxhub.streamx.flink.submit.FlinkSubmitHelper;
 import com.streamxhub.streamx.flink.submit.domain.*;
+import com.streamxhub.streamx.flink.submit.tool.FlinkSubmitHelper;
 import lombok.SneakyThrows;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.codec.digest.DigestUtils;
@@ -955,6 +955,7 @@ public void cancel(Application appParam) {
                             .getOrDefault(ConfigConst.KEY_FLINK_SAVEPOINT_PATH(), "");
                 }
                 StopRequest stopInfo = new StopRequest(
+                    flinkVersion.getVersion(),
                     flinkVersion.getFlinkHome(),
                     application.getAppId(),
                     application.getJobId(),

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -112,6 +112,7 @@ public RestResponse mapping(Application app) {
     public RestResponse deploy(Application app) {
         Application application = applicationService.getById(app.getId());
         assert application != null;
+        applicationService.checkEnv(app);
         application.setBackUp(true);
         application.setBackUpDescription(app.getBackUpDescription());
         applicationService.deploy(application);
@@ -128,7 +129,7 @@ public RestResponse revoke(Application app) throws Exception {
     @PostMapping("start")
     @RequiresPermissions("app:start")
     public RestResponse start(Application app) throws Exception {
-        boolean success = applicationService.checkStart(app);
+        boolean success = applicationService.checkEnv(app);
         if (success) {
             applicationService.starting(app);
             boolean started = applicationService.start(app, false);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/ApplicationService.java
Patch:
@@ -84,5 +84,5 @@ public interface ApplicationService extends IService<Application> {
 
     void restart(Application application) throws Exception;
 
-    boolean checkStart(Application app);
+    boolean checkEnv(Application app);
 }

File: streamx-flink/streamx-flink-test/streamx-flink-test-datastream/src/main/java/com/streamxhub/streamx/test/flink/java/bean/LogBean.java
Patch:
@@ -18,7 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.flink.javacase.bean;
+package com.streamxhub.streamx.test.flink.java.bean;
 
 import lombok.Data;
 

File: streamx-flink/streamx-flink-test/streamx-flink-test-datastream/src/main/java/com/streamxhub/streamx/test/flink/java/bean/OrderInfo.java
Patch:
@@ -18,7 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.flink.javacase.bean;
+package com.streamxhub.streamx.test.flink.java.bean;
 
 
 import lombok.Data;

File: streamx-flink/streamx-flink-test/streamx-flink-test-datastream/src/main/java/com/streamxhub/streamx/test/flink/java/datastream/KafkaJavaApp.java
Patch:
@@ -18,14 +18,14 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.flink.javacase.stream;
+package com.streamxhub.streamx.test.flink.java.datastream;
 
 import com.streamxhub.streamx.flink.core.StreamEnvConfig;
 import com.streamxhub.streamx.flink.core.java.sink.KafkaSink;
 import com.streamxhub.streamx.flink.core.java.source.KafkaSource;
 import com.streamxhub.streamx.flink.core.scala.StreamingContext;
 import com.streamxhub.streamx.flink.core.scala.source.KafkaRecord;
-import com.streamxhub.streamx.flink.javacase.bean.LogBean;
+import com.streamxhub.streamx.test.flink.java.bean.LogBean;
 import org.apache.flink.api.common.functions.MapFunction;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.streaming.api.datastream.DataStream;

File: streamx-flink/streamx-flink-test/streamx-flink-test-datastream/src/main/java/com/streamxhub/streamx/test/flink/java/datastream/KafkaSimpleJavaApp.java
Patch:
@@ -18,7 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.flink.javacase.stream;
+package com.streamxhub.streamx.test.flink.java.datastream;
 
 import com.streamxhub.streamx.flink.core.StreamEnvConfig;
 import com.streamxhub.streamx.flink.core.java.source.KafkaSource;

File: streamx-flink/streamx-flink-test/streamx-flink-test-datastream/src/main/java/com/streamxhub/streamx/test/flink/java/datastream/MySQLJavaApp.java
Patch:
@@ -18,14 +18,14 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.flink.javacase.stream;
+package com.streamxhub.streamx.test.flink.java.datastream;
 
 import com.streamxhub.streamx.flink.core.StreamEnvConfig;
 import com.streamxhub.streamx.flink.core.java.function.SQLQueryFunction;
 import com.streamxhub.streamx.flink.core.java.function.SQLResultFunction;
 import com.streamxhub.streamx.flink.core.java.source.JdbcSource;
 import com.streamxhub.streamx.flink.core.scala.StreamingContext;
-import com.streamxhub.streamx.flink.javacase.bean.OrderInfo;
+import com.streamxhub.streamx.test.flink.java.bean.OrderInfo;
 import org.apache.flink.api.common.typeinfo.TypeInformation;
 
 import java.io.Serializable;

File: streamx-flink/streamx-flink-test/streamx-flink-test-tablesql/src/main/java/com/streamxhub/streamx/test/flink/java/tablesql/JavaStreamTableApp.java
Patch:
@@ -18,7 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.flink.javacase.tablesql;
+package com.streamxhub.streamx.test.flink.java.tablesql;
 
 import com.streamxhub.streamx.flink.core.StreamTableContext;
 import com.streamxhub.streamx.flink.core.StreamTableEnvConfig;

File: streamx-flink/streamx-flink-test/streamx-flink-test-tablesql/src/main/java/com/streamxhub/streamx/test/flink/java/tablesql/JavaTableApp.java
Patch:
@@ -18,7 +18,7 @@
  * specific language governing permissions and limitations
  * under the License.
  */
-package com.streamxhub.streamx.flink.javacase.tablesql;
+package com.streamxhub.streamx.test.flink.java.tablesql;
 
 import org.apache.flink.table.api.EnvironmentSettings;
 import org.apache.flink.table.api.TableEnvironment;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -152,6 +152,7 @@ public RestResponse cancel(Application app) {
         return RestResponse.create();
     }
 
+    // fixme to adapte for kubernetes-only scenarios
     @PostMapping("yarn")
     public RestResponse yarn() {
         return RestResponse.create().data(HadoopUtils.getRMWebAppURL(false));

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationConfigServiceImpl.java
Patch:
@@ -41,6 +41,7 @@
 import com.streamxhub.streamx.console.core.service.EffectiveService;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.io.FileUtils;
+import org.apache.commons.lang3.ArrayUtils;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.context.ApplicationContext;
 import org.springframework.stereotype.Service;
@@ -239,9 +240,9 @@ public List<ApplicationConfig> history(Application application) {
     @Override
     public synchronized String readTemplate() {
         if (flinkConfTemplate == null) {
-            String profiles = context.getEnvironment().getActiveProfiles()[0];
+            String[] activeProfiles = context.getEnvironment().getActiveProfiles();
             String path;
-            if (profiles.equals(PROD_ENV_NAME)) {
+            if (ArrayUtils.isNotEmpty(activeProfiles) && activeProfiles[0].equals(PROD_ENV_NAME)) {
                 //生产环境部署读取conf/flink-application.template
                 path = WebUtils.getAppDir("conf").concat("/flink-application.template");
             } else {

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/runner/EnvInitializer.java
Patch:
@@ -69,6 +69,8 @@ public void run(ApplicationArguments args) throws Exception {
                 ConfigConst.STREAMX_WORKSPACE_DEFAULT()
             )
         );
+        // local storage must exists
+        storageInitialize(StorageType.LFS);
     }
 
     /**

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -394,6 +394,7 @@ public String getYarnName(Application appParam) {
      * @return
      */
     @Override
+    // fixme
     public AppExistsState checkExists(Application appParam) {
         boolean inDB = this.baseMapper.selectCount(
             new QueryWrapper<Application>().lambda()
@@ -426,7 +427,8 @@ public AppExistsState checkExists(Application appParam) {
             if (inDB) {
                 return AppExistsState.IN_DB;
             }
-            if (YarnUtils.isContains(appParam.getJobName())) {
+            if (ExecutionMode.isYarnMode(appParam.getExecutionMode())
+                && YarnUtils.isContains(appParam.getJobName())) {
                 return AppExistsState.IN_YARN;
             }
         }
@@ -1059,7 +1061,6 @@ public boolean start(Application appParam, boolean auto) throws Exception {
             settingService.getDockerRegisterUser(),
             settingService.getDockerRegisterPassword()
         );
-
         SubmitRequest submitInfo = new SubmitRequest(
             settingService.getEffectiveFlinkHome(),
             settingService.getFlinkVersion(),

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/SettingServiceImpl.java
Patch:
@@ -22,6 +22,7 @@
 
 
 import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;
+import com.streamxhub.streamx.common.conf.ConfigConst;
 import com.streamxhub.streamx.common.util.CommandUtils;
 import com.streamxhub.streamx.common.util.PropertiesUtils;
 import com.streamxhub.streamx.common.util.Utils;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -182,12 +182,11 @@ public void rollback(Application application) {
     @SneakyThrows
     @Override
     public SqlError verifySql(String sql) {
-        return null;
-        /*ClassLoader loader = getFlinkShimsClassLoader();
+        ClassLoader loader = getFlinkShimsClassLoader();
         Class<?> clazz = loader.loadClass("com.streamxhub.streamx.flink.core.FlinkSqlValidator");
         Method method = clazz.getDeclaredMethod("verifySql", String.class);
         method.setAccessible(true);
-        return (SqlError) method.invoke(null, sql);*/
+        return (SqlError) method.invoke(null, sql);
     }
 
     @SneakyThrows

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -182,12 +182,11 @@ public void rollback(Application application) {
     @SneakyThrows
     @Override
     public SqlError verifySql(String sql) {
-        return null;
-        /*ClassLoader loader = getFlinkShimsClassLoader();
+        ClassLoader loader = getFlinkShimsClassLoader();
         Class<?> clazz = loader.loadClass("com.streamxhub.streamx.flink.core.FlinkSqlValidator");
         Method method = clazz.getDeclaredMethod("verifySql", String.class);
         method.setAccessible(true);
-        return (SqlError) method.invoke(null, sql);*/
+        return (SqlError) method.invoke(null, sql);
     }
 
     @SneakyThrows

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -630,12 +630,10 @@ public void deploy(Application application) {
                                 updateWrapper.set(Application::getState, FlinkAppState.DEPLOYED.getValue());
                             }
                         }
-                    } catch (ServiceException e) {
+                    } catch (Exception e) {
                         updateWrapper.set(Application::getState, FlinkAppState.ADDED.getValue());
                         updateWrapper.set(Application::getOptionState, OptionState.NONE.getValue());
                         updateWrapper.set(Application::getDeploy, DeployState.NEED_DEPLOY_DOWN_DEPENDENCY_FAILED.get());
-                    } catch (Exception e) {
-                        e.printStackTrace();
                     } finally {
                         FlinkTrackingTask.refreshTracking(application.getId(), () -> {
                             baseMapper.update(application, updateWrapper);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -630,12 +630,10 @@ public void deploy(Application application) {
                                 updateWrapper.set(Application::getState, FlinkAppState.DEPLOYED.getValue());
                             }
                         }
-                    } catch (ServiceException e) {
+                    } catch (Exception e) {
                         updateWrapper.set(Application::getState, FlinkAppState.ADDED.getValue());
                         updateWrapper.set(Application::getOptionState, OptionState.NONE.getValue());
                         updateWrapper.set(Application::getDeploy, DeployState.NEED_DEPLOY_DOWN_DEPENDENCY_FAILED.get());
-                    } catch (Exception e) {
-                        e.printStackTrace();
                     } finally {
                         FlinkTrackingTask.refreshTracking(application.getId(), () -> {
                             baseMapper.update(application, updateWrapper);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -592,6 +592,7 @@ public void deploy(Application application) {
                     });
 
                     LambdaUpdateWrapper<Application> updateWrapper = new LambdaUpdateWrapper<>();
+                    updateWrapper.eq(Application::getId, application.getId());
                     try {
                         if (application.isCustomCodeJob()) {
                             log.info("CustomCodeJob deploying...");
@@ -613,7 +614,6 @@ public void deploy(Application application) {
                             downloadDependency(application);
                         }
                         // 4) 更新发布状态,需要重启的应用则重新启动...
-                        updateWrapper.eq(Application::getId, application.getId());
                         if (application.getRestart()) {
                             application.setSavePointed(true);
                             // 重新启动.
@@ -631,7 +631,6 @@ public void deploy(Application application) {
                             }
                         }
                     } catch (ServiceException e) {
-                        updateWrapper.eq(Application::getId, application.getId());
                         updateWrapper.set(Application::getState, FlinkAppState.ADDED.getValue());
                         updateWrapper.set(Application::getOptionState, OptionState.NONE.getValue());
                         updateWrapper.set(Application::getDeploy, DeployState.NEED_DEPLOY_DOWN_DEPENDENCY_FAILED.get());

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -592,6 +592,7 @@ public void deploy(Application application) {
                     });
 
                     LambdaUpdateWrapper<Application> updateWrapper = new LambdaUpdateWrapper<>();
+                    updateWrapper.eq(Application::getId, application.getId());
                     try {
                         if (application.isCustomCodeJob()) {
                             log.info("CustomCodeJob deploying...");
@@ -613,7 +614,6 @@ public void deploy(Application application) {
                             downloadDependency(application);
                         }
                         // 4) 更新发布状态,需要重启的应用则重新启动...
-                        updateWrapper.eq(Application::getId, application.getId());
                         if (application.getRestart()) {
                             application.setSavePointed(true);
                             // 重新启动.
@@ -631,7 +631,6 @@ public void deploy(Application application) {
                             }
                         }
                     } catch (ServiceException e) {
-                        updateWrapper.eq(Application::getId, application.getId());
                         updateWrapper.set(Application::getState, FlinkAppState.ADDED.getValue());
                         updateWrapper.set(Application::getOptionState, OptionState.NONE.getValue());
                         updateWrapper.set(Application::getDeploy, DeployState.NEED_DEPLOY_DOWN_DEPENDENCY_FAILED.get());

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/metrics/flink/CheckPoints.java
Patch:
@@ -82,7 +82,7 @@ public CheckPointType getCheckPointType() {
         }
 
         public String getPath() {
-            return this.getExternalPath().replaceFirst("^hdfs:", "hdfs://");
+            return this.getExternalPath().replaceFirst("^hdfs:/[^/]", "hdfs:///");
         }
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -25,6 +25,7 @@
 import com.baomidou.mybatisplus.core.conditions.update.LambdaUpdateWrapper;
 import com.baomidou.mybatisplus.core.conditions.update.UpdateWrapper;
 import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;
+import com.streamxhub.streamx.common.util.ClassLoaderUtils;
 import com.streamxhub.streamx.common.util.DeflaterUtils;
 import com.streamxhub.streamx.console.base.utils.WebUtil;
 import com.streamxhub.streamx.console.core.dao.FlinkSqlMapper;
@@ -51,6 +52,7 @@
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
+import java.util.function.Supplier;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 import java.util.stream.Collectors;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/FlinkTrackingTask.java
Patch:
@@ -341,7 +341,7 @@ private void handleCheckPoints(Application application) throws Exception {
                             savePoint.setAppId(application.getId());
                             savePoint.setLatest(true);
                             savePoint.setType(checkPoint.getCheckPointType().get());
-                            savePoint.setPath(checkPoint.getPath());
+                            savePoint.setPath(checkPoint.getExternalPath());
                             savePoint.setTriggerTime(new Date(checkPoint.getTriggerTimestamp()));
                             savePoint.setCreateTime(new Date());
                             savePointService.save(savePoint);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/metrics/flink/CheckPoints.java
Patch:
@@ -82,7 +82,7 @@ public CheckPointType getCheckPointType() {
         }
 
         public String getPath() {
-            return this.getExternalPath().replaceFirst("^hdfs:", "hdfs://");
+            return this.getExternalPath().replaceFirst("^hdfs:/[^/]", "hdfs:///");
         }
     }
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -25,6 +25,7 @@
 import com.baomidou.mybatisplus.core.conditions.update.LambdaUpdateWrapper;
 import com.baomidou.mybatisplus.core.conditions.update.UpdateWrapper;
 import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;
+import com.streamxhub.streamx.common.util.ClassLoaderUtils;
 import com.streamxhub.streamx.common.util.DeflaterUtils;
 import com.streamxhub.streamx.console.base.utils.WebUtil;
 import com.streamxhub.streamx.console.core.dao.FlinkSqlMapper;
@@ -51,6 +52,7 @@
 import java.util.List;
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
+import java.util.function.Supplier;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 import java.util.stream.Collectors;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/task/FlinkTrackingTask.java
Patch:
@@ -341,7 +341,7 @@ private void handleCheckPoints(Application application) throws Exception {
                             savePoint.setAppId(application.getId());
                             savePoint.setLatest(true);
                             savePoint.setType(checkPoint.getCheckPointType().get());
-                            savePoint.setPath(checkPoint.getPath());
+                            savePoint.setPath(checkPoint.getExternalPath());
                             savePoint.setTriggerTime(new Date(checkPoint.getTriggerTimestamp()));
                             savePoint.setCreateTime(new Date());
                             savePointService.save(savePoint);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -153,7 +153,7 @@ public RestResponse cancel(Application app) {
 
     @PostMapping("yarn")
     public RestResponse yarn() {
-        return RestResponse.create().data(HadoopUtils.getRMWebAppURL(true));
+        return RestResponse.create().data(HadoopUtils.getRMWebAppURL(false));
     }
 
     @PostMapping("name")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkSqlController.java
Patch:
@@ -17,14 +17,12 @@
 package com.streamxhub.streamx.console.core.controller;
 
 import com.streamxhub.streamx.common.enums.SqlErrorType;
-import com.streamxhub.streamx.common.util.ClassLoaderUtils;
 import com.streamxhub.streamx.console.base.domain.RestResponse;
 import com.streamxhub.streamx.console.base.exception.ServiceException;
 import com.streamxhub.streamx.console.core.entity.Application;
 import com.streamxhub.streamx.console.core.entity.FlinkSql;
 import com.streamxhub.streamx.console.core.service.FlinkSqlService;
 import com.streamxhub.streamx.flink.core.SqlError;
-import com.streamxhub.streamx.flink.core.SqlValidator;
 import lombok.extern.slf4j.Slf4j;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.validation.annotation.Validated;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -460,7 +460,7 @@ public boolean update(Application appParam) {
             } else if (application.isStreamXJob()) {
                 ApplicationConfig config = configService.getEffective(application.getId());
                 if (config != null) {
-                    if (!appParam.getConfigId().equals(config.getId())) {
+                    if (appParam.getConfigId() == null || !appParam.getConfigId().equals(config.getId())) {
                         application.setDeploy(DeployState.NEED_RESTART_AFTER_CONF_UPDATE.get());
                     } else {
                         String decode = new String(Base64.getDecoder().decode(appParam.getConfig()));

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -183,7 +183,7 @@ public void rollback(Application application) {
     @Override
     public SqlError verifySql(String sql) {
         ClassLoader loader = getFlinkShimsClassLoader();
-        Class<?> clazz = loader.loadClass("com.streamxhub.streamx.flink.core.SqlValidator");
+        Class<?> clazz = loader.loadClass("com.streamxhub.streamx.flink.core.FlinkSqlValidator");
         Method method = clazz.getDeclaredMethod("verifySql", String.class);
         method.setAccessible(true);
         return (SqlError) method.invoke(null, sql);

File: streamx-console/streamx-console-service/src/test/java/SQLCommandTest.java
Patch:
@@ -22,7 +22,7 @@
 import com.streamxhub.streamx.common.enums.SqlErrorType;
 import com.streamxhub.streamx.console.base.domain.RestResponse;
 import com.streamxhub.streamx.flink.core.SqlError;
-import com.streamxhub.streamx.flink.core.SqlValidator;
+import com.streamxhub.streamx.flink.core.FlinkSqlValidator;
 import org.junit.Test;
 
 import java.util.regex.Matcher;
@@ -35,7 +35,7 @@ public void sqlParae() {
 
         String sql = "SET table.planner = blink;";
 
-        SqlError sqlError = SqlValidator.verifySql(sql);
+        SqlError sqlError = FlinkSqlValidator.verifySql(sql);
         if (sqlError != null) {
             String[] array = sqlError.sql().trim().split("\n");
             String start = array[0].trim();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -153,7 +153,7 @@ public RestResponse cancel(Application app) {
 
     @PostMapping("yarn")
     public RestResponse yarn() {
-        return RestResponse.create().data(HadoopUtils.getRMWebAppURL(true));
+        return RestResponse.create().data(HadoopUtils.getRMWebAppURL(false));
     }
 
     @PostMapping("name")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkSqlController.java
Patch:
@@ -17,14 +17,12 @@
 package com.streamxhub.streamx.console.core.controller;
 
 import com.streamxhub.streamx.common.enums.SqlErrorType;
-import com.streamxhub.streamx.common.util.ClassLoaderUtils;
 import com.streamxhub.streamx.console.base.domain.RestResponse;
 import com.streamxhub.streamx.console.base.exception.ServiceException;
 import com.streamxhub.streamx.console.core.entity.Application;
 import com.streamxhub.streamx.console.core.entity.FlinkSql;
 import com.streamxhub.streamx.console.core.service.FlinkSqlService;
 import com.streamxhub.streamx.flink.core.SqlError;
-import com.streamxhub.streamx.flink.core.SqlValidator;
 import lombok.extern.slf4j.Slf4j;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.validation.annotation.Validated;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -460,7 +460,7 @@ public boolean update(Application appParam) {
             } else if (application.isStreamXJob()) {
                 ApplicationConfig config = configService.getEffective(application.getId());
                 if (config != null) {
-                    if (!appParam.getConfigId().equals(config.getId())) {
+                    if (appParam.getConfigId() == null || !appParam.getConfigId().equals(config.getId())) {
                         application.setDeploy(DeployState.NEED_RESTART_AFTER_CONF_UPDATE.get());
                     } else {
                         String decode = new String(Base64.getDecoder().decode(appParam.getConfig()));

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -183,7 +183,7 @@ public void rollback(Application application) {
     @Override
     public SqlError verifySql(String sql) {
         ClassLoader loader = getFlinkShimsClassLoader();
-        Class<?> clazz = loader.loadClass("com.streamxhub.streamx.flink.core.SqlValidator");
+        Class<?> clazz = loader.loadClass("com.streamxhub.streamx.flink.core.FlinkSqlValidator");
         Method method = clazz.getDeclaredMethod("verifySql", String.class);
         method.setAccessible(true);
         return (SqlError) method.invoke(null, sql);

File: streamx-console/streamx-console-service/src/test/java/SQLCommandTest.java
Patch:
@@ -22,7 +22,7 @@
 import com.streamxhub.streamx.common.enums.SqlErrorType;
 import com.streamxhub.streamx.console.base.domain.RestResponse;
 import com.streamxhub.streamx.flink.core.SqlError;
-import com.streamxhub.streamx.flink.core.SqlValidator;
+import com.streamxhub.streamx.flink.core.FlinkSqlValidator;
 import org.junit.Test;
 
 import java.util.regex.Matcher;
@@ -35,7 +35,7 @@ public void sqlParae() {
 
         String sql = "SET table.planner = blink;";
 
-        SqlError sqlError = SqlValidator.verifySql(sql);
+        SqlError sqlError = FlinkSqlValidator.verifySql(sql);
         if (sqlError != null) {
             String[] array = sqlError.sql().trim().split("\n");
             String start = array[0].trim();

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/source/HBaseSource.java
Patch:
@@ -46,8 +46,8 @@ public DataStreamSource<T> getDataStream(HBaseQueryFunction<T> queryFunction,
                                              HBaseResultFunction<T> resultFunction,
                                              RunningFunction runningFunc) {
 
-        Utils.require(queryFunction != null, "queryFunction must be not null");
-        Utils.require(resultFunction != null, "resultFunction must be not null");
+        Utils.require(queryFunction != null, "queryFunction must not be null");
+        Utils.require(resultFunction != null, "resultFunction must not be null");
         HBaseSourceFunction<T> sourceFunction = new HBaseSourceFunction<>(property, queryFunction, resultFunction, runningFunc, null);
         return context.getJavaEnv().addSource(sourceFunction);
 

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/source/JdbcSource.java
Patch:
@@ -64,8 +64,8 @@ public DataStreamSource<T> getDataStream(SQLQueryFunction<T> queryFunction,
                                              SQLResultFunction<T> resultFunction,
                                              RunningFunction runningFunc) {
 
-        Utils.require(queryFunction != null, "queryFunction must be not null");
-        Utils.require(resultFunction != null, "resultFunction must be not null");
+        Utils.require(queryFunction != null, "queryFunction must not be null");
+        Utils.require(resultFunction != null, "resultFunction must not be null");
         this.jdbc = this.jdbc == null ? ConfigUtils.getJdbcConf(context.parameter().toMap(), alias) : this.jdbc;
         JdbcSourceFunction<T> sourceFunction = new JdbcSourceFunction<>(jdbc, queryFunction, resultFunction, runningFunc, null);
         return context.getJavaEnv().addSource(sourceFunction);

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/source/MongoSource.java
Patch:
@@ -47,9 +47,9 @@ public DataStreamSource<T> getDataStream(String collectionName,
                                              MongoResultFunction<T> resultFunction,
                                              RunningFunction runningFunc) {
 
-        Utils.require(collectionName != null, "collectionName must be not null");
-        Utils.require(queryFunction != null, "queryFunction must be not null");
-        Utils.require(resultFunction != null, "resultFunction must be not null");
+        Utils.require(collectionName != null, "collectionName must not be null");
+        Utils.require(queryFunction != null, "queryFunction must not be null");
+        Utils.require(resultFunction != null, "resultFunction must not be null");
         MongoSourceFunction<T> sourceFunction = new MongoSourceFunction<>(collectionName, property, queryFunction, resultFunction, runningFunc, null);
         return context.getJavaEnv().addSource(sourceFunction);
 

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/source/HBaseSource.java
Patch:
@@ -46,8 +46,8 @@ public DataStreamSource<T> getDataStream(HBaseQueryFunction<T> queryFunction,
                                              HBaseResultFunction<T> resultFunction,
                                              RunningFunction runningFunc) {
 
-        Utils.require(queryFunction != null, "queryFunction must be not null");
-        Utils.require(resultFunction != null, "resultFunction must be not null");
+        Utils.require(queryFunction != null, "queryFunction must not be null");
+        Utils.require(resultFunction != null, "resultFunction must not be null");
         HBaseSourceFunction<T> sourceFunction = new HBaseSourceFunction<>(property, queryFunction, resultFunction, runningFunc, null);
         return context.getJavaEnv().addSource(sourceFunction);
 

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/source/JdbcSource.java
Patch:
@@ -64,8 +64,8 @@ public DataStreamSource<T> getDataStream(SQLQueryFunction<T> queryFunction,
                                              SQLResultFunction<T> resultFunction,
                                              RunningFunction runningFunc) {
 
-        Utils.require(queryFunction != null, "queryFunction must be not null");
-        Utils.require(resultFunction != null, "resultFunction must be not null");
+        Utils.require(queryFunction != null, "queryFunction must not be null");
+        Utils.require(resultFunction != null, "resultFunction must not be null");
         this.jdbc = this.jdbc == null ? ConfigUtils.getJdbcConf(context.parameter().toMap(), alias) : this.jdbc;
         JdbcSourceFunction<T> sourceFunction = new JdbcSourceFunction<>(jdbc, queryFunction, resultFunction, runningFunc, null);
         return context.getJavaEnv().addSource(sourceFunction);

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/source/MongoSource.java
Patch:
@@ -47,9 +47,9 @@ public DataStreamSource<T> getDataStream(String collectionName,
                                              MongoResultFunction<T> resultFunction,
                                              RunningFunction runningFunc) {
 
-        Utils.require(collectionName != null, "collectionName must be not null");
-        Utils.require(queryFunction != null, "queryFunction must be not null");
-        Utils.require(resultFunction != null, "resultFunction must be not null");
+        Utils.require(collectionName != null, "collectionName must not be null");
+        Utils.require(queryFunction != null, "queryFunction must not be null");
+        Utils.require(resultFunction != null, "resultFunction must not be null");
         MongoSourceFunction<T> sourceFunction = new MongoSourceFunction<>(collectionName, property, queryFunction, resultFunction, runningFunc, null);
         return context.getJavaEnv().addSource(sourceFunction);
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/FlinkSqlServiceImpl.java
Patch:
@@ -38,7 +38,6 @@
 import com.streamxhub.streamx.flink.core.SqlError;
 import lombok.SneakyThrows;
 import lombok.extern.slf4j.Slf4j;
-import org.jboss.netty.util.internal.ConcurrentHashMap;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.stereotype.Service;
 import org.springframework.transaction.annotation.Propagation;
@@ -51,6 +50,7 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 import java.util.stream.Collectors;

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -148,7 +148,7 @@ public RestResponse cancel(Application app) {
 
     @PostMapping("yarn")
     public RestResponse yarn() {
-        return RestResponse.create().data(HadoopUtils.getRMWebAppURL(false));
+        return RestResponse.create().data(HadoopUtils.getRMWebAppURL(true));
     }
 
     @PostMapping("name")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkSqlController.java
Patch:
@@ -59,7 +59,6 @@ public RestResponse verify(String sql) {
                 .data(false)
                 .message(sqlError.exception())
                 .put("type", sqlError.errorType().errorType)
-                .put("sql", sqlError.sql())
                 .put("start", start)
                 .put("end", end);
             //语法异常

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationConfigServiceImpl.java
Patch:
@@ -251,7 +251,7 @@ public synchronized String readTemplate() {
             }
             File file = new File(path);
             try {
-                String conf = FileUtils.readFileToString(file, "utf-8");
+                String conf = FileUtils.readFileToString(file);
                 this.flinkConfTemplate = Base64.getEncoder().encodeToString(conf.getBytes());
             } catch (IOException e) {
                 e.printStackTrace();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/EffectiveServiceImpl.java
Patch:
@@ -33,6 +33,8 @@
 import org.springframework.transaction.annotation.Propagation;
 import org.springframework.transaction.annotation.Transactional;
 
+import java.util.Date;
+
 /**
  * @author benjobs
  */
@@ -68,6 +70,7 @@ public void saveOrUpdate(Long appId, EffectiveType type, Long id) {
             effective.setAppId(appId);
             effective.setTargetType(type.getType());
             effective.setTargetId(id);
+            effective.setCreateTime(new Date());
             save(effective);
         } else {
             update(new UpdateWrapper<Effective>()

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/JWTUtil.java
Patch:
@@ -25,7 +25,7 @@
 import com.auth0.jwt.algorithms.Algorithm;
 import com.auth0.jwt.exceptions.JWTDecodeException;
 import com.auth0.jwt.interfaces.DecodedJWT;
-import com.streamxhub.streamx.console.base.properties.StreamXProperties;
+import com.streamxhub.streamx.console.base.properties.ShiroProperties;
 import com.streamxhub.streamx.console.base.utils.SpringContextUtil;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.lang3.StringUtils;
@@ -38,8 +38,7 @@
 @Slf4j
 public class JWTUtil {
 
-    private static final long EXPIRE_TIME =
-            SpringContextUtil.getBean(StreamXProperties.class).getShiro().getJwtTimeOut() * 1000;
+    private static final long EXPIRE_TIME = SpringContextUtil.getBean(ShiroProperties.class).getJwtTimeOut() * 1000;
 
     /**
      * 校验 token是否正确

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/ApplicationController.java
Patch:
@@ -148,7 +148,7 @@ public RestResponse cancel(Application app) {
 
     @PostMapping("yarn")
     public RestResponse yarn() {
-        return RestResponse.create().data(HadoopUtils.getRMWebAppURL(false));
+        return RestResponse.create().data(HadoopUtils.getRMWebAppURL(true));
     }
 
     @PostMapping("name")

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/controller/FlinkSqlController.java
Patch:
@@ -59,7 +59,6 @@ public RestResponse verify(String sql) {
                 .data(false)
                 .message(sqlError.exception())
                 .put("type", sqlError.errorType().errorType)
-                .put("sql", sqlError.sql())
                 .put("start", start)
                 .put("end", end);
             //语法异常

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationConfigServiceImpl.java
Patch:
@@ -251,7 +251,7 @@ public synchronized String readTemplate() {
             }
             File file = new File(path);
             try {
-                String conf = FileUtils.readFileToString(file, "utf-8");
+                String conf = FileUtils.readFileToString(file);
                 this.flinkConfTemplate = Base64.getEncoder().encodeToString(conf.getBytes());
             } catch (IOException e) {
                 e.printStackTrace();

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/EffectiveServiceImpl.java
Patch:
@@ -33,6 +33,8 @@
 import org.springframework.transaction.annotation.Propagation;
 import org.springframework.transaction.annotation.Transactional;
 
+import java.util.Date;
+
 /**
  * @author benjobs
  */
@@ -68,6 +70,7 @@ public void saveOrUpdate(Long appId, EffectiveType type, Long id) {
             effective.setAppId(appId);
             effective.setTargetType(type.getType());
             effective.setTargetId(id);
+            effective.setCreateTime(new Date());
             save(effective);
         } else {
             update(new UpdateWrapper<Effective>()

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/system/authentication/JWTUtil.java
Patch:
@@ -25,7 +25,7 @@
 import com.auth0.jwt.algorithms.Algorithm;
 import com.auth0.jwt.exceptions.JWTDecodeException;
 import com.auth0.jwt.interfaces.DecodedJWT;
-import com.streamxhub.streamx.console.base.properties.StreamXProperties;
+import com.streamxhub.streamx.console.base.properties.ShiroProperties;
 import com.streamxhub.streamx.console.base.utils.SpringContextUtil;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.commons.lang3.StringUtils;
@@ -38,8 +38,7 @@
 @Slf4j
 public class JWTUtil {
 
-    private static final long EXPIRE_TIME =
-            SpringContextUtil.getBean(StreamXProperties.class).getShiro().getJwtTimeOut() * 1000;
+    private static final long EXPIRE_TIME = SpringContextUtil.getBean(ShiroProperties.class).getJwtTimeOut() * 1000;
 
     /**
      * 校验 token是否正确

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/utils/CommonUtil.java
Patch:
@@ -22,6 +22,7 @@
 
 import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
+import com.streamxhub.streamx.common.util.AssertUtil;
 import lombok.extern.slf4j.Slf4j;
 import org.springframework.cglib.beans.BeanMap;
 

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/AlertServiceImpl.java
Patch:
@@ -166,7 +166,7 @@ private MailTemplate getMailTemplate(Application application) {
         template.setStartTime(DateUtils.format(application.getStartTime(), DateUtils.fullFormat(), TimeZone.getDefault()));
         template.setEndTime(DateUtils.format(application.getEndTime() == null ? new Date() : application.getEndTime(), DateUtils.fullFormat(), TimeZone.getDefault()));
         template.setDuration(DateUtils.toRichTimeDuration(duration));
-        template.setRestart(application.isNeedRestartOnFailed());
+        template.setRestart(application.isNeedRestartOnFailed() && application.getRestartCount() > 0);
         template.setRestartIndex(application.getRestartCount());
         template.setTotalRestart(application.getRestartSize());
         template.setCpFailureRateInterval(DateUtils.toRichTimeDuration(application.getCpFailureRateInterval()));

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/sink/JdbcSink.java
Patch:
@@ -20,6 +20,7 @@
  */
 package com.streamxhub.streamx.flink.core.java.sink;
 
+import com.streamxhub.streamx.common.util.AssertUtil;
 import com.streamxhub.streamx.common.util.ConfigUtils;
 import com.streamxhub.streamx.flink.core.java.function.SQLFromFunction;
 import com.streamxhub.streamx.flink.core.scala.StreamingContext;
@@ -59,7 +60,7 @@ public JdbcSink<T> sql(SQLFromFunction<T> func) {
     }
 
     public DataStreamSink<T> sink(DataStream<T> dataStream) {
-        assert sqlFunc != null;
+        AssertUtil.notNull(sqlFunc);
         this.jdbc = this.jdbc == null ? ConfigUtils.getJdbcConf(context.parameter().toMap(), alias) : this.jdbc;
         JdbcSinkFunction<T> sinkFun = new JdbcSinkFunction<>(this.jdbc, this.sqlFunc);
         return dataStream.addSink(sinkFun);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/AlertServiceImpl.java
Patch:
@@ -166,7 +166,7 @@ private MailTemplate getMailTemplate(Application application) {
         template.setStartTime(DateUtils.format(application.getStartTime(), DateUtils.fullFormat(), TimeZone.getDefault()));
         template.setEndTime(DateUtils.format(application.getEndTime() == null ? new Date() : application.getEndTime(), DateUtils.fullFormat(), TimeZone.getDefault()));
         template.setDuration(DateUtils.toRichTimeDuration(duration));
-        template.setRestart(application.isNeedRestartOnFailed());
+        template.setRestart(application.isNeedRestartOnFailed() && application.getRestartCount() > 0);
         template.setRestartIndex(application.getRestartCount());
         template.setTotalRestart(application.getRestartSize());
         template.setCpFailureRateInterval(DateUtils.toRichTimeDuration(application.getCpFailureRateInterval()));

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/base/utils/CommonUtil.java
Patch:
@@ -22,6 +22,7 @@
 
 import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
+import com.streamxhub.streamx.common.util.AssertUtil;
 import lombok.extern.slf4j.Slf4j;
 import org.springframework.cglib.beans.BeanMap;
 

File: streamx-flink/streamx-flink-core/src/main/java/com/streamxhub/streamx/flink/core/java/sink/JdbcSink.java
Patch:
@@ -20,6 +20,7 @@
  */
 package com.streamxhub.streamx.flink.core.java.sink;
 
+import com.streamxhub.streamx.common.util.AssertUtil;
 import com.streamxhub.streamx.common.util.ConfigUtils;
 import com.streamxhub.streamx.flink.core.java.function.SQLFromFunction;
 import com.streamxhub.streamx.flink.core.scala.StreamingContext;
@@ -59,7 +60,7 @@ public JdbcSink<T> sql(SQLFromFunction<T> func) {
     }
 
     public DataStreamSink<T> sink(DataStream<T> dataStream) {
-        assert sqlFunc != null;
+        AssertUtil.notNull(sqlFunc);
         this.jdbc = this.jdbc == null ? ConfigUtils.getJdbcConf(context.parameter().toMap(), alias) : this.jdbc;
         JdbcSinkFunction<T> sinkFun = new JdbcSinkFunction<>(this.jdbc, this.sqlFunc);
         return dataStream.addSink(sinkFun);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -891,7 +891,7 @@ public boolean start(Application appParam, boolean auto) throws Exception {
         if (!auto) {
             application.setRestartCount(0);
         } else {
-            if (application.getRestartCount() >= application.getRestartSize()) {
+            if (!application.isNeedRestartOnFailed()) {
                 return false;
             }
             application.setRestartCount(application.getRestartCount() + 1);

File: streamx-console/streamx-console-service/src/main/java/com/streamxhub/streamx/console/core/service/impl/ApplicationServiceImpl.java
Patch:
@@ -891,7 +891,7 @@ public boolean start(Application appParam, boolean auto) throws Exception {
         if (!auto) {
             application.setRestartCount(0);
         } else {
-            if (application.getRestartCount() >= application.getRestartSize()) {
+            if (!application.isNeedRestartOnFailed()) {
                 return false;
             }
             application.setRestartCount(application.getRestartCount() + 1);

